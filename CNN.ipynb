{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing main libraries\n",
    "\n",
    "## Conservare un dataset solo per il test, implementare gridsearch seanza sare ealry stopping. Refittare solo il modello migliore con ealy stopping successivamente su tutto il training set e valutarlo sul test set messo da parte all'inizio. Mettere tutti i modelli in un unico file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    ""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the dataset\n",
    "\n",
    "- df_ok: labels of ok gauges\n",
    "- df_delta: labels of delta gauges\n",
    "- df_ raw: raw data cointaining the full reading of each gauge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_delta = pd.read_csv('df_delta.csv') # cointains labels for delta VG\n",
    "df_ok = pd.read_csv('df_ok.csv')  #contains labels for ok VG\n",
    "\n",
    "df_raw = pd.read_csv('df_raw.csv') ## contains full reading of each VG\n",
    "\n",
    "df_labels = pd.concat([df_ok, df_delta], sort=False, axis=0)\n",
    "\n",
    "\n",
    "df_VG = pd.merge(df_raw, df_labels, on =['gauge_id','fillNumber'])\n",
    "df_VG = df_VG.set_index(['gauge_id','fillNumber'], drop=True)\n",
    "\n",
    "## Removing categorical values\n",
    "df_VG.y.replace(to_replace=['ok', 'delta'], value=[0, 1], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(194, 3000)\n(84, 3000)\n(194,)\n(84,)\n"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = np.array(df_VG.iloc[:, :-1])\n",
    "y = np.array(df_VG.iloc[:, -1])\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_valid.shape)\n",
    "print(y_train.shape)\n",
    "print(y_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining scalers for CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import StandardScaler, MaxAbsScaler, MinMaxScaler, RobustScaler\n",
    "\n",
    "\n",
    "class RowStandardScaler(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        return None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        scaler = StandardScaler()\n",
    "        return scaler.fit_transform(X.transpose()).transpose()\n",
    "\n",
    "scaler = RowStandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_valid = scaler.fit_transform(X_valid)\n",
    "X_train = X_train[..., np.newaxis]\n",
    "X_valid = X_valid[..., np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"sequential_3\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv1d_3 (Conv1D)            (None, 3000, 15)          315       \n_________________________________________________________________\nmax_pooling1d_3 (MaxPooling1 (None, 1500, 15)          0         \n_________________________________________________________________\nflatten_3 (Flatten)          (None, 22500)             0         \n_________________________________________________________________\ndense_6 (Dense)              (None, 100)               2250100   \n_________________________________________________________________\ndense_7 (Dense)              (None, 1)                 101       \n=================================================================\nTotal params: 2,250,516\nTrainable params: 2,250,516\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Conv1D(filters=15, kernel_size=20, activation='relu', padding='same', use_bias=True, input_shape=(3000, 1)),\n",
    "    keras.layers.MaxPool1D(pool_size=2),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(units=100, activation='relu'),\n",
    "    keras.layers.Dense(units=1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "                        optimizer=keras.optimizers.Adam(),\n",
    "                        metrics=[keras.metrics.Recall()])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Train on 194 samples, validate on 84 samples\nEpoch 1/100\n194/194 [==============================] - 1s 3ms/sample - loss: 2.3573e-05 - recall: 1.0000 - val_loss: 0.4402 - val_recall: 0.9333\nEpoch 2/100\n194/194 [==============================] - 1s 3ms/sample - loss: 2.3235e-05 - recall: 1.0000 - val_loss: 0.4407 - val_recall: 0.9333\nEpoch 3/100\n194/194 [==============================] - 1s 3ms/sample - loss: 2.2887e-05 - recall: 1.0000 - val_loss: 0.4410 - val_recall: 0.9333\nEpoch 4/100\n194/194 [==============================] - 1s 3ms/sample - loss: 2.2563e-05 - recall: 1.0000 - val_loss: 0.4415 - val_recall: 0.9333\nEpoch 5/100\n194/194 [==============================] - 1s 3ms/sample - loss: 2.2343e-05 - recall: 1.0000 - val_loss: 0.4419 - val_recall: 0.9333\nEpoch 6/100\n194/194 [==============================] - 1s 3ms/sample - loss: 2.2059e-05 - recall: 1.0000 - val_loss: 0.4425 - val_recall: 0.9333\n"
    }
   ],
   "source": [
    "history =  model.fit(X_train, y_train, epochs=100,\n",
    "                     validation_data=(X_valid, y_valid),\n",
    "                     callbacks = [keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[0. 1. 1. 0. 0. 0. 1. 1. 0. 0.]\n[0 1 1 0 0 0 1 1 0 0]\n"
    }
   ],
   "source": [
    "print(np.round(y_pred[:,0])[:10])\n",
    "print(y_valid[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.9404761904761905"
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(y_true=y_valid, y_pred=np.round(y_pred[:,0]), sample_weight=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}