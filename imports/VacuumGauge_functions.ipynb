{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit-Learns Estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import StandardScaler, MaxAbsScaler, MinMaxScaler, RobustScaler\n",
    "\n",
    "class Prepocess(BaseEstimator, TransformerMixin):\n",
    "    '''\n",
    "     The preprocessing of the input is divided in 2 steps:\n",
    "\n",
    "     1. Max pooling layer with kernel 15 and strides 15: reduce the dimensionality of a factor 15 keeping the max values,\n",
    "        it preserve the interesting part of the signal\n",
    "     2. Median filter with kernel 9 to get rid of evenutally present white noise\n",
    "    '''\n",
    "    def __init__(self, max_pool_size=15, median_size=9, savgol_length=11, log_scale=False):\n",
    "        self.max_pool_size = max_pool_size\n",
    "        self.median_size = median_size\n",
    "        self.savgol_length = savgol_length\n",
    "        self.log_scale = log_scale\n",
    "        return None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        from skimage.measure import block_reduce\n",
    "        from scipy.signal import medfilt, savgol_filter\n",
    "        X_max = block_reduce(X, block_size=(1, self.max_pool_size), func=np.max)\n",
    "\n",
    "        if self.log_scale:\n",
    "            X_max = np.log10(X_max)\n",
    "\n",
    "        X_med = np.apply_along_axis(medfilt,\n",
    "                                    axis=1,\n",
    "                                    arr= X_max,\n",
    "                                    kernel_size=self.median_size)\n",
    "\n",
    "        X_sav = np.apply_along_axis(savgol_filter,\n",
    "                                    axis=1,\n",
    "                                    arr= X_med,\n",
    "                                    window_length=self.savgol_length,\n",
    "                                    polyorder=2)\n",
    "        \n",
    "\n",
    "        return X_sav\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class RowScaler(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, scaling_method='Standard'):\n",
    "        self.scaling_options = ['Standard', 'MinMax', 'MaxAbs', 'Robust']\n",
    "        assert (scaling_method in self.scaling_options), 'scaling_method:' + scaling_method + ' not in ' + str(self.scaling_options)\n",
    "        \n",
    "        self.scaling_method = scaling_method\n",
    "        return None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        if self.scaling_method == 'Robust':\n",
    "            self.scaler = RobustScaler()\n",
    "        elif self.scaling_method == 'MinMax':\n",
    "            self.scaler = MinMaxScaler()\n",
    "        elif self.scaling_method == 'Standard':\n",
    "            self.scaler = StandardScaler()\n",
    "        elif self.scaling_method == 'MaxAbs':\n",
    "            self.scaler = MaxAbsScaler()\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        return self.scaler.fit_transform(X.transpose()).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printGridSearchResults(grid_search, scoring):\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print(grid_search.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = grid_search.cv_results_['mean_test_{}'.format(scoring)]\n",
    "    stds = grid_search.cv_results_['std_test_{}'.format(scoring)]\n",
    "    for mean, std, params in zip(means, stds, grid_search.cv_results_['params']):\n",
    "        print(\"{:0.3f} (+/-{:0.03f}) for {}\".format(mean, std * 2, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plottare tutte e 3 le metriche, passare il valore di ordinamento\n",
    "\n",
    "def plot_score (model_dir, model_version, scoring_list=['accuracy'],\n",
    "                sort_scoring='accuracy', n_results=-1, name=''):\n",
    "    if model_version.split('.')[-1] == 'pkl':\n",
    "        model = joblib.load(model_path)\n",
    "        results = pd.DataFrame(model.cv_results_)\n",
    "    elif model_version.split('.')[-1] == 'csv':\n",
    "        results = pd.read_csv(model_path)\n",
    "        model = None\n",
    "\n",
    "    results = results.sort_values(by='rank_test_{}'.format(sort_scoring))\n",
    "    results = results.reset_index(drop=True)\n",
    "    plt.figure(figsize=(10,10))\n",
    "    for index, scoring in enumerate(scoring_list):\n",
    "        test_mean = results['mean_test_{}'.format(scoring)][:n_results]\n",
    "        test_std = results['std_test_{}'.format(scoring)][:n_results]\n",
    "\n",
    "        train_mean = results['mean_train_{}'.format(scoring)][:n_results]\n",
    "        train_std = results['std_train_{}'.format(scoring)][:n_results]\n",
    "\n",
    "        plt.subplot(len(scoring_list), 1, index+1)\n",
    "        plt.errorbar(range(len(test_mean)), test_mean, yerr=test_std,\n",
    "                    linestyle='None', marker='o', color='b', label='test')\n",
    "\n",
    "        plt.errorbar(range(len(train_mean)), train_mean, yerr=train_std,\n",
    "                    linestyle='None', marker='o', color='r', label='train')\n",
    "\n",
    "        plt.tick_params(axis='both', which='major', labelsize=18)\n",
    "        plt.xlabel('Parameters set (index)', fontsize=18)\n",
    "        plt.ylabel(name + ' ' + scoring, fontsize=22)\n",
    "        plt.ylim(0.8,1)\n",
    "\n",
    "        plt.legend(fontsize=20, frameon=False, loc='lower left')\n",
    "    plt.show()\n",
    "    return results, model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def save_model(model, model_dir, model_version):\n",
    "    model_path = os.path.join(model_dir, model_version)\n",
    "    if os.path.exists(model_path):\n",
    "        print(model_path + ' already exist, not overwritten.')\n",
    "    else:\n",
    "        !mkdir -p {model_dir}\n",
    "        joblib.dump(model, model_path)\n",
    "        print(model_path + ' succesfully saved.')\n",
    "\n",
    "\n",
    "def save_keras_model(model, model_dir, model_version):\n",
    "    model_path = os.path.join(model_dir, model_version)\n",
    "    if os.path.exists(model_path):\n",
    "        print(model_path + ' already exist, not overwritten.')\n",
    "    else:\n",
    "        !mkdir -p {model_dir}\n",
    "        model.save(model_path)\n",
    "        print(model_path + ' succesfully saved.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF Functions and Layers(for keras models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rowScale(X):\n",
    "    mean = tf.reshape(tf.reduce_mean(X, axis=1), [-1, 1, 1])\n",
    "    std =  tf.reshape(tf.math.reduce_std(X, axis=1), [-1, 1, 1])\n",
    "    return (X - mean)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def preprocess(X):\n",
    "    X_med = tfa.image.median_filter2d(image= X,\n",
    "                                      filter_shape= [1, 9],\n",
    "                                      padding = 'CONSTANT',\n",
    "                                      constant_values= 0)\n",
    "\n",
    "    mean = tf.reshape(tf.reduce_mean(X_med, axis=1), [-1, 1, 1])\n",
    "    std =  tf.reshape(tf.math.reduce_std(X_med, axis=1), [-1, 1, 1])\n",
    "\n",
    "    return (X_med - mean)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "class KerasPreprocess(keras.layers.Layer):\n",
    "    def __init__(self, median_size=9, activation=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.median_size = median_size\n",
    "        self.activation = keras.activations.get(activation)\n",
    "        \n",
    "\n",
    "    def build(self, batch_input_shape):\n",
    "        super().build(batch_input_shape) #must be at the end\n",
    "    \n",
    "    def call(self, X):\n",
    "        X_med = tfa.image.median_filter2d(image= X,\n",
    "                                      filter_shape= [1, self.median_size],\n",
    "                                      padding = 'CONSTANT',\n",
    "                                      constant_values= 0)\n",
    "\n",
    "        mean = tf.reshape(tf.reduce_mean(X_med, axis=1), [-1, 1, 1])\n",
    "        std =  tf.reshape(tf.math.reduce_std(X_med, axis=1), [-1, 1, 1])\n",
    "\n",
    "        return (X_med - mean)/std\n",
    "    \n",
    "    def compute_output_shape(self, batch_input_shape):\n",
    "        return batch_input_shape\n",
    "    \n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, 'median_size': self.median_size,\n",
    "                'activation': keras.activations.serialize(self.activation)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class OneCycleScheduler(keras.callbacks.Callback):\n",
    "#     def __init__(self, iterations, max_rate, start_rate=None,\n",
    "#                  last_iterations=None, last_rate=None):\n",
    "#         self.iterations = iterations\n",
    "#         self.max_rate = max_rate\n",
    "#         self.start_rate = start_rate or max_rate / 10\n",
    "#         self.last_iterations = last_iterations or iterations // 10 + 1\n",
    "#         self.half_iteration = (iterations - self.last_iterations) // 2\n",
    "#         self.last_rate = last_rate or self.start_rate / 1000\n",
    "#         self.iteration = 0\n",
    "#     def _interpolate(self, iter1, iter2, rate1, rate2):\n",
    "#         return ((rate2 - rate1) * (self.iteration - iter1)\n",
    "#                 / (iter2 - iter1) + rate1)\n",
    "#     def on_batch_begin(self, batch, logs):\n",
    "#         if self.iteration < self.half_iteration:\n",
    "#             rate = self._interpolate(0, self.half_iteration, self.start_rate, self.max_rate)\n",
    "#         elif self.iteration < 2 * self.half_iteration:\n",
    "#             rate = self._interpolate(self.half_iteration, 2 * self.half_iteration,\n",
    "#                                      self.max_rate, self.start_rate)\n",
    "#         else:\n",
    "#             rate = self._interpolate(2 * self.half_iteration, self.iterations,\n",
    "#                                      self.start_rate, self.last_rate)\n",
    "#             rate = max(rate, self.last_rate)\n",
    "#         self.iteration += 1\n",
    "#         K.set_value(self.model.optimizer.lr, rate)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}