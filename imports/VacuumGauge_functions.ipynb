{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing the dataset along the row\n",
    "\n",
    "A custom normalization transformer has been defined to perform the row normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import StandardScaler, MaxAbsScaler, MinMaxScaler, RobustScaler\n",
    "\n",
    "\n",
    "class RowScaler(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, scaling_method='Standard'):\n",
    "        self.scaling_options = ['Standard', 'MinMax', 'MaxAbs', 'Robust']\n",
    "        assert (scaling_method in self.scaling_options), 'scaling_method:' + scaling_method + ' not in ' + str(self.scaling_options)\n",
    "        self.scaling_method = scaling_method\n",
    "\n",
    "        return None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        if self.scaling_method == 'Robust':\n",
    "            self.scaler = RobustScaler()\n",
    "        elif self.scaling_method == 'MinMax':\n",
    "            self.scaler = MinMaxScaler()\n",
    "        elif self.scaling_method == 'Standard':\n",
    "            self.scaler = StandardScaler()\n",
    "        elif self.scaling_method == 'MaxAbs':\n",
    "            self.scaler = MaxAbsScaler()\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        return self.scaler.fit_transform(X.transpose()).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printGridSearchResults(grid_search, scoring):\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print(grid_search.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = grid_search.cv_results_['mean_test_{}'.format(scoring)]\n",
    "    stds = grid_search.cv_results_['std_test_{}'.format(scoring)]\n",
    "    for mean, std, params in zip(means, stds, grid_search.cv_results_['params']):\n",
    "        print(\"{:0.3f} (+/-{:0.03f}) for {}\".format(mean, std * 2, params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def save_model(model, model_dir, model_version):\n",
    "    model_path = os.path.join(model_dir, model_version)\n",
    "    if os.path.exists(model_path):\n",
    "        print(model_path + ' already exist, not overwritten.')\n",
    "    else:\n",
    "        !mkdir -p {model_dir}\n",
    "        joblib.dump(model, model_path)\n",
    "        print(model_path + ' succesfully saved.')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}