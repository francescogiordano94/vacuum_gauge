{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run imports/VacuumGauge_functions.ipynb\n",
    "%run imports/rbflayer.py\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "root_logdir = os.path.join(os.curdir, 'data/logs')\n",
    "\n",
    "if not(os.path.exists(root_logdir)):\n",
    "    !mkdir -p {root_logdir}\n",
    "    print('{} succesfully created.'.format(root_logdir))\n",
    "else:\n",
    "    print('{} already exist.'.format(root_logdir))\n",
    "\n",
    "def get_run_logdir(model_version):\n",
    "    import time\n",
    "    run_id = time.strftime('{}_run_%Y_%m_%d-%H_%M_%S'.format(model_version))\n",
    "    return os.path.join(root_logdir, run_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorboard starting -- (only if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir={root_logdir} --port=6006"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the dataset\n",
    "\n",
    "- df_ok: labels of ok gauges\n",
    "- df_delta: labels of delta gauges\n",
    "- df_ raw: raw data cointaining the full reading of each gauge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_delta = pd.read_csv('data/datasets/df_delta.csv') # cointains labels for delta VG\n",
    "df_ok = pd.read_csv('data/datasets/df_ok.csv')  #contains labels for ok VG\n",
    "\n",
    "df_raw = pd.read_csv('data/datasets/df_raw.csv') ## contains full reading of each VG\n",
    "\n",
    "df_labels = pd.concat([df_ok, df_delta], sort=False, axis=0)\n",
    "\n",
    "\n",
    "df_VG = pd.merge(df_raw, df_labels, on =['gauge_id','fillNumber'])\n",
    "df_VG = df_VG.set_index(['gauge_id','fillNumber'], drop=True)\n",
    "\n",
    "## Removing categorical values\n",
    "df_VG.y.replace(to_replace=['ok', 'delta'], value=[0, 1], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the dataset in input and target\n",
    "- X are the input features\n",
    "- y is the target vector\n",
    "\n",
    "Definition of a StratifiedKFold split to be used in all the grid searchs for all the model: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(df_VG.iloc[:, :-1])\n",
    "y = np.array(df_VG.iloc[:, -1])\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "strat_kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hold out a test set for final evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "\n",
    "# sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "\n",
    "# print(sss)\n",
    "\n",
    "# for train_index, test_index in sss.split(X, y):\n",
    "#     print(\"TRAIN size:\", len(train_index), \"TEST size:\", len(test_index))\n",
    "#     X_train, X_test = X[train_index], X[test_index]\n",
    "#     y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "\n",
    "# print(len(y_train))\n",
    "# print(sum(y_train))\n",
    "# print(len(y_test))\n",
    "# print(sum(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "The preprocessing of the input is divided in 3 steps:\n",
    "\n",
    "1. Max pooling layer with kernel 15 and strides 15: reduce the dimensionality of a factor 15 keeping the max values, it preserve the interesting part of the signal\n",
    "2. Median filter with kernel 9 to get rid of evenutally present white noise\n",
    "3. Savitzkyâ€“Golay filter to further reduce discontinuities\n",
    "4. Scaling of each time series to help gradient descent converge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.gradient([50,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage\n",
    "\n",
    "def mean_angle(degrees, axis=None):\n",
    "    '''\n",
    "    https://en.wikipedia.org/wiki/Mean_of_circular_quantities\n",
    "    '''\n",
    "    x = np.mean(np.cos(degrees*np.pi/180), axis=axis)\n",
    "    y = np.mean(np.sin(degrees*np.pi/180), axis=axis)\n",
    "    return np.arctan2(y,x)*180/np.pi\n",
    "\n",
    "\n",
    "out = mean_angle(\n",
    "    skimage.util.view_as_windows(\n",
    "        np.pad(degrees, (1, 1), mode='symmetric'),\n",
    "        window_shape=(3, 3, 3)\n",
    "    ),\n",
    "    axis=(-1, -2, -3)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "from skimage.measure import block_reduce\n",
    "\n",
    "\n",
    "## Tensorflow implementation of max_pool\n",
    "\n",
    "# X_max = X.reshape((X.shape[0], 3000, 1))  \n",
    "# X_max = tf.nn.max_pool1d(X_max, ksize=15, strides=15, padding='VALID')\n",
    "# X_max = X_max[...,0]\n",
    "\n",
    "## Numpy implementation of max_pool\n",
    "\n",
    "X_max = block_reduce(X, block_size=(1,15), func=np.max)\n",
    "\n",
    "\n",
    "X_med = np.apply_along_axis(scipy.signal.medfilt, axis=1, arr= X_max, kernel_size=9)\n",
    "X_sav = np.apply_along_axis(scipy.signal.savgol_filter, axis=1,\n",
    "                            arr= X_med, window_length=11, polyorder=2)\n",
    "scaler = RowScaler(scaling_method='Standard')\n",
    "\n",
    "pca = PCA(n_components=30)\n",
    "X_norm = scaler.fit_transform(X_sav)\n",
    "X_pca = pca.fit_transform(X_norm)\n",
    "\n",
    "\n",
    "\n",
    "# X_f = np.fft.fft(X_avg, X_avg.shape[-1])\n",
    "# X_f = np.fft.fftshift(X_f, axes=-1)\n",
    "X_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g = np.gradient(X_norm, axis=1)\n",
    "# for i in range(0, 20, 1):\n",
    "#     plt.plot(X_norm[i])\n",
    "#     plt.plot(g[i]/np.max(g[i]))\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "for i in range(0,12):\n",
    "    plt.subplot(4,1,1)\n",
    "    plt.plot(X[i])\n",
    "    plt.subplot(4,1,2)\n",
    "    plt.plot(X_med[i])\n",
    "    plt.subplot(4,1,3)\n",
    "    plt.plot(X_sav[i])\n",
    "    plt.subplot(4,1,4)\n",
    "    plt.plot(g[i])\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick overview on the PCA impact\n",
    "\n",
    "PCA performed on the trainig part of the normalised dataset to visualize its impact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scaler = RowScaler('Standard')\n",
    "# X_norm = scaler.fit_transform(X)\n",
    "# X_norm[0].shape\n",
    "\n",
    "i=100\n",
    "X_m = scaler.fit_transform(X) - scaler.fit_transform(X).mean(axis=0, keepdims=0)\n",
    "plt.figure()\n",
    "plt.plot(range(3000), scaler.fit_transform(X)[i])\n",
    "plt.plot(range(3000), X_m[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = Prepocess(log_scale=False)\n",
    "scaler = RowScaler('Standard')\n",
    "\n",
    "pca = PCA(n_components=3)\n",
    "\n",
    "\n",
    "X_pca = pca.fit_transform(scaler.fit_transform(preprocess.fit_transform(X)))\n",
    "# X_pca = pca.fit_transform(scaler.fit_transform(X))\n",
    "X_pca[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "fontsize=15\n",
    "\n",
    "ok = X_pca[y==0]\n",
    "delta = X_pca[y ==1]\n",
    "\n",
    "\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "fontsize=20\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.scatter(ok[:,0], ok[:,1], c='b', label='no heating', s=50)\n",
    "plt.scatter(delta[:,0], delta[:,1], c='r', label='heating', s=50)\n",
    "\n",
    "plt.legend(fontsize=fontsize)\n",
    "plt.xlabel('component #1', fontsize=fontsize)\n",
    "plt.ylabel('component #2', fontsize=fontsize)\n",
    "plt.tick_params(axis='both', which='major', labelsize=fontsize)\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "fig = plt.figure(figsize=(10,8))\n",
    "ax = Axes3D(fig)\n",
    "\n",
    "ax.scatter(ok[:,0], ok[:,1], ok[:,2], c='b', label='no heating', s=50)\n",
    "ax.scatter(delta[:,0], delta[:,1], delta[:,2], c='r', label='heating', s=50)\n",
    "\n",
    "ax.set_xlabel('component #1', fontsize=fontsize)\n",
    "ax.set_ylabel('component #2', fontsize=fontsize)\n",
    "ax.set_zlabel('component #3', fontsize=fontsize)\n",
    "\n",
    "# ax.set_xlim(-25,30)\n",
    "# ax.set_ylim(-5,20)\n",
    "# ax.set_zlim(-10,7.5)\n",
    "plt.gca().patch.set_facecolor('white')\n",
    "plt.tick_params(axis='both', which='major', labelsize=fontsize)\n",
    "plt.legend(fontsize=fontsize)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = np.where(np.all([y == 1, X_pca[:,0]>5], axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-MEANS preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import KernelPCA\n",
    "from sklearn.manifold import LocallyLinearEmbedding\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "preprocess = Prepocess(log_scale=False)\n",
    "scaler = RowScaler('Standard')\n",
    "\n",
    "kmeans = KMeans(n_clusters=3,\n",
    "                algorithm='elkan',\n",
    "                random_state=42)\n",
    "lle = LocallyLinearEmbedding(n_components=3, n_neighbors= 10)\n",
    "rbf_pca = KernelPCA(n_components=3, kernel='rbf', gamma=0.005)\n",
    "tsne = TSNE(n_components=3, perplexity=20)\n",
    "a = preprocess.fit_transform(X)\n",
    "b = scaler.fit_transform(a)\n",
    "d = kmeans.fit_transform(b)\n",
    "# d = rbf_pca.fit_transform(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for center in kmeans.cluster_centers_:\n",
    "#     plt.plot(range(200), center)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "ok = d[y==0]\n",
    "delta = d[y ==1]\n",
    "\n",
    "\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "fontsize=20\n",
    "plt.close('all')\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.scatter(ok[:,0], ok[:,1], c='b', label='no heating', s=50)\n",
    "plt.scatter(delta[:,0], delta[:,1], c='r', label='heating', s=50)\n",
    "\n",
    "plt.legend(fontsize=fontsize)\n",
    "plt.xlabel('component #1', fontsize=fontsize)\n",
    "plt.ylabel('component #2', fontsize=fontsize)\n",
    "plt.tick_params(axis='both', which='major', labelsize=fontsize)\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "fig = plt.figure(figsize=(10,8))\n",
    "ax = Axes3D(fig)\n",
    "\n",
    "ax.scatter(ok[:,0], ok[:,1], ok[:,2], c='b', label='no heating', s=50)\n",
    "ax.scatter(delta[:,0], delta[:,1], delta[:,2], c='r', label='heating', s=50)\n",
    "\n",
    "ax.set_xlabel('component #1', fontsize=fontsize)\n",
    "ax.set_ylabel('component #2', fontsize=fontsize)\n",
    "ax.set_zlabel('component #3', fontsize=fontsize)\n",
    "\n",
    "# ax.set_xlim(-25,30)\n",
    "# ax.set_ylim(-5,20)\n",
    "# ax.set_zlim(-10,7.5)\n",
    "plt.gca().patch.set_facecolor('white')\n",
    "plt.tick_params(axis='both', which='major', labelsize=fontsize)\n",
    "plt.legend(fontsize=fontsize)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest_clf = Pipeline([\n",
    "    ('preprocessor', Prepocess()),\n",
    "    ('scaler', RowScaler(scaling_method='Standard')),\n",
    "    ('kmeans', KMeans(algorithm='elkan',random_state=42)),\n",
    "    ('forest', RandomForestClassifier())\n",
    "\n",
    "])\n",
    "\n",
    "model = forest_clf\n",
    "model_dir = 'data/models/random_forest'\n",
    "model_version = 'forest_006.pkl'\n",
    "scoring = ['recall', 'accuracy', 'precision']\n",
    "\n",
    "forest_path = os.path.join(model_dir, model_version)\n",
    "\n",
    "print(os.path.join(model_dir,model_version))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "a = Real(2,100, prior='log-uniform')\n",
    "# b = Real(1,100)\n",
    "X = range(1,1000)\n",
    "plt.plot((sorted(a.rvs(100))))\n",
    "# plt.plot(sorted(b.rvs(1000)))\n",
    "print(np.max(a.transform(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(range(30,51, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "\n",
    "param_grid = [\n",
    "    {\n",
    "    #  'scaler__scaling_method': RowScaler().scaling_options,\n",
    "     'kmeans__n_clusters': [10, 30, 100],\n",
    "     'preprocessor__log_scale': [False],\n",
    "     'forest__n_estimators': [50, 100, 150],\n",
    "     'forest__max_leaf_nodes': [2, 3, 4],\n",
    "     'forest__bootstrap': [False],\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"# Tuning hyper-parameters for {} and {}\".format(scoring[0], scoring[1]))\n",
    "print()\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=model, \n",
    "    param_grid=param_grid, \n",
    "    scoring=scoring,\n",
    "    n_jobs=-1,\n",
    "    verbose=1, \n",
    "    cv=strat_kfold, \n",
    "    return_train_score=True,\n",
    "    refit=scoring[1]  ## Score used for final refit\n",
    ")\n",
    "\n",
    "grid_search.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printGridSearchResults(grid_search, scoring[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(grid_search, model_dir, model_version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regressor (classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_clf = Pipeline([\n",
    "    ('preprocessor', Prepocess(log_scale=False)),\n",
    "    ('scaler', RowScaler(scaling_method='Standard')),\n",
    "    ('kmeans', KMeans(algorithm='elkan',random_state=42)),\n",
    "    ('logistic', LogisticRegression(solver='liblinear'))\n",
    "\n",
    "])\n",
    "\n",
    "model = log_clf\n",
    "model_dir = 'data/models/logistic_classifier'\n",
    "model_version = 'logistic_004.pkl'\n",
    "scoring = ['recall', 'accuracy', 'precision']\n",
    "\n",
    "log_path = os.path.join(model_dir, model_version)\n",
    "\n",
    "print(os.path.join(model_dir, model_version))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "    {\n",
    "    #  'scaler__scaling_method': RowScaler().scaling_options,\n",
    "     'kmeans__n_clusters': [5, 10, 30, 50, 100],\n",
    "     'logistic__penalty': ['l1', 'l2']\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"# Tuning hyper-parameters for {} and {}\".format(scoring[0], scoring[1]))\n",
    "print()\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=model, \n",
    "    param_grid=param_grid, \n",
    "    scoring=scoring,\n",
    "    n_jobs=-1,\n",
    "    verbose=1, \n",
    "    cv=strat_kfold, \n",
    "    return_train_score=True,\n",
    "    refit=scoring[0]  ## Score used for final refit\n",
    ")\n",
    "\n",
    "grid_search.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printGridSearchResults(grid_search, scoring[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(grid_search)\n",
    "save_model(grid_search, model_dir, model_version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_clf = Pipeline([\n",
    "    ('preprocessor', Prepocess()),\n",
    "    ('scaler', RowScaler(scaling_method='Standard')),\n",
    "    ('kmeans', KMeans(algorithm='elkan',random_state=42)),\n",
    "    ('knn', KNeighborsClassifier())\n",
    "\n",
    "])\n",
    "\n",
    "model = knn_clf\n",
    "model_dir = 'data/models/knn'\n",
    "model_version = 'knn_003.pkl'\n",
    "scoring = ['recall', 'accuracy', 'precision']\n",
    "\n",
    "knn_path = os.path.join(model_dir, model_version)\n",
    "print(os.path.join(model_dir, model_version))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "    {'scaler__scaling_method': RowScaler().scaling_options,\n",
    "     'kmeans__n_clusters': [5, 10, 30, 50, 100],\n",
    "     'knn__n_neighbors': range(3,7),\n",
    "     'knn__n_jobs': [-1]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"# Tuning hyper-parameters for {} and {}\".format(scoring[0], scoring[1]))\n",
    "print()\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=model, \n",
    "    param_grid=param_grid, \n",
    "    scoring=scoring,\n",
    "    n_jobs=-1,\n",
    "    verbose=1, \n",
    "    cv=strat_kfold, \n",
    "    return_train_score=True,\n",
    "    refit=scoring[0]  ## Score used for final refit\n",
    ")\n",
    "\n",
    "grid_search.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printGridSearchResults(grid_search, scoring[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(grid_search, model_dir, model_version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Calcolare false positive rate sui casi non labellati\n",
    "provare la derivata ed eventualmente lstm con 2 input (derivata e segnale)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "StratifiedShuffleSplit(n_splits=20, random_state=42, test_size=0.33,\n            train_size=None)\n[0, 2, 3, 7, 8, 10, 12, 13, 14, 15, 16, 17, 18, 19, 21, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 38, 39, 40, 41, 42, 43, 44, 46, 48, 52, 54, 55, 56, 57, 59, 60, 62, 63, 64, 65, 68, 69, 70, 71, 73, 75, 76, 77, 79, 80, 81, 82, 83, 84, 85, 90, 91, 93, 94, 95, 96, 97, 99, 101, 103, 104, 106, 107, 108, 109, 112, 113, 114, 118, 120, 122, 123, 126, 127, 129, 130, 132, 133, 134, 135, 136, 137, 139, 140, 141, 143, 144, 145, 146, 147, 150, 152, 153, 154, 155, 156, 157, 158, 159, 160, 162, 163, 164, 166, 168, 169, 170, 171, 172, 173, 174, 175, 177, 179, 182, 185, 187, 189, 191, 192, 193, 194, 195, 198, 200, 203, 204, 206, 209, 210, 211, 212, 215, 217, 218, 221, 222, 223, 224, 225, 226, 227, 229, 230, 231, 232, 233, 235, 236, 237, 238, 241, 242, 244, 246, 247, 251, 252, 254, 256, 257, 258, 260, 262, 263, 265, 267, 270, 271, 272, 274, 275, 276]\n[0, 2, 3, 4, 5, 6, 7, 8, 10, 12, 13, 14, 17, 18, 19, 20, 21, 22, 23, 24, 27, 28, 29, 30, 34, 35, 36, 37, 38, 42, 44, 45, 47, 50, 53, 54, 55, 57, 59, 60, 61, 62, 63, 64, 65, 66, 68, 70, 71, 73, 74, 76, 78, 79, 80, 81, 82, 83, 84, 86, 87, 88, 89, 91, 92, 94, 95, 97, 99, 100, 103, 104, 105, 106, 107, 110, 111, 112, 114, 117, 122, 123, 124, 126, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 140, 142, 143, 144, 145, 146, 147, 148, 150, 151, 152, 155, 156, 157, 160, 161, 162, 163, 164, 165, 169, 173, 174, 177, 179, 180, 181, 182, 183, 185, 186, 187, 188, 190, 191, 194, 195, 198, 200, 201, 202, 203, 204, 206, 207, 209, 210, 213, 214, 215, 218, 219, 220, 221, 227, 228, 229, 231, 232, 234, 235, 237, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 254, 255, 257, 258, 259, 260, 261, 262, 263, 264, 266, 267, 268, 270, 272, 274, 276]\n[1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 14, 15, 16, 17, 18, 19, 20, 22, 24, 25, 27, 29, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42, 43, 44, 46, 47, 49, 50, 51, 52, 53, 54, 55, 56, 58, 60, 61, 62, 63, 67, 68, 69, 72, 78, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 93, 95, 96, 97, 98, 99, 101, 102, 105, 106, 109, 111, 112, 113, 114, 115, 116, 118, 119, 120, 122, 123, 124, 125, 126, 128, 131, 132, 133, 134, 135, 136, 138, 139, 140, 141, 144, 146, 148, 150, 151, 152, 153, 156, 157, 158, 160, 161, 162, 163, 165, 167, 168, 170, 171, 175, 176, 177, 180, 181, 186, 189, 190, 191, 192, 193, 194, 196, 197, 198, 200, 201, 202, 204, 207, 208, 209, 210, 211, 213, 216, 217, 221, 222, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 241, 242, 243, 244, 245, 248, 249, 251, 252, 253, 254, 256, 257, 258, 259, 261, 262, 265, 269, 271, 275, 276]\n[0, 1, 3, 4, 5, 6, 8, 9, 12, 15, 16, 18, 19, 20, 21, 23, 24, 25, 26, 28, 29, 32, 33, 36, 37, 38, 39, 40, 42, 43, 44, 45, 48, 49, 50, 51, 52, 53, 55, 56, 58, 59, 62, 63, 66, 67, 68, 69, 70, 71, 72, 73, 76, 77, 78, 79, 80, 81, 83, 84, 86, 87, 89, 93, 94, 95, 98, 102, 103, 104, 105, 106, 108, 109, 110, 111, 112, 113, 114, 116, 118, 119, 120, 121, 125, 126, 127, 130, 132, 133, 135, 136, 138, 139, 141, 142, 144, 147, 150, 154, 155, 156, 158, 159, 161, 162, 166, 168, 169, 170, 171, 172, 174, 175, 177, 179, 180, 181, 183, 186, 188, 190, 191, 192, 193, 195, 196, 198, 199, 200, 203, 205, 206, 207, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 221, 222, 223, 224, 225, 229, 230, 232, 233, 234, 236, 237, 238, 242, 243, 244, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 259, 260, 263, 264, 266, 267, 268, 269, 271, 273, 274, 275, 277]\n[0, 1, 4, 7, 8, 9, 10, 14, 16, 23, 24, 25, 26, 27, 28, 31, 34, 35, 36, 37, 38, 39, 41, 44, 45, 46, 47, 48, 49, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 66, 67, 68, 70, 73, 74, 76, 79, 80, 81, 82, 83, 84, 87, 88, 89, 90, 92, 93, 94, 95, 97, 99, 100, 101, 102, 103, 104, 106, 108, 109, 110, 111, 112, 113, 114, 115, 116, 118, 119, 120, 121, 122, 123, 124, 125, 126, 132, 133, 134, 135, 138, 141, 142, 143, 145, 147, 149, 151, 152, 153, 156, 158, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 172, 173, 174, 175, 176, 178, 179, 180, 181, 183, 184, 186, 187, 188, 190, 191, 193, 194, 196, 197, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 212, 215, 217, 221, 222, 223, 224, 227, 228, 229, 230, 232, 233, 234, 236, 238, 241, 242, 243, 249, 250, 252, 254, 255, 256, 257, 258, 260, 261, 262, 263, 264, 265, 268, 269, 270, 271, 272, 273, 274, 276, 277]\n[1, 2, 4, 5, 6, 9, 10, 12, 15, 19, 20, 22, 23, 24, 25, 26, 27, 29, 30, 31, 32, 33, 34, 35, 37, 39, 41, 42, 43, 44, 45, 47, 48, 49, 52, 53, 54, 55, 56, 57, 60, 61, 62, 65, 66, 67, 68, 70, 72, 73, 74, 75, 76, 77, 79, 80, 81, 82, 84, 89, 90, 92, 93, 94, 95, 96, 99, 101, 102, 106, 107, 109, 110, 112, 115, 116, 118, 119, 120, 121, 122, 123, 124, 126, 127, 129, 133, 134, 135, 136, 137, 138, 141, 142, 144, 146, 148, 149, 150, 151, 152, 153, 154, 155, 157, 158, 159, 160, 161, 162, 164, 165, 167, 168, 169, 173, 174, 176, 177, 179, 180, 181, 182, 184, 186, 189, 191, 193, 194, 195, 197, 198, 199, 200, 201, 202, 203, 204, 206, 207, 208, 210, 212, 214, 215, 217, 219, 222, 223, 225, 226, 228, 229, 230, 232, 233, 234, 236, 239, 241, 242, 243, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 259, 260, 261, 263, 264, 265, 267, 268, 273, 274, 275, 276, 277]\n[0, 1, 2, 3, 4, 6, 7, 8, 10, 11, 12, 14, 15, 17, 19, 20, 21, 22, 23, 25, 26, 27, 29, 30, 32, 34, 35, 36, 37, 39, 40, 41, 43, 44, 46, 47, 49, 53, 54, 55, 57, 59, 61, 62, 63, 65, 67, 68, 69, 72, 73, 74, 75, 76, 77, 82, 83, 84, 85, 86, 87, 90, 91, 92, 94, 96, 97, 99, 100, 101, 105, 106, 108, 110, 112, 114, 115, 116, 118, 119, 120, 123, 124, 125, 127, 128, 129, 131, 132, 133, 135, 137, 138, 139, 140, 141, 142, 143, 145, 146, 147, 149, 150, 151, 152, 153, 154, 155, 156, 157, 161, 162, 164, 165, 168, 169, 170, 171, 172, 173, 174, 175, 176, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 190, 194, 195, 200, 203, 204, 205, 206, 207, 208, 209, 213, 214, 216, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 234, 235, 236, 237, 238, 241, 242, 246, 248, 251, 252, 254, 256, 258, 260, 261, 262, 264, 265, 266, 268, 269, 270, 271, 273, 275]\n[0, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13, 16, 17, 18, 19, 20, 21, 22, 23, 26, 27, 28, 31, 32, 33, 34, 36, 38, 39, 40, 42, 43, 44, 45, 48, 49, 50, 51, 53, 57, 58, 62, 63, 64, 65, 67, 68, 69, 70, 71, 72, 73, 74, 75, 78, 79, 80, 82, 83, 84, 86, 87, 88, 90, 93, 94, 95, 96, 97, 100, 104, 105, 107, 108, 109, 110, 111, 112, 115, 118, 120, 121, 122, 123, 124, 125, 126, 128, 131, 133, 135, 136, 139, 140, 141, 143, 144, 145, 146, 147, 149, 152, 153, 154, 156, 157, 158, 160, 161, 162, 163, 164, 166, 167, 171, 172, 173, 174, 178, 182, 183, 184, 186, 187, 188, 189, 190, 191, 194, 195, 196, 197, 198, 199, 202, 203, 204, 205, 206, 208, 209, 210, 213, 220, 221, 222, 224, 225, 226, 229, 230, 233, 234, 235, 236, 238, 239, 241, 242, 244, 245, 246, 247, 249, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 263, 265, 266, 267, 268, 269, 270, 271, 272, 273, 276, 277]\n[0, 2, 3, 4, 7, 8, 9, 11, 12, 13, 15, 17, 18, 21, 22, 23, 25, 27, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 42, 44, 45, 47, 48, 49, 50, 52, 54, 55, 57, 58, 59, 60, 61, 62, 63, 64, 67, 68, 71, 72, 73, 74, 77, 78, 79, 80, 81, 82, 85, 86, 87, 88, 89, 90, 92, 98, 99, 101, 102, 104, 105, 106, 107, 108, 109, 110, 111, 113, 114, 119, 120, 121, 125, 128, 130, 131, 133, 135, 136, 137, 139, 140, 141, 142, 146, 149, 151, 152, 154, 155, 156, 157, 158, 159, 160, 161, 162, 165, 166, 167, 168, 169, 170, 172, 173, 175, 176, 177, 178, 180, 181, 182, 184, 185, 188, 190, 193, 194, 196, 197, 198, 199, 200, 201, 202, 203, 205, 208, 209, 210, 212, 213, 214, 216, 217, 221, 223, 224, 225, 226, 227, 228, 229, 231, 232, 234, 235, 236, 238, 240, 242, 243, 244, 249, 250, 251, 252, 253, 254, 256, 259, 260, 261, 262, 263, 264, 265, 267, 269, 270, 271, 275, 276, 277]\n[0, 1, 3, 4, 6, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 21, 25, 28, 29, 31, 34, 35, 37, 38, 39, 40, 42, 43, 44, 45, 46, 48, 49, 51, 52, 53, 55, 57, 58, 60, 61, 62, 63, 65, 66, 68, 69, 71, 72, 73, 74, 76, 77, 78, 79, 81, 82, 83, 85, 86, 88, 89, 90, 92, 93, 94, 95, 96, 97, 99, 100, 101, 103, 104, 107, 109, 115, 116, 118, 120, 122, 123, 124, 125, 126, 127, 128, 129, 130, 132, 133, 135, 136, 137, 138, 140, 141, 142, 144, 145, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 160, 161, 163, 165, 167, 168, 170, 171, 174, 175, 176, 177, 178, 183, 185, 186, 187, 190, 191, 192, 195, 196, 198, 199, 200, 202, 203, 204, 205, 206, 207, 213, 214, 215, 216, 217, 218, 219, 220, 221, 223, 224, 225, 227, 228, 230, 232, 234, 235, 238, 243, 244, 246, 247, 248, 249, 250, 252, 255, 256, 258, 259, 261, 262, 263, 264, 265, 266, 267, 269, 270, 271, 274, 275, 277]\n[0, 3, 6, 7, 8, 9, 11, 12, 13, 14, 19, 20, 21, 22, 25, 26, 28, 29, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 43, 44, 47, 48, 49, 50, 51, 53, 54, 55, 56, 57, 59, 60, 61, 62, 63, 64, 65, 66, 67, 69, 70, 71, 73, 75, 77, 78, 79, 80, 82, 84, 85, 87, 89, 91, 94, 96, 98, 99, 100, 101, 102, 104, 105, 107, 108, 109, 110, 111, 112, 114, 117, 118, 121, 122, 123, 124, 125, 126, 129, 132, 133, 134, 135, 136, 137, 139, 140, 141, 142, 143, 144, 146, 147, 150, 152, 155, 156, 157, 159, 160, 161, 165, 167, 168, 169, 170, 173, 175, 176, 177, 179, 180, 181, 183, 186, 188, 189, 190, 192, 193, 194, 195, 198, 199, 200, 201, 202, 203, 205, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 218, 219, 220, 223, 226, 227, 228, 232, 234, 235, 236, 238, 239, 240, 241, 242, 243, 246, 247, 250, 252, 253, 256, 258, 259, 260, 263, 264, 265, 266, 267, 268, 269, 271, 272, 274, 275]\n[0, 1, 2, 3, 4, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 27, 29, 31, 32, 33, 35, 38, 40, 41, 43, 44, 45, 48, 49, 50, 53, 54, 55, 58, 59, 61, 62, 63, 64, 65, 66, 67, 68, 70, 71, 73, 74, 76, 78, 83, 85, 86, 90, 91, 92, 93, 94, 95, 97, 99, 101, 102, 103, 107, 110, 112, 114, 116, 117, 118, 121, 122, 123, 124, 126, 129, 130, 131, 132, 133, 134, 136, 138, 140, 141, 142, 143, 144, 145, 146, 147, 148, 150, 151, 154, 155, 156, 158, 160, 161, 162, 163, 165, 166, 168, 169, 170, 172, 175, 176, 177, 179, 180, 182, 183, 184, 185, 186, 187, 191, 195, 197, 198, 199, 200, 201, 202, 204, 205, 206, 207, 208, 210, 211, 213, 214, 215, 216, 218, 219, 221, 222, 223, 224, 227, 228, 229, 230, 231, 232, 235, 236, 238, 239, 240, 241, 242, 243, 244, 245, 246, 250, 251, 253, 254, 255, 256, 258, 260, 263, 264, 265, 266, 268, 270, 271, 272, 275, 277]\n[3, 4, 5, 6, 8, 9, 10, 13, 14, 16, 17, 18, 19, 20, 21, 22, 24, 26, 27, 28, 29, 30, 31, 33, 34, 35, 37, 38, 39, 40, 41, 43, 44, 45, 47, 50, 51, 52, 53, 54, 57, 59, 63, 64, 65, 66, 67, 68, 70, 71, 75, 76, 77, 79, 80, 81, 83, 84, 85, 86, 87, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 104, 105, 106, 109, 113, 115, 119, 120, 122, 124, 125, 127, 128, 129, 130, 131, 134, 135, 136, 137, 139, 142, 143, 144, 145, 146, 147, 148, 149, 151, 152, 154, 155, 159, 166, 167, 168, 170, 171, 172, 174, 175, 176, 178, 179, 180, 182, 183, 185, 186, 188, 189, 190, 191, 192, 193, 194, 196, 197, 198, 199, 200, 201, 202, 204, 206, 208, 209, 211, 213, 214, 216, 220, 221, 223, 225, 226, 227, 228, 229, 231, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 246, 247, 249, 250, 252, 253, 255, 256, 258, 260, 261, 262, 263, 265, 267, 268, 271, 272, 274, 276]\n[0, 3, 7, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 30, 31, 33, 34, 38, 40, 41, 44, 45, 46, 47, 49, 52, 53, 55, 59, 61, 63, 64, 65, 66, 67, 69, 71, 72, 73, 74, 75, 76, 78, 79, 80, 81, 85, 88, 89, 91, 92, 93, 95, 97, 98, 99, 100, 101, 105, 106, 107, 109, 110, 111, 112, 114, 116, 118, 120, 121, 122, 123, 125, 126, 127, 128, 129, 131, 133, 135, 136, 137, 139, 140, 141, 142, 143, 145, 147, 151, 153, 154, 155, 156, 158, 159, 160, 161, 162, 163, 165, 166, 167, 170, 171, 173, 175, 178, 179, 180, 183, 186, 187, 188, 190, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 203, 204, 205, 208, 209, 211, 212, 213, 216, 217, 218, 219, 221, 223, 225, 226, 228, 232, 235, 236, 237, 238, 242, 243, 244, 245, 246, 247, 248, 250, 251, 252, 253, 254, 255, 256, 258, 259, 260, 261, 262, 263, 264, 265, 267, 268, 269, 270, 272, 275, 276, 277]\n[0, 2, 4, 6, 7, 9, 10, 11, 12, 17, 18, 19, 21, 23, 24, 25, 26, 28, 30, 31, 34, 35, 37, 38, 40, 41, 43, 44, 45, 48, 49, 50, 51, 52, 54, 55, 57, 58, 59, 60, 62, 64, 67, 69, 70, 73, 74, 75, 76, 77, 82, 83, 84, 85, 86, 87, 88, 89, 91, 92, 94, 96, 97, 99, 100, 102, 104, 105, 106, 107, 109, 110, 111, 112, 113, 115, 116, 117, 118, 119, 120, 121, 122, 123, 127, 129, 130, 132, 133, 134, 135, 136, 137, 139, 141, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 158, 159, 162, 163, 168, 169, 171, 172, 174, 177, 178, 181, 184, 185, 188, 189, 192, 194, 197, 198, 199, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 212, 214, 215, 216, 217, 218, 219, 220, 221, 222, 224, 226, 229, 231, 233, 234, 235, 236, 237, 239, 241, 242, 244, 246, 247, 248, 251, 252, 253, 255, 256, 258, 259, 260, 262, 264, 265, 267, 268, 269, 270, 271, 272, 273, 274, 276, 277]\n[0, 2, 4, 7, 11, 12, 13, 14, 15, 16, 17, 19, 21, 22, 23, 24, 25, 31, 34, 36, 37, 38, 39, 42, 44, 45, 48, 49, 50, 51, 53, 55, 56, 57, 58, 59, 60, 61, 64, 65, 66, 67, 69, 70, 71, 72, 73, 76, 78, 79, 80, 81, 83, 84, 86, 87, 88, 89, 90, 91, 92, 96, 97, 98, 102, 103, 105, 108, 109, 112, 113, 117, 118, 119, 120, 121, 122, 124, 125, 126, 127, 128, 130, 134, 135, 137, 138, 139, 141, 146, 147, 148, 150, 151, 154, 155, 156, 157, 158, 159, 161, 162, 163, 167, 168, 169, 170, 172, 173, 175, 176, 177, 178, 181, 182, 184, 185, 186, 188, 190, 192, 193, 194, 195, 198, 199, 200, 202, 203, 204, 205, 206, 207, 208, 209, 212, 213, 215, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 235, 237, 238, 239, 241, 242, 243, 244, 245, 246, 247, 248, 249, 252, 253, 254, 257, 258, 259, 260, 263, 264, 265, 266, 267, 268, 269, 271, 272, 273, 274, 275, 276]\n[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 14, 15, 16, 17, 20, 21, 22, 25, 30, 31, 33, 34, 35, 37, 38, 39, 40, 42, 43, 46, 48, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 63, 64, 67, 71, 72, 73, 74, 76, 77, 78, 80, 81, 84, 85, 87, 89, 90, 93, 95, 96, 97, 99, 100, 102, 104, 107, 108, 109, 110, 111, 112, 114, 116, 118, 119, 121, 122, 123, 124, 125, 127, 128, 129, 130, 131, 132, 133, 135, 137, 138, 140, 141, 142, 143, 144, 145, 147, 148, 149, 151, 153, 154, 155, 159, 162, 163, 164, 165, 166, 168, 169, 172, 174, 178, 180, 181, 182, 183, 184, 185, 187, 189, 191, 192, 193, 195, 196, 197, 199, 200, 201, 202, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 217, 218, 219, 221, 223, 224, 227, 229, 230, 232, 233, 234, 235, 237, 240, 241, 242, 244, 245, 248, 249, 252, 253, 254, 256, 257, 259, 260, 261, 262, 264, 266, 267, 268, 270, 271, 272, 274, 275, 276, 277]\n[2, 3, 4, 6, 7, 8, 10, 11, 12, 14, 17, 18, 19, 23, 25, 27, 28, 29, 30, 31, 32, 34, 35, 37, 38, 39, 40, 41, 43, 44, 45, 46, 48, 49, 50, 52, 53, 55, 56, 59, 61, 63, 64, 65, 66, 67, 71, 74, 77, 78, 79, 80, 82, 83, 84, 85, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 99, 100, 104, 105, 106, 107, 108, 109, 110, 111, 113, 114, 115, 116, 117, 118, 120, 121, 122, 124, 125, 128, 129, 130, 131, 133, 134, 135, 136, 138, 139, 140, 142, 143, 145, 147, 148, 150, 151, 152, 154, 155, 156, 159, 160, 161, 162, 164, 166, 167, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 183, 185, 187, 188, 190, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 204, 207, 210, 211, 212, 214, 217, 219, 220, 221, 223, 226, 227, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 242, 244, 245, 246, 249, 250, 252, 254, 256, 257, 258, 261, 262, 265, 266, 267, 269, 271, 272, 276]\n[0, 4, 5, 6, 7, 8, 10, 11, 12, 14, 16, 18, 19, 20, 21, 23, 26, 28, 29, 31, 33, 34, 35, 36, 38, 39, 40, 42, 43, 45, 47, 48, 50, 51, 52, 53, 54, 57, 58, 60, 61, 62, 63, 64, 65, 68, 69, 70, 72, 73, 74, 75, 76, 77, 78, 81, 83, 84, 86, 87, 89, 90, 91, 94, 95, 97, 98, 99, 100, 105, 106, 108, 110, 111, 112, 113, 114, 118, 119, 120, 121, 124, 125, 126, 127, 128, 131, 132, 135, 136, 137, 138, 139, 141, 142, 146, 148, 150, 151, 152, 153, 156, 157, 158, 161, 165, 166, 167, 168, 169, 170, 171, 173, 174, 177, 178, 180, 182, 183, 184, 186, 187, 188, 189, 191, 194, 195, 196, 197, 199, 200, 203, 204, 205, 206, 207, 208, 211, 216, 217, 218, 219, 220, 221, 222, 223, 224, 226, 227, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 241, 243, 244, 247, 248, 249, 250, 251, 252, 255, 256, 257, 259, 260, 261, 262, 263, 264, 265, 267, 270, 271, 272, 273, 274, 276, 277]\n[0, 2, 4, 5, 6, 7, 8, 10, 12, 16, 18, 19, 20, 22, 23, 26, 27, 29, 30, 31, 34, 36, 37, 38, 39, 41, 43, 44, 45, 46, 47, 51, 52, 53, 54, 55, 57, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 74, 76, 77, 78, 79, 80, 81, 82, 83, 84, 86, 87, 90, 92, 93, 94, 95, 97, 99, 100, 103, 104, 106, 109, 110, 111, 113, 114, 115, 116, 120, 121, 124, 125, 128, 129, 131, 132, 133, 134, 135, 137, 138, 140, 143, 144, 147, 148, 149, 151, 153, 154, 155, 156, 158, 163, 164, 165, 166, 167, 169, 170, 171, 174, 175, 176, 177, 179, 180, 181, 182, 183, 184, 185, 186, 189, 190, 191, 192, 193, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 217, 218, 219, 220, 222, 223, 225, 229, 232, 233, 236, 237, 238, 240, 242, 243, 244, 246, 247, 249, 253, 254, 255, 256, 257, 258, 259, 262, 263, 264, 265, 266, 269, 271, 273, 274, 275, 276, 277]\n"
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=20, test_size=0.33, random_state=42)\n",
    "\n",
    "print(sss)\n",
    "\n",
    "for train_index, test_index in sss.split(X, y):\n",
    "    # print(\"TRAIN size:\", len(train_index), \"TEST size:\", len(test_index))\n",
    "    # X_train, X_test = X[train_index], X[test_index]\n",
    "    # y_train, y_test = y[train_index], y[test_index]\n",
    "    print(sorted(train_index))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function that builds the CNN for the gridsearch. Each layer is a Conv1D and a maxpool. Each layer reduce the second axis dimension of a factor 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nreshape (Reshape)            (None, 3000, 1)           0         \n_________________________________________________________________\nmax_pooling1d (MaxPooling1D) (None, 200, 1)            0         \n_________________________________________________________________\nkeras_preprocess (KerasPrepr (None, 200, 1)            0         \n_________________________________________________________________\nconv1d (Conv1D)              (None, 200, 10)           510       \n_________________________________________________________________\nmax_pooling1d_1 (MaxPooling1 (None, 100, 10)           0         \n_________________________________________________________________\nconv1d_1 (Conv1D)            (None, 100, 10)           5010      \n_________________________________________________________________\nmax_pooling1d_2 (MaxPooling1 (None, 50, 10)            0         \n_________________________________________________________________\nflatten (Flatten)            (None, 500)               0         \n_________________________________________________________________\ndense (Dense)                (None, 1)                 501       \n=================================================================\nTotal params: 6,021\nTrainable params: 6,021\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "%run imports/VacuumGauge_functions.ipynb\n",
    "keras.backend.clear_session()\n",
    "\n",
    "METRICS = [\n",
    "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      keras.metrics.Precision(name='precision'),\n",
    "      keras.metrics.Recall(name='recall')\n",
    "]\n",
    "\n",
    "def build_CNN(layers=1, filters=32, kernel_size=10, metrics=METRICS):\n",
    "    \n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Reshape((3000, 1), input_shape=[3000]))\n",
    "    model.add(keras.layers.MaxPool1D(pool_size=15, strides=15, padding='same'))\n",
    "    # model.add(keras.layers.Lambda(lambda X: preprocess(X)))\n",
    "    model.add(KerasPreprocess())\n",
    "\n",
    "    for layer in range(layers):\n",
    "        model.add(keras.layers.Conv1D(filters=filters, kernel_size=kernel_size,\n",
    "                                      activation='relu', strides=1, input_shape = [None, 1],\n",
    "                                      padding='same', use_bias=True, kernel_initializer='he_normal',\n",
    "                                      ))\n",
    "        model.add(keras.layers.MaxPool1D(pool_size=2, padding='same'))\n",
    "\n",
    "    \n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "    # learning_rate = keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=0.1,\n",
    "    #                                                             decay_steps= batch_size ,\n",
    "    #                                                             decay_rate=0.1)\n",
    "    optimizer = keras.optimizers.Nadam(learning_rate=1e-5)\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=metrics)\n",
    "    return model\n",
    "\n",
    "model = build_CNN(layers=2, filters=10, kernel_size=50)\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tf.Tensor: shape=(278, 3000), dtype=float32, numpy=\narray([[9.6999998e-11, 9.9568992e-11, 1.0213799e-10, ..., 5.9617374e-11,\n        5.9808686e-11, 5.9999998e-11],\n       [2.5000000e-09, 2.4698676e-09, 2.4397353e-09, ..., 7.3000002e-09,\n        7.3000002e-09, 7.3000002e-09],\n       [1.5000000e-09, 1.5126027e-09, 1.5252055e-09, ..., 4.6612665e-09,\n        4.6306332e-09, 4.5999999e-09],\n       ...,\n       [2.2999999e-11, 2.2726784e-11, 2.2999999e-11, ..., 1.9499987e-11,\n        1.9749993e-11, 2.0000000e-11],\n       [2.9999999e-11, 2.9999999e-11, 2.9999999e-11, ..., 3.2000000e-11,\n        3.2000000e-11, 3.1000001e-11],\n       [1.2000000e-11, 1.2000000e-11, 1.2000000e-11, ..., 1.2000000e-11,\n        1.2000000e-11, 1.2000000e-11]], dtype=float32)>"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "X[0]\n",
    "tf.constant(X, dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "StratifiedShuffleSplit(n_splits=10, random_state=42, test_size=0.33,\n            train_size=None)\nIteration 1 of 10\nIteration 2 of 10\nIteration 3 of 10\nIteration 4 of 10\nIteration 5 of 10\nIteration 6 of 10\nIteration 7 of 10\nIteration 8 of 10\nIteration 9 of 10\nIteration 10 of 10\n"
    }
   ],
   "source": [
    "model = build_CNN(layers=2, filters=10, kernel_size=50)\n",
    "epochs = 300\n",
    "run_log_dir = get_run_logdir('cnn')\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_log_dir)\n",
    "#model.run_eagerly = False\n",
    "sss = StratifiedShuffleSplit(n_splits=10, random_state=42, test_size=0.33)\n",
    "print(sss)\n",
    "\n",
    "for index, (train_index, test_index) in enumerate(sss.split(X, y)):\n",
    "\n",
    "\n",
    "    print('Iteration {} of {}'.format(index + 1, sss.get_n_splits()))\n",
    "\n",
    "    X_train, X_test = tf.constant(X[train_index], dtype='float32'), tf.constant(X[test_index], dtype='float32')\n",
    "    y_train, y_test = tf.constant(y[train_index], dtype='float32'), tf.constant(y[test_index], dtype='float32')\n",
    "\n",
    "    model = build_CNN(layers=2, filters=10, kernel_size=50)\n",
    "    history = model.fit(X_train, y_train,\n",
    "                        epochs=epochs, verbose=0, batch_size=32,\n",
    "                        validation_data=(X_test, y_test))\n",
    "    if index == 0:\n",
    "        results = {item: [] for item in history.history}\n",
    "\n",
    "    for key in history.history.keys():\n",
    "        results[key].append(history.history[key][-1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "loss = 0.11 +/- 0.03\naccuracy = 0.97 +/- 0.01\nprecision = 0.98 +/- 0.02\nrecall = 0.96 +/- 0.02\nval_loss = 0.15 +/- 0.04\nval_accuracy = 0.95 +/- 0.02\nval_precision = 0.96 +/- 0.03\nval_recall = 0.94 +/- 0.03\n"
    }
   ],
   "source": [
    "for key in results.keys():\n",
    "    print('{} = {:.2f} +/- {:.2f}'.format(key, np.mean(results[key]), np.std(results[key])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = 'data/models/cnn'\n",
    "model_version = 'cnn_005.h5'\n",
    "model_csv = 'cnn_005.csv'\n",
    "cv_result = pd.DataFrame(results)\n",
    "cv_result.to_csv(os.path.join(model_dir, model_csv),  index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "loss = 0.10 +/- 0.03\naccuracy = 0.97 +/- 0.01\nprecision = 0.98 +/- 0.01\nrecall = 0.96 +/- 0.01\nval_loss = 0.14 +/- 0.04\nval_accuracy = 0.96 +/- 0.02\nval_precision = 0.96 +/- 0.02\nval_recall = 0.95 +/- 0.02\n"
    }
   ],
   "source": [
    "for key in cv_result:\n",
    "    \n",
    "    print('{} = {:.2f} +/- {:.2f}'.format(key, np.mean(results[key]), np.std(results[key])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#early_stopping_cb = keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)\n",
    "def exponential_decay(lr0, s):\n",
    "    def exponential_decay_fn(epoch):\n",
    "        return lr0 * 0.1**(epoch/s)\n",
    "    return exponential_decay_fn\n",
    "\n",
    "exponential_decay_fn = exponential_decay(lr0=1e-5, s=-17)    \n",
    "epochs = 500\n",
    "run_log_dir = get_run_logdir('cnn')\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_log_dir)  \n",
    "\n",
    "lr = [exponential_decay_fn(epoch) for epoch in range(100)]\n",
    "lr_scheduler = keras.callbacks.LearningRateScheduler(exponential_decay_fn)\n",
    "epochs = 100\n",
    "class_weight = {0: 1.,\n",
    "                1: 1.}\n",
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=epochs, verbose=1, class_weight=class_weight,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    callbacks= [lr_scheduler, tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(lr, history.history['val_loss'])\n",
    "plt.xlim(1e-5, 1e-1)\n",
    "plt.xscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "y_pred = grid_search.best_estimator_.predict(X_test)\n",
    "\n",
    "# y_pred = np.round(y_pred)\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(recall_score(y_test, y_pred))\n",
    "print(precision_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "model = build_CNN(layers=2, filters=10, kernel_size=50)\n",
    "cnn_clf = keras.wrappers.scikit_learn.KerasClassifier(build_CNN)\n",
    "\n",
    "model = cnn_clf\n",
    "model_dir = 'data/models/cnn'\n",
    "model_version = 'cnn_004.h5'\n",
    "model_csv = 'cnn_004.csv'\n",
    "scoring = ['recall', 'accuracy', 'precision']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "param_grid = [\n",
    "    {'layers': [1, 2],\n",
    "     'filters' : [10], \n",
    "     'kernel_size' : [50, 80, 100]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras.backend.clear_session()\n",
    "\n",
    "print(\"# Tuning hyper-parameters for {} and {}\".format(scoring[0], scoring[1]))\n",
    "print()\n",
    "results = cross_validate(\n",
    "    estimator=model, \n",
    "    X = X,\n",
    "    y = y,\n",
    "    scoring=scoring,\n",
    "    n_jobs=-1,\n",
    "    verbose=1, \n",
    "    cv=strat_kfold,\n",
    "    epochs=300,\n",
    "    return_train_score=True,\n",
    "    # refit=scoring[0]  ## Score used for final refit\n",
    ")\n",
    "\n",
    "# grid_search.fit(X, y, epochs=300, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(model, 'model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = tf.data.Dataset.from_tensor_slices((tf.constant(X_train), tf.constant(y_train)))\n",
    "val_set = tf.data.Dataset.from_tensor_slices((tf.constant(X_test), tf.constant(y_test)))\n",
    "for item in train_set.batch(32).take(3):\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printGridSearchResults(grid_search, scoring[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_result = pd.DataFrame(grid_search.cv_results_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_result.to_csv(os.path.join(model_dir, model_csv),  index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_estimator_.model.save(os.path.join(model_dir, model_version))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.read_csv('data/datasets/df_raw.csv')\n",
    "df_raw = df_raw[df_raw.fillNumber != 2011]\n",
    "\n",
    "df_raw = df_raw.astype({'fillNumber': 'int'})\n",
    "df_raw = df_raw.set_index(['gauge_id','fillNumber'], drop=True)\n",
    "df_raw.index.get_level_values('fillNumber').value_counts()\n",
    "\n",
    "\n",
    "kmeans_centers_path = 'data/datasets/k12_centers.npy'\n",
    "silhouette_scores_path = 'data/datasets/silhouette_scores_range_2_20.npy'\n",
    "inertias_path = 'data/datasets/intertias_range_2_20.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "scaler = RowScaler(scaling_method='Standard')\n",
    "Xu_scaled = scaler.fit_transform(df_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(kmeans_centers_path):\n",
    "    k12_centers = np.load(kmeans_centers_path)\n",
    "    print('KMeans center loaded.')\n",
    "else:\n",
    "    print('Recomputing KMeans...')\n",
    "    kmeans_per_k = [KMeans(n_clusters=k,\n",
    "                                    algorithm='elkan',\n",
    "                                    random_state=42,\n",
    "                                    n_jobs=-1,\n",
    "                                    verbose=2\n",
    "                                    ).fit(X_scaled)\n",
    "                    for k in range(2, 20)]\n",
    "    k12_centers = np.array(kmeans_per_k[12 -2].cluster_centers_)\n",
    "    np.save('data/datasets/k12_centers.npy', k12_centers)\n",
    "\n",
    "\n",
    "\n",
    "if os.path.exists(inertias_path):\n",
    "    inertias = np.load(inertias_path)\n",
    "    print('inertias loaded.')\n",
    "else:\n",
    "    inertias = [model.inertia_ for model in kmeans_per_k]\n",
    "    np.save(inertias_path, inertias)\n",
    "    print('inertias saved.')\n",
    "\n",
    "if os.path.exists(silhouette_scores_path):\n",
    "    silhouette_scores = np.load(silhouette_scores_path)\n",
    "    print('silhouette loaded')\n",
    "else:\n",
    "    silhouette_scores = [silhouette_score(X_scaled, model.labels_)\n",
    "                         for model in kmeans_per_k]\n",
    "    np.save(silhouette_scores_path, silhouette_scores)\n",
    "    print('silhouette saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 3.5))\n",
    "plt.plot(range(2, 20), inertias, \"bo-\")\n",
    "plt.xlabel(\"$k$\", fontsize=14)\n",
    "plt.ylabel(\"Inertia\", fontsize=14)\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 3))\n",
    "plt.plot(range(2, 20), silhouette_scores, \"bo-\")\n",
    "plt.xlabel(\"$k$\", fontsize=14)\n",
    "plt.xlim(10,15)\n",
    "plt.ylim(0.16, 0.19)\n",
    "plt.ylabel(\"Silhouette score\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_samples\n",
    "from matplotlib.ticker import FixedLocator, FixedFormatter\n",
    "\n",
    "plt.figure(figsize=(11, 9))\n",
    "\n",
    "for k in (10, 11, 12, 13):\n",
    "    plt.subplot(2, 2, k - 9)\n",
    "    \n",
    "    y_pred = kmeans_per_k[k - 2].labels_\n",
    "    silhouette_coefficients = silhouette_samples(X_scaled, y_pred)\n",
    "\n",
    "    padding = len(X_scaled) // 30\n",
    "    pos = padding\n",
    "    ticks = []\n",
    "    for i in range(k):\n",
    "        coeffs = silhouette_coefficients[y_pred == i]\n",
    "        coeffs.sort()\n",
    "\n",
    "        color = mpl.cm.Spectral(i / k)\n",
    "        plt.fill_betweenx(np.arange(pos, pos + len(coeffs)), 0, coeffs,\n",
    "                          facecolor=color, edgecolor=color, alpha=0.7)\n",
    "        ticks.append(pos + len(coeffs) // 2)\n",
    "        pos += len(coeffs) + padding\n",
    "\n",
    "    plt.gca().yaxis.set_major_locator(FixedLocator(ticks))\n",
    "    plt.gca().yaxis.set_major_formatter(FixedFormatter(range(k)))\n",
    "    if k in (10, 12):\n",
    "        plt.ylabel(\"Cluster\")\n",
    "    \n",
    "    if k in (12, 13):\n",
    "        plt.gca().set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "        plt.xlabel(\"Silhouette Coefficient\")\n",
    "    else:\n",
    "        plt.tick_params(labelbottom=False)\n",
    "\n",
    "    plt.axvline(x=silhouette_scores[k - 2], color=\"red\", linestyle=\"--\")\n",
    "    plt.title(\"$k={}$\".format(k), fontsize=16)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(kmeans_per_k[12 -2].cluster_centers_)\n",
    "k12_centers.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k12_centers = np.load('data/datasets/k12_centers.npy')\n",
    "for c in k12_centers:\n",
    "    plt.plot(range(3000), c)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "d_max = np.max(euclidean_distances(k12_centers, k12_centers))\n",
    "keras.backend.clear_session()\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Lambda(lambda X: rowScale(X), input_shape=[3000]))\n",
    "model.add(RBFLayer(12,\n",
    "                    initializer=InitFromFile('data/datasets/k12_centers.npy'),\n",
    "                    betas=d_max/np.sqrt(len(k12_centers)),\n",
    "                    trainable=False,\n",
    "                    input_shape=[3000])\n",
    "                    )\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "model.add(keras.layers.Lambda(lambda X: tf.round(X)))\n",
    "\n",
    "optimizer = keras.optimizers.Adam()\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=[keras.metrics.Recall()])\n",
    "\n",
    "model.summary()\n",
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X, y, epochs=5, validation_split=0.33, verbose=1)\n",
    "y_pred = model.predict(X[-50:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "11 // 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "domande:\n",
    "devo abilitare il training sul layer RBF? iniziamo senza farlo\n",
    "definire modelli finali: pca solo su training, kmeans su tutto unlabelled\n",
    "train - val- test split, va bene? No usiamo solo k fold\n",
    "quante fold nel k fold? meglio 10\n",
    "perche RNN cosi lenta?"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}