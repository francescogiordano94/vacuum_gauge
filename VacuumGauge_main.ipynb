{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "./data/logs already exist.\n"
    }
   ],
   "source": [
    "%run imports/VacuumGauge_functions.ipynb\n",
    "%run imports/rbflayer.py\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "root_logdir = os.path.join(os.curdir, 'data/logs')\n",
    "\n",
    "if not(os.path.exists(root_logdir)):\n",
    "    !mkdir -p {root_logdir}\n",
    "    print('{} succesfully created.'.format(root_logdir))\n",
    "else:\n",
    "    print('{} already exist.'.format(root_logdir))\n",
    "\n",
    "def get_run_logdir(model_version):\n",
    "    import time\n",
    "    run_id = time.strftime('{}_run_%Y_%m_%d-%H_%M_%S'.format(model_version))\n",
    "    return os.path.join(root_logdir, run_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorboard starting -- (only if needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": "\n      <iframe id=\"tensorboard-frame-43b83180e074e764\" width=\"100%\" height=\"800\" frameborder=\"0\">\n      </iframe>\n      <script>\n        (function() {\n          const frame = document.getElementById(\"tensorboard-frame-43b83180e074e764\");\n          const url = new URL(\"/\", window.location);\n          url.port = 6006;\n          frame.src = url;\n        })();\n      </script>\n  ",
      "text/plain": "<IPython.core.display.HTML object>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir={root_logdir} --port=6006"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the dataset\n",
    "\n",
    "- df_ok: labels of ok gauges\n",
    "- df_delta: labels of delta gauges\n",
    "- df_ raw: raw data cointaining the full reading of each gauge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_delta = pd.read_csv('data/datasets/df_delta.csv') # cointains labels for delta VG\n",
    "df_ok = pd.read_csv('data/datasets/df_ok.csv')  #contains labels for ok VG\n",
    "\n",
    "df_raw = pd.read_csv('data/datasets/df_raw.csv') ## contains full reading of each VG\n",
    "\n",
    "df_labels = pd.concat([df_ok, df_delta], sort=False, axis=0)\n",
    "\n",
    "\n",
    "df_VG = pd.merge(df_raw, df_labels, on =['gauge_id','fillNumber'])\n",
    "df_VG = df_VG.set_index(['gauge_id','fillNumber'], drop=True)\n",
    "\n",
    "## Removing categorical values\n",
    "df_VG.y.replace(to_replace=['ok', 'delta'], value=[0, 1], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the dataset in input and target\n",
    "- X are the input features\n",
    "- y is the target vector\n",
    "\n",
    "Definition of a StratifiedKFold split to be used in all the grid searchs for all the model: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(df_VG.iloc[:, :-1])\n",
    "y = np.array(df_VG.iloc[:, -1])\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "strat_kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hold out a test set for final evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "\n",
    "# sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "\n",
    "# print(sss)\n",
    "\n",
    "# for train_index, test_index in sss.split(X, y):\n",
    "#     print(\"TRAIN size:\", len(train_index), \"TEST size:\", len(test_index))\n",
    "#     X_train, X_test = X[train_index], X[test_index]\n",
    "#     y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "\n",
    "# print(len(y_train))\n",
    "# print(sum(y_train))\n",
    "# print(len(y_test))\n",
    "# print(sum(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "The preprocessing of the input is divided in 3 steps:\n",
    "\n",
    "1. Max pooling layer with kernel 15 and strides 15: reduce the dimensionality of a factor 15 keeping the max values, it preserve the interesting part of the signal\n",
    "2. Median filter with kernel 9 to get rid of evenutally present white noise\n",
    "3. Savitzkyâ€“Golay filter to further reduce discontinuities\n",
    "4. Scaling of each time series to help gradient descent converge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "from skimage.measure import block_reduce\n",
    "\n",
    "## Tensorflow implementation of max_pool\n",
    "\n",
    "# X_max = X.reshape((X.shape[0], 3000, 1))  \n",
    "# X_max = tf.nn.max_pool1d(X_max, ksize=15, strides=15, padding='VALID')\n",
    "# X_max = X_max[...,0]\n",
    "\n",
    "## Numpy implementation of max_pool\n",
    "\n",
    "X_max = block_reduce(X, block_size=(1,15), func=np.max)\n",
    "\n",
    "\n",
    "X_med = np.apply_along_axis(scipy.signal.medfilt, axis=1, arr= X_max, kernel_size=9)\n",
    "X_sav = np.apply_along_axis(scipy.signal.savgol_filter, axis=1,\n",
    "                            arr= X_med, window_length=11, polyorder=2)\n",
    "scaler = RowScaler(scaling_method='Standard')\n",
    "\n",
    "pca = PCA(n_components=30)\n",
    "X_norm = scaler.fit_transform(X_sav)\n",
    "X_pca = pca.fit_transform(X_norm)\n",
    "\n",
    "\n",
    "\n",
    "# X_f = np.fft.fft(X_avg, X_avg.shape[-1])\n",
    "# X_f = np.fft.fftshift(X_f, axes=-1)\n",
    "X_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# g = np.gradient(X_norm, axis=1)\n",
    "# for i in range(0, 20, 1):\n",
    "#     plt.plot(X_norm[i])\n",
    "#     plt.plot(g[i]/np.max(g[i]))\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "for i in range(0,12):\n",
    "    plt.subplot(4,1,1)\n",
    "    plt.plot(X[i])\n",
    "    plt.subplot(4,1,2)\n",
    "    plt.plot(X_med[i])\n",
    "    plt.subplot(4,1,3)\n",
    "    plt.plot(X_sav[i])\n",
    "    plt.subplot(4,1,4)\n",
    "    plt.plot(g[i])\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick overview on the PCA impact\n",
    "\n",
    "PCA performed on the trainig part of the normalised dataset to visualize its impact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scaler = RowScaler('Standard')\n",
    "# X_norm = scaler.fit_transform(X)\n",
    "# X_norm[0].shape\n",
    "\n",
    "i=100\n",
    "X_m = scaler.fit_transform(X) - scaler.fit_transform(X).mean(axis=0, keepdims=0)\n",
    "plt.figure()\n",
    "plt.plot(range(3000), scaler.fit_transform(X)[i])\n",
    "plt.plot(range(3000), X_m[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess = Prepocess(log_scale=False)\n",
    "scaler = RowScaler('Standard')\n",
    "\n",
    "pca = PCA(n_components=3)\n",
    "\n",
    "\n",
    "X_pca = pca.fit_transform(scaler.fit_transform(preprocess.fit_transform(X)))\n",
    "# X_pca = pca.fit_transform(scaler.fit_transform(X))\n",
    "X_pca[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "fontsize=15\n",
    "\n",
    "ok = X_pca[y==0]\n",
    "delta = X_pca[y ==1]\n",
    "\n",
    "\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "fontsize=20\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.scatter(ok[:,0], ok[:,1], c='b', label='no heating', s=50)\n",
    "plt.scatter(delta[:,0], delta[:,1], c='r', label='heating', s=50)\n",
    "\n",
    "plt.legend(fontsize=fontsize)\n",
    "plt.xlabel('component #1', fontsize=fontsize)\n",
    "plt.ylabel('component #2', fontsize=fontsize)\n",
    "plt.tick_params(axis='both', which='major', labelsize=fontsize)\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "fig = plt.figure(figsize=(10,8))\n",
    "ax = Axes3D(fig)\n",
    "\n",
    "ax.scatter(ok[:,0], ok[:,1], ok[:,2], c='b', label='no heating', s=50)\n",
    "ax.scatter(delta[:,0], delta[:,1], delta[:,2], c='r', label='heating', s=50)\n",
    "\n",
    "ax.set_xlabel('component #1', fontsize=fontsize)\n",
    "ax.set_ylabel('component #2', fontsize=fontsize)\n",
    "ax.set_zlabel('component #3', fontsize=fontsize)\n",
    "\n",
    "# ax.set_xlim(-25,30)\n",
    "# ax.set_ylim(-5,20)\n",
    "# ax.set_zlim(-10,7.5)\n",
    "plt.gca().patch.set_facecolor('white')\n",
    "plt.tick_params(axis='both', which='major', labelsize=fontsize)\n",
    "plt.legend(fontsize=fontsize)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = np.where(np.all([y == 1, X_pca[:,0]>5], axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-MEANS preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import KernelPCA\n",
    "from sklearn.manifold import LocallyLinearEmbedding\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "preprocess = Prepocess(log_scale=False)\n",
    "scaler = RowScaler('Standard')\n",
    "\n",
    "kmeans = KMeans(n_clusters=3,\n",
    "                algorithm='elkan',\n",
    "                random_state=42)\n",
    "lle = LocallyLinearEmbedding(n_components=3, n_neighbors= 10)\n",
    "rbf_pca = KernelPCA(n_components=3, kernel='rbf', gamma=0.005)\n",
    "tsne = TSNE(n_components=3, perplexity=20)\n",
    "a = preprocess.fit_transform(X)\n",
    "b = scaler.fit_transform(a)\n",
    "d = kmeans.fit_transform(b)\n",
    "# d = rbf_pca.fit_transform(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for center in kmeans.cluster_centers_:\n",
    "#     plt.plot(range(200), center)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "ok = d[y==0]\n",
    "delta = d[y ==1]\n",
    "\n",
    "\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "fontsize=20\n",
    "plt.close('all')\n",
    "plt.figure(figsize=(10,8))\n",
    "plt.scatter(ok[:,0], ok[:,1], c='b', label='no heating', s=50)\n",
    "plt.scatter(delta[:,0], delta[:,1], c='r', label='heating', s=50)\n",
    "\n",
    "plt.legend(fontsize=fontsize)\n",
    "plt.xlabel('component #1', fontsize=fontsize)\n",
    "plt.ylabel('component #2', fontsize=fontsize)\n",
    "plt.tick_params(axis='both', which='major', labelsize=fontsize)\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "fig = plt.figure(figsize=(10,8))\n",
    "ax = Axes3D(fig)\n",
    "\n",
    "ax.scatter(ok[:,0], ok[:,1], ok[:,2], c='b', label='no heating', s=50)\n",
    "ax.scatter(delta[:,0], delta[:,1], delta[:,2], c='r', label='heating', s=50)\n",
    "\n",
    "ax.set_xlabel('component #1', fontsize=fontsize)\n",
    "ax.set_ylabel('component #2', fontsize=fontsize)\n",
    "ax.set_zlabel('component #3', fontsize=fontsize)\n",
    "\n",
    "# ax.set_xlim(-25,30)\n",
    "# ax.set_ylim(-5,20)\n",
    "# ax.set_zlim(-10,7.5)\n",
    "plt.gca().patch.set_facecolor('white')\n",
    "plt.tick_params(axis='both', which='major', labelsize=fontsize)\n",
    "plt.legend(fontsize=fontsize)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest_clf = Pipeline([\n",
    "    ('preprocessor', Prepocess()),\n",
    "    ('scaler', RowScaler(scaling_method='Standard')),\n",
    "    ('kmeans', KMeans(algorithm='elkan',random_state=42)),\n",
    "    ('forest', RandomForestClassifier())\n",
    "\n",
    "])\n",
    "\n",
    "model = forest_clf\n",
    "model_dir = 'data/models/random_forest'\n",
    "model_version = 'forest_006.pkl'\n",
    "scoring = ['recall', 'accuracy', 'precision']\n",
    "\n",
    "forest_path = os.path.join(model_dir, model_version)\n",
    "\n",
    "print(os.path.join(model_dir,model_version))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "a = Real(2,100, prior='log-uniform')\n",
    "# b = Real(1,100)\n",
    "X = range(1,1000)\n",
    "plt.plot((sorted(a.rvs(100))))\n",
    "# plt.plot(sorted(b.rvs(1000)))\n",
    "print(np.max(a.transform(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(range(30,51, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "\n",
    "param_grid = [\n",
    "    {\n",
    "    #  'scaler__scaling_method': RowScaler().scaling_options,\n",
    "     'kmeans__n_clusters': [10, 30, 100],\n",
    "     'preprocessor__log_scale': [False],\n",
    "     'forest__n_estimators': [50, 100, 150],\n",
    "     'forest__max_leaf_nodes': [2, 3, 4],\n",
    "     'forest__bootstrap': [False],\n",
    "    }\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"# Tuning hyper-parameters for {} and {}\".format(scoring[0], scoring[1]))\n",
    "print()\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=model, \n",
    "    param_grid=param_grid, \n",
    "    scoring=scoring,\n",
    "    n_jobs=-1,\n",
    "    verbose=1, \n",
    "    cv=strat_kfold, \n",
    "    return_train_score=True,\n",
    "    refit=scoring[1]  ## Score used for final refit\n",
    ")\n",
    "\n",
    "grid_search.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printGridSearchResults(grid_search, scoring[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(grid_search, model_dir, model_version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regressor (classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "data/models/logistic_classifier/logistic_004.pkl\n"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_clf = Pipeline([\n",
    "    ('preprocessor', Prepocess(log_scale=False)),\n",
    "    ('scaler', RowScaler(scaling_method='Standard')),\n",
    "    ('kmeans', KMeans(algorithm='elkan',random_state=42)),\n",
    "    ('logistic', LogisticRegression(solver='liblinear'))\n",
    "\n",
    "])\n",
    "\n",
    "model = log_clf\n",
    "model_dir = 'data/models/logistic_classifier'\n",
    "model_version = 'logistic_004.pkl'\n",
    "scoring = ['recall', 'accuracy', 'precision']\n",
    "\n",
    "log_path = os.path.join(model_dir, model_version)\n",
    "\n",
    "print(os.path.join(model_dir, model_version))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "    {\n",
    "    #  'scaler__scaling_method': RowScaler().scaling_options,\n",
    "     'kmeans__n_clusters': [5, 10, 30, 50, 100],\n",
    "     'logistic__penalty': ['l1', 'l2']\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "# Tuning hyper-parameters for recall and accuracy\n\nFitting 5 folds for each of 10 candidates, totalling 50 fits\n[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   35.1s\n[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:   41.2s finished\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=42, shuffle=True),\n             error_score='raise-deprecating',\n             estimator=Pipeline(memory=None,\n                                steps=[('preprocessor',\n                                        Prepocess(log_scale=False,\n                                                  max_pool_size=15,\n                                                  median_size=9,\n                                                  savgol_length=11)),\n                                       ('scaler',\n                                        RowScaler(scaling_method='Standard')),\n                                       ('kmeans',\n                                        KMeans(algorithm='elkan', copy_x=True,\n                                               init='k-means++', max...\n                                                           multi_class='warn',\n                                                           n_jobs=None,\n                                                           penalty='l2',\n                                                           random_state=None,\n                                                           solver='liblinear',\n                                                           tol=0.0001,\n                                                           verbose=0,\n                                                           warm_start=False))],\n                                verbose=False),\n             iid='warn', n_jobs=-1,\n             param_grid=[{'kmeans__n_clusters': [5, 10, 30, 50, 100],\n                          'logistic__penalty': ['l1', 'l2']}],\n             pre_dispatch='2*n_jobs', refit='recall', return_train_score=True,\n             scoring=['recall', 'accuracy', 'precision'], verbose=1)"
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "print(\"# Tuning hyper-parameters for {} and {}\".format(scoring[0], scoring[1]))\n",
    "print()\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=model, \n",
    "    param_grid=param_grid, \n",
    "    scoring=scoring,\n",
    "    n_jobs=-1,\n",
    "    verbose=1, \n",
    "    cv=strat_kfold, \n",
    "    return_train_score=True,\n",
    "    refit=scoring[0]  ## Score used for final refit\n",
    ")\n",
    "\n",
    "grid_search.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Best parameters set found on development set:\n{'kmeans__n_clusters': 10, 'logistic__penalty': 'l1'}\n\nGrid scores on development set:\n\n0.971 (+/-0.030) for {'kmeans__n_clusters': 5, 'logistic__penalty': 'l1'}\n0.970 (+/-0.030) for {'kmeans__n_clusters': 5, 'logistic__penalty': 'l2'}\n0.971 (+/-0.052) for {'kmeans__n_clusters': 10, 'logistic__penalty': 'l1'}\n0.971 (+/-0.052) for {'kmeans__n_clusters': 10, 'logistic__penalty': 'l2'}\n0.985 (+/-0.036) for {'kmeans__n_clusters': 30, 'logistic__penalty': 'l1'}\n0.985 (+/-0.036) for {'kmeans__n_clusters': 30, 'logistic__penalty': 'l2'}\n0.985 (+/-0.036) for {'kmeans__n_clusters': 50, 'logistic__penalty': 'l1'}\n0.992 (+/-0.031) for {'kmeans__n_clusters': 50, 'logistic__penalty': 'l2'}\n0.993 (+/-0.029) for {'kmeans__n_clusters': 100, 'logistic__penalty': 'l1'}\n0.985 (+/-0.036) for {'kmeans__n_clusters': 100, 'logistic__penalty': 'l2'}\n"
    }
   ],
   "source": [
    "printGridSearchResults(grid_search, scoring[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "Pipeline(memory=None,\n         steps=[('preprocessor',\n                 Prepocess(log_scale=False, max_pool_size=15, median_size=9,\n                           savgol_length=11)),\n                ('scaler', RowScaler(scaling_method='Standard')),\n                ('kmeans',\n                 KMeans(algorithm='elkan', copy_x=True, init='k-means++',\n                        max_iter=300, n_clusters=10, n_init=10, n_jobs=None,\n                        precompute_distances='auto', random_state=42,\n                        tol=0.0001, verbose=0)),\n                ('logistic',\n                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n                                    fit_intercept=True, intercept_scaling=1,\n                                    l1_ratio=None, max_iter=100,\n                                    multi_class='warn', n_jobs=None,\n                                    penalty='l1', random_state=None,\n                                    solver='liblinear', tol=0.0001, verbose=0,\n                                    warm_start=False))],\n         verbose=False)"
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "data/models/logistic_classifier/logistic_004.pkl succesfully saved.\n"
    }
   ],
   "source": [
    "#print(grid_search)\n",
    "save_model(grid_search, model_dir, model_version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "data/models/knn/knn_003.pkl\n"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_clf = Pipeline([\n",
    "    ('preprocessor', Prepocess()),\n",
    "    ('scaler', RowScaler(scaling_method='Standard')),\n",
    "    ('kmeans', KMeans(algorithm='elkan',random_state=42)),\n",
    "    ('knn', KNeighborsClassifier())\n",
    "\n",
    "])\n",
    "\n",
    "model = knn_clf\n",
    "model_dir = 'data/models/knn'\n",
    "model_version = 'knn_003.pkl'\n",
    "scoring = ['recall', 'accuracy', 'precision']\n",
    "\n",
    "knn_path = os.path.join(model_dir, model_version)\n",
    "print(os.path.join(model_dir, model_version))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "    {'scaler__scaling_method': RowScaler().scaling_options,\n",
    "     'kmeans__n_clusters': [5, 10, 30, 50, 100],\n",
    "     'knn__n_neighbors': range(3,7),\n",
    "     'knn__n_jobs': [-1]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "# Tuning hyper-parameters for recall and accuracy\n\nFitting 5 folds for each of 80 candidates, totalling 400 fits\n[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   35.4s\n[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  2.5min\n[Parallel(n_jobs=-1)]: Done 400 out of 400 | elapsed:  5.6min finished\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=42, shuffle=True),\n             error_score='raise-deprecating',\n             estimator=Pipeline(memory=None,\n                                steps=[('preprocessor',\n                                        Prepocess(log_scale=False,\n                                                  max_pool_size=15,\n                                                  median_size=9,\n                                                  savgol_length=11)),\n                                       ('scaler',\n                                        RowScaler(scaling_method='Standard')),\n                                       ('kmeans',\n                                        KMeans(algorithm='elkan', copy_x=True,\n                                               init='k-means++', max...\n                                                             n_neighbors=5, p=2,\n                                                             weights='uniform'))],\n                                verbose=False),\n             iid='warn', n_jobs=-1,\n             param_grid=[{'kmeans__n_clusters': [5, 10, 30, 50, 100],\n                          'knn__n_jobs': [-1], 'knn__n_neighbors': range(3, 7),\n                          'scaler__scaling_method': ['Standard', 'MinMax',\n                                                     'MaxAbs', 'Robust']}],\n             pre_dispatch='2*n_jobs', refit='recall', return_train_score=True,\n             scoring=['recall', 'accuracy', 'precision'], verbose=1)"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "print(\"# Tuning hyper-parameters for {} and {}\".format(scoring[0], scoring[1]))\n",
    "print()\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=model, \n",
    "    param_grid=param_grid, \n",
    "    scoring=scoring,\n",
    "    n_jobs=-1,\n",
    "    verbose=1, \n",
    "    cv=strat_kfold, \n",
    "    return_train_score=True,\n",
    "    refit=scoring[0]  ## Score used for final refit\n",
    ")\n",
    "\n",
    "grid_search.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Best parameters set found on development set:\n{'kmeans__n_clusters': 10, 'knn__n_jobs': -1, 'knn__n_neighbors': 3, 'scaler__scaling_method': 'Standard'}\n\nGrid scores on development set:\n\n0.953 (+/-0.036) for {'kmeans__n_clusters': 5, 'knn__n_jobs': -1, 'knn__n_neighbors': 3, 'scaler__scaling_method': 'Standard'}\n0.957 (+/-0.028) for {'kmeans__n_clusters': 5, 'knn__n_jobs': -1, 'knn__n_neighbors': 3, 'scaler__scaling_method': 'MinMax'}\n0.903 (+/-0.052) for {'kmeans__n_clusters': 5, 'knn__n_jobs': -1, 'knn__n_neighbors': 3, 'scaler__scaling_method': 'MaxAbs'}\n0.935 (+/-0.080) for {'kmeans__n_clusters': 5, 'knn__n_jobs': -1, 'knn__n_neighbors': 3, 'scaler__scaling_method': 'Robust'}\n0.942 (+/-0.034) for {'kmeans__n_clusters': 5, 'knn__n_jobs': -1, 'knn__n_neighbors': 4, 'scaler__scaling_method': 'Standard'}\n0.960 (+/-0.043) for {'kmeans__n_clusters': 5, 'knn__n_jobs': -1, 'knn__n_neighbors': 4, 'scaler__scaling_method': 'MinMax'}\n0.928 (+/-0.072) for {'kmeans__n_clusters': 5, 'knn__n_jobs': -1, 'knn__n_neighbors': 4, 'scaler__scaling_method': 'MaxAbs'}\n0.935 (+/-0.080) for {'kmeans__n_clusters': 5, 'knn__n_jobs': -1, 'knn__n_neighbors': 4, 'scaler__scaling_method': 'Robust'}\n0.946 (+/-0.045) for {'kmeans__n_clusters': 5, 'knn__n_jobs': -1, 'knn__n_neighbors': 5, 'scaler__scaling_method': 'Standard'}\n0.957 (+/-0.029) for {'kmeans__n_clusters': 5, 'knn__n_jobs': -1, 'knn__n_neighbors': 5, 'scaler__scaling_method': 'MinMax'}\n0.928 (+/-0.042) for {'kmeans__n_clusters': 5, 'knn__n_jobs': -1, 'knn__n_neighbors': 5, 'scaler__scaling_method': 'MaxAbs'}\n0.928 (+/-0.068) for {'kmeans__n_clusters': 5, 'knn__n_jobs': -1, 'knn__n_neighbors': 5, 'scaler__scaling_method': 'Robust'}\n0.942 (+/-0.054) for {'kmeans__n_clusters': 5, 'knn__n_jobs': -1, 'knn__n_neighbors': 6, 'scaler__scaling_method': 'Standard'}\n0.957 (+/-0.044) for {'kmeans__n_clusters': 5, 'knn__n_jobs': -1, 'knn__n_neighbors': 6, 'scaler__scaling_method': 'MinMax'}\n0.932 (+/-0.050) for {'kmeans__n_clusters': 5, 'knn__n_jobs': -1, 'knn__n_neighbors': 6, 'scaler__scaling_method': 'MaxAbs'}\n0.924 (+/-0.065) for {'kmeans__n_clusters': 5, 'knn__n_jobs': -1, 'knn__n_neighbors': 6, 'scaler__scaling_method': 'Robust'}\n0.964 (+/-0.039) for {'kmeans__n_clusters': 10, 'knn__n_jobs': -1, 'knn__n_neighbors': 3, 'scaler__scaling_method': 'Standard'}\n0.971 (+/-0.043) for {'kmeans__n_clusters': 10, 'knn__n_jobs': -1, 'knn__n_neighbors': 3, 'scaler__scaling_method': 'MinMax'}\n0.928 (+/-0.033) for {'kmeans__n_clusters': 10, 'knn__n_jobs': -1, 'knn__n_neighbors': 3, 'scaler__scaling_method': 'MaxAbs'}\n0.953 (+/-0.073) for {'kmeans__n_clusters': 10, 'knn__n_jobs': -1, 'knn__n_neighbors': 3, 'scaler__scaling_method': 'Robust'}\n0.960 (+/-0.052) for {'kmeans__n_clusters': 10, 'knn__n_jobs': -1, 'knn__n_neighbors': 4, 'scaler__scaling_method': 'Standard'}\n0.960 (+/-0.036) for {'kmeans__n_clusters': 10, 'knn__n_jobs': -1, 'knn__n_neighbors': 4, 'scaler__scaling_method': 'MinMax'}\n0.946 (+/-0.061) for {'kmeans__n_clusters': 10, 'knn__n_jobs': -1, 'knn__n_neighbors': 4, 'scaler__scaling_method': 'MaxAbs'}\n0.939 (+/-0.066) for {'kmeans__n_clusters': 10, 'knn__n_jobs': -1, 'knn__n_neighbors': 4, 'scaler__scaling_method': 'Robust'}\n0.964 (+/-0.045) for {'kmeans__n_clusters': 10, 'knn__n_jobs': -1, 'knn__n_neighbors': 5, 'scaler__scaling_method': 'Standard'}\n0.968 (+/-0.027) for {'kmeans__n_clusters': 10, 'knn__n_jobs': -1, 'knn__n_neighbors': 5, 'scaler__scaling_method': 'MinMax'}\n0.939 (+/-0.054) for {'kmeans__n_clusters': 10, 'knn__n_jobs': -1, 'knn__n_neighbors': 5, 'scaler__scaling_method': 'MaxAbs'}\n0.950 (+/-0.069) for {'kmeans__n_clusters': 10, 'knn__n_jobs': -1, 'knn__n_neighbors': 5, 'scaler__scaling_method': 'Robust'}\n0.968 (+/-0.042) for {'kmeans__n_clusters': 10, 'knn__n_jobs': -1, 'knn__n_neighbors': 6, 'scaler__scaling_method': 'Standard'}\n0.964 (+/-0.032) for {'kmeans__n_clusters': 10, 'knn__n_jobs': -1, 'knn__n_neighbors': 6, 'scaler__scaling_method': 'MinMax'}\n0.953 (+/-0.044) for {'kmeans__n_clusters': 10, 'knn__n_jobs': -1, 'knn__n_neighbors': 6, 'scaler__scaling_method': 'MaxAbs'}\n0.950 (+/-0.026) for {'kmeans__n_clusters': 10, 'knn__n_jobs': -1, 'knn__n_neighbors': 6, 'scaler__scaling_method': 'Robust'}\n0.975 (+/-0.043) for {'kmeans__n_clusters': 30, 'knn__n_jobs': -1, 'knn__n_neighbors': 3, 'scaler__scaling_method': 'Standard'}\n0.971 (+/-0.028) for {'kmeans__n_clusters': 30, 'knn__n_jobs': -1, 'knn__n_neighbors': 3, 'scaler__scaling_method': 'MinMax'}\n0.939 (+/-0.029) for {'kmeans__n_clusters': 30, 'knn__n_jobs': -1, 'knn__n_neighbors': 3, 'scaler__scaling_method': 'MaxAbs'}\n0.960 (+/-0.052) for {'kmeans__n_clusters': 30, 'knn__n_jobs': -1, 'knn__n_neighbors': 3, 'scaler__scaling_method': 'Robust'}\n0.964 (+/-0.032) for {'kmeans__n_clusters': 30, 'knn__n_jobs': -1, 'knn__n_neighbors': 4, 'scaler__scaling_method': 'Standard'}\n0.968 (+/-0.035) for {'kmeans__n_clusters': 30, 'knn__n_jobs': -1, 'knn__n_neighbors': 4, 'scaler__scaling_method': 'MinMax'}\n0.946 (+/-0.052) for {'kmeans__n_clusters': 30, 'knn__n_jobs': -1, 'knn__n_neighbors': 4, 'scaler__scaling_method': 'MaxAbs'}\n0.950 (+/-0.057) for {'kmeans__n_clusters': 30, 'knn__n_jobs': -1, 'knn__n_neighbors': 4, 'scaler__scaling_method': 'Robust'}\n0.964 (+/-0.032) for {'kmeans__n_clusters': 30, 'knn__n_jobs': -1, 'knn__n_neighbors': 5, 'scaler__scaling_method': 'Standard'}\n0.968 (+/-0.035) for {'kmeans__n_clusters': 30, 'knn__n_jobs': -1, 'knn__n_neighbors': 5, 'scaler__scaling_method': 'MinMax'}\n0.950 (+/-0.036) for {'kmeans__n_clusters': 30, 'knn__n_jobs': -1, 'knn__n_neighbors': 5, 'scaler__scaling_method': 'MaxAbs'}\n0.953 (+/-0.066) for {'kmeans__n_clusters': 30, 'knn__n_jobs': -1, 'knn__n_neighbors': 5, 'scaler__scaling_method': 'Robust'}\n0.964 (+/-0.032) for {'kmeans__n_clusters': 30, 'knn__n_jobs': -1, 'knn__n_neighbors': 6, 'scaler__scaling_method': 'Standard'}\n0.964 (+/-0.032) for {'kmeans__n_clusters': 30, 'knn__n_jobs': -1, 'knn__n_neighbors': 6, 'scaler__scaling_method': 'MinMax'}\n0.942 (+/-0.027) for {'kmeans__n_clusters': 30, 'knn__n_jobs': -1, 'knn__n_neighbors': 6, 'scaler__scaling_method': 'MaxAbs'}\n0.946 (+/-0.050) for {'kmeans__n_clusters': 30, 'knn__n_jobs': -1, 'knn__n_neighbors': 6, 'scaler__scaling_method': 'Robust'}\n0.975 (+/-0.043) for {'kmeans__n_clusters': 50, 'knn__n_jobs': -1, 'knn__n_neighbors': 3, 'scaler__scaling_method': 'Standard'}\n0.975 (+/-0.029) for {'kmeans__n_clusters': 50, 'knn__n_jobs': -1, 'knn__n_neighbors': 3, 'scaler__scaling_method': 'MinMax'}\n0.946 (+/-0.040) for {'kmeans__n_clusters': 50, 'knn__n_jobs': -1, 'knn__n_neighbors': 3, 'scaler__scaling_method': 'MaxAbs'}\n0.960 (+/-0.052) for {'kmeans__n_clusters': 50, 'knn__n_jobs': -1, 'knn__n_neighbors': 3, 'scaler__scaling_method': 'Robust'}\n0.964 (+/-0.032) for {'kmeans__n_clusters': 50, 'knn__n_jobs': -1, 'knn__n_neighbors': 4, 'scaler__scaling_method': 'Standard'}\n0.968 (+/-0.035) for {'kmeans__n_clusters': 50, 'knn__n_jobs': -1, 'knn__n_neighbors': 4, 'scaler__scaling_method': 'MinMax'}\n0.953 (+/-0.050) for {'kmeans__n_clusters': 50, 'knn__n_jobs': -1, 'knn__n_neighbors': 4, 'scaler__scaling_method': 'MaxAbs'}\n0.946 (+/-0.031) for {'kmeans__n_clusters': 50, 'knn__n_jobs': -1, 'knn__n_neighbors': 4, 'scaler__scaling_method': 'Robust'}\n0.964 (+/-0.032) for {'kmeans__n_clusters': 50, 'knn__n_jobs': -1, 'knn__n_neighbors': 5, 'scaler__scaling_method': 'Standard'}\n0.971 (+/-0.028) for {'kmeans__n_clusters': 50, 'knn__n_jobs': -1, 'knn__n_neighbors': 5, 'scaler__scaling_method': 'MinMax'}\n0.950 (+/-0.053) for {'kmeans__n_clusters': 50, 'knn__n_jobs': -1, 'knn__n_neighbors': 5, 'scaler__scaling_method': 'MaxAbs'}\n0.946 (+/-0.050) for {'kmeans__n_clusters': 50, 'knn__n_jobs': -1, 'knn__n_neighbors': 5, 'scaler__scaling_method': 'Robust'}\n0.960 (+/-0.027) for {'kmeans__n_clusters': 50, 'knn__n_jobs': -1, 'knn__n_neighbors': 6, 'scaler__scaling_method': 'Standard'}\n0.964 (+/-0.032) for {'kmeans__n_clusters': 50, 'knn__n_jobs': -1, 'knn__n_neighbors': 6, 'scaler__scaling_method': 'MinMax'}\n0.942 (+/-0.028) for {'kmeans__n_clusters': 50, 'knn__n_jobs': -1, 'knn__n_neighbors': 6, 'scaler__scaling_method': 'MaxAbs'}\n0.942 (+/-0.041) for {'kmeans__n_clusters': 50, 'knn__n_jobs': -1, 'knn__n_neighbors': 6, 'scaler__scaling_method': 'Robust'}\n0.975 (+/-0.043) for {'kmeans__n_clusters': 100, 'knn__n_jobs': -1, 'knn__n_neighbors': 3, 'scaler__scaling_method': 'Standard'}\n0.978 (+/-0.035) for {'kmeans__n_clusters': 100, 'knn__n_jobs': -1, 'knn__n_neighbors': 3, 'scaler__scaling_method': 'MinMax'}\n0.935 (+/-0.037) for {'kmeans__n_clusters': 100, 'knn__n_jobs': -1, 'knn__n_neighbors': 3, 'scaler__scaling_method': 'MaxAbs'}\n0.960 (+/-0.052) for {'kmeans__n_clusters': 100, 'knn__n_jobs': -1, 'knn__n_neighbors': 3, 'scaler__scaling_method': 'Robust'}\n0.960 (+/-0.027) for {'kmeans__n_clusters': 100, 'knn__n_jobs': -1, 'knn__n_neighbors': 4, 'scaler__scaling_method': 'Standard'}\n0.968 (+/-0.027) for {'kmeans__n_clusters': 100, 'knn__n_jobs': -1, 'knn__n_neighbors': 4, 'scaler__scaling_method': 'MinMax'}\n0.950 (+/-0.049) for {'kmeans__n_clusters': 100, 'knn__n_jobs': -1, 'knn__n_neighbors': 4, 'scaler__scaling_method': 'MaxAbs'}\n0.946 (+/-0.050) for {'kmeans__n_clusters': 100, 'knn__n_jobs': -1, 'knn__n_neighbors': 4, 'scaler__scaling_method': 'Robust'}\n0.964 (+/-0.032) for {'kmeans__n_clusters': 100, 'knn__n_jobs': -1, 'knn__n_neighbors': 5, 'scaler__scaling_method': 'Standard'}\n0.968 (+/-0.027) for {'kmeans__n_clusters': 100, 'knn__n_jobs': -1, 'knn__n_neighbors': 5, 'scaler__scaling_method': 'MinMax'}\n0.942 (+/-0.071) for {'kmeans__n_clusters': 100, 'knn__n_jobs': -1, 'knn__n_neighbors': 5, 'scaler__scaling_method': 'MaxAbs'}\n0.950 (+/-0.047) for {'kmeans__n_clusters': 100, 'knn__n_jobs': -1, 'knn__n_neighbors': 5, 'scaler__scaling_method': 'Robust'}\n0.964 (+/-0.032) for {'kmeans__n_clusters': 100, 'knn__n_jobs': -1, 'knn__n_neighbors': 6, 'scaler__scaling_method': 'Standard'}\n0.964 (+/-0.033) for {'kmeans__n_clusters': 100, 'knn__n_jobs': -1, 'knn__n_neighbors': 6, 'scaler__scaling_method': 'MinMax'}\n0.939 (+/-0.050) for {'kmeans__n_clusters': 100, 'knn__n_jobs': -1, 'knn__n_neighbors': 6, 'scaler__scaling_method': 'MaxAbs'}\n0.939 (+/-0.042) for {'kmeans__n_clusters': 100, 'knn__n_jobs': -1, 'knn__n_neighbors': 6, 'scaler__scaling_method': 'Robust'}\n"
    }
   ],
   "source": [
    "printGridSearchResults(grid_search, scoring[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.9568345323741008"
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "data/models/knn/knn_003.pkl succesfully saved.\n"
    }
   ],
   "source": [
    "save_model(grid_search, model_dir, model_version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Calcolare false positive rate sui casi non labellati\n",
    "provare la derivata ed eventualmente lstm con 2 input (derivata e segnale)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "StratifiedShuffleSplit(n_splits=1, random_state=35, test_size=0.4,\n            train_size=None)\nTRAIN size: 166 TEST size: 112\n"
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.4, random_state=35)\n",
    "\n",
    "print(sss)\n",
    "\n",
    "for train_index, test_index in sss.split(X, y):\n",
    "    print(\"TRAIN size:\", len(train_index), \"TEST size:\", len(test_index))\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function that builds the CNN for the gridsearch. Each layer is a Conv1D and a maxpool. Each layer reduce the second axis dimension of a factor 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_addons as tfa\n",
    "\n",
    "X_train_ = X_train[..., np.newaxis]\n",
    "X_med = tfa.image.median_filter2d(\n",
    "    image= X_train_,\n",
    "    filter_shape= [1, 11],\n",
    "    padding = 'CONSTANT',\n",
    "    constant_values= 0,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(222, 200, 1)"
     },
     "metadata": {},
     "execution_count": 145
    }
   ],
   "source": [
    "X_norm = model.predict(X_train)\n",
    "X_norm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 2 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"262.571875pt\" version=\"1.1\" viewBox=\"0 0 374.043932 262.571875\" width=\"374.043932pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <defs>\n  <style type=\"text/css\">\n*{stroke-linecap:butt;stroke-linejoin:round;}\n  </style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 262.571875 \nL 374.043932 262.571875 \nL 374.043932 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 31.890625 118.154489 \nL 366.690625 118.154489 \nL 366.690625 19.318125 \nL 31.890625 19.318125 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"mdaca23a825\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"47.108807\" xlink:href=\"#mdaca23a825\" y=\"118.154489\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <defs>\n       <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n      </defs>\n      <g transform=\"translate(43.291307 134.272614)scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"97.852994\" xlink:href=\"#mdaca23a825\" y=\"118.154489\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 500 -->\n      <defs>\n       <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n      </defs>\n      <g transform=\"translate(86.400494 134.272614)scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"148.597182\" xlink:href=\"#mdaca23a825\" y=\"118.154489\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 1000 -->\n      <defs>\n       <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n      </defs>\n      <g transform=\"translate(133.327182 134.272614)scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"199.341369\" xlink:href=\"#mdaca23a825\" y=\"118.154489\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 1500 -->\n      <g transform=\"translate(184.071369 134.272614)scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"250.085557\" xlink:href=\"#mdaca23a825\" y=\"118.154489\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 2000 -->\n      <defs>\n       <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n      </defs>\n      <g transform=\"translate(234.815557 134.272614)scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"300.829744\" xlink:href=\"#mdaca23a825\" y=\"118.154489\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 2500 -->\n      <g transform=\"translate(285.559744 134.272614)scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_7\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"351.573932\" xlink:href=\"#mdaca23a825\" y=\"118.154489\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 3000 -->\n      <defs>\n       <path d=\"M 40.578125 39.3125 \nQ 47.65625 37.796875 51.625 33 \nQ 55.609375 28.21875 55.609375 21.1875 \nQ 55.609375 10.40625 48.1875 4.484375 \nQ 40.765625 -1.421875 27.09375 -1.421875 \nQ 22.515625 -1.421875 17.65625 -0.515625 \nQ 12.796875 0.390625 7.625 2.203125 \nL 7.625 11.71875 \nQ 11.71875 9.328125 16.59375 8.109375 \nQ 21.484375 6.890625 26.8125 6.890625 \nQ 36.078125 6.890625 40.9375 10.546875 \nQ 45.796875 14.203125 45.796875 21.1875 \nQ 45.796875 27.640625 41.28125 31.265625 \nQ 36.765625 34.90625 28.71875 34.90625 \nL 20.21875 34.90625 \nL 20.21875 43.015625 \nL 29.109375 43.015625 \nQ 36.375 43.015625 40.234375 45.921875 \nQ 44.09375 48.828125 44.09375 54.296875 \nQ 44.09375 59.90625 40.109375 62.90625 \nQ 36.140625 65.921875 28.71875 65.921875 \nQ 24.65625 65.921875 20.015625 65.03125 \nQ 15.375 64.15625 9.8125 62.3125 \nL 9.8125 71.09375 \nQ 15.4375 72.65625 20.34375 73.4375 \nQ 25.25 74.21875 29.59375 74.21875 \nQ 40.828125 74.21875 47.359375 69.109375 \nQ 53.90625 64.015625 53.90625 55.328125 \nQ 53.90625 49.265625 50.4375 45.09375 \nQ 46.96875 40.921875 40.578125 39.3125 \nz\n\" id=\"DejaVuSans-51\"/>\n      </defs>\n      <g transform=\"translate(336.303932 134.272614)scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_8\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"m80a1977b82\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"31.890625\" xlink:href=\"#m80a1977b82\" y=\"100.694791\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 2 -->\n      <g transform=\"translate(17.255625 105.253854)scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_9\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"31.890625\" xlink:href=\"#m80a1977b82\" y=\"74.528106\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 4 -->\n      <defs>\n       <path d=\"M 37.796875 64.3125 \nL 12.890625 25.390625 \nL 37.796875 25.390625 \nz\nM 35.203125 72.90625 \nL 47.609375 72.90625 \nL 47.609375 25.390625 \nL 58.015625 25.390625 \nL 58.015625 17.1875 \nL 47.609375 17.1875 \nL 47.609375 0 \nL 37.796875 0 \nL 37.796875 17.1875 \nL 4.890625 17.1875 \nL 4.890625 26.703125 \nz\n\" id=\"DejaVuSans-52\"/>\n      </defs>\n      <g transform=\"translate(17.255625 79.087168)scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-52\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"31.890625\" xlink:href=\"#m80a1977b82\" y=\"48.361421\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 6 -->\n      <defs>\n       <path d=\"M 33.015625 40.375 \nQ 26.375 40.375 22.484375 35.828125 \nQ 18.609375 31.296875 18.609375 23.390625 \nQ 18.609375 15.53125 22.484375 10.953125 \nQ 26.375 6.390625 33.015625 6.390625 \nQ 39.65625 6.390625 43.53125 10.953125 \nQ 47.40625 15.53125 47.40625 23.390625 \nQ 47.40625 31.296875 43.53125 35.828125 \nQ 39.65625 40.375 33.015625 40.375 \nz\nM 52.59375 71.296875 \nL 52.59375 62.3125 \nQ 48.875 64.0625 45.09375 64.984375 \nQ 41.3125 65.921875 37.59375 65.921875 \nQ 27.828125 65.921875 22.671875 59.328125 \nQ 17.53125 52.734375 16.796875 39.40625 \nQ 19.671875 43.65625 24.015625 45.921875 \nQ 28.375 48.1875 33.59375 48.1875 \nQ 44.578125 48.1875 50.953125 41.515625 \nQ 57.328125 34.859375 57.328125 23.390625 \nQ 57.328125 12.15625 50.6875 5.359375 \nQ 44.046875 -1.421875 33.015625 -1.421875 \nQ 20.359375 -1.421875 13.671875 8.265625 \nQ 6.984375 17.96875 6.984375 36.375 \nQ 6.984375 53.65625 15.1875 63.9375 \nQ 23.390625 74.21875 37.203125 74.21875 \nQ 40.921875 74.21875 44.703125 73.484375 \nQ 48.484375 72.75 52.59375 71.296875 \nz\n\" id=\"DejaVuSans-54\"/>\n      </defs>\n      <g transform=\"translate(17.255625 52.920483)scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-54\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"31.890625\" xlink:href=\"#m80a1977b82\" y=\"22.194735\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 8 -->\n      <defs>\n       <path d=\"M 31.78125 34.625 \nQ 24.75 34.625 20.71875 30.859375 \nQ 16.703125 27.09375 16.703125 20.515625 \nQ 16.703125 13.921875 20.71875 10.15625 \nQ 24.75 6.390625 31.78125 6.390625 \nQ 38.8125 6.390625 42.859375 10.171875 \nQ 46.921875 13.96875 46.921875 20.515625 \nQ 46.921875 27.09375 42.890625 30.859375 \nQ 38.875 34.625 31.78125 34.625 \nz\nM 21.921875 38.8125 \nQ 15.578125 40.375 12.03125 44.71875 \nQ 8.5 49.078125 8.5 55.328125 \nQ 8.5 64.0625 14.71875 69.140625 \nQ 20.953125 74.21875 31.78125 74.21875 \nQ 42.671875 74.21875 48.875 69.140625 \nQ 55.078125 64.0625 55.078125 55.328125 \nQ 55.078125 49.078125 51.53125 44.71875 \nQ 48 40.375 41.703125 38.8125 \nQ 48.828125 37.15625 52.796875 32.3125 \nQ 56.78125 27.484375 56.78125 20.515625 \nQ 56.78125 9.90625 50.3125 4.234375 \nQ 43.84375 -1.421875 31.78125 -1.421875 \nQ 19.734375 -1.421875 13.25 4.234375 \nQ 6.78125 9.90625 6.78125 20.515625 \nQ 6.78125 27.484375 10.78125 32.3125 \nQ 14.796875 37.15625 21.921875 38.8125 \nz\nM 18.3125 54.390625 \nQ 18.3125 48.734375 21.84375 45.5625 \nQ 25.390625 42.390625 31.78125 42.390625 \nQ 38.140625 42.390625 41.71875 45.5625 \nQ 45.3125 48.734375 45.3125 54.390625 \nQ 45.3125 60.0625 41.71875 63.234375 \nQ 38.140625 66.40625 31.78125 66.40625 \nQ 25.390625 66.40625 21.84375 63.234375 \nQ 18.3125 60.0625 18.3125 54.390625 \nz\n\" id=\"DejaVuSans-56\"/>\n      </defs>\n      <g transform=\"translate(17.255625 26.753798)scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-56\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_12\">\n     <!-- 1eâˆ’11 -->\n     <defs>\n      <path d=\"M 56.203125 29.59375 \nL 56.203125 25.203125 \nL 14.890625 25.203125 \nQ 15.484375 15.921875 20.484375 11.0625 \nQ 25.484375 6.203125 34.421875 6.203125 \nQ 39.59375 6.203125 44.453125 7.46875 \nQ 49.3125 8.734375 54.109375 11.28125 \nL 54.109375 2.78125 \nQ 49.265625 0.734375 44.1875 -0.34375 \nQ 39.109375 -1.421875 33.890625 -1.421875 \nQ 20.796875 -1.421875 13.15625 6.1875 \nQ 5.515625 13.8125 5.515625 26.8125 \nQ 5.515625 40.234375 12.765625 48.109375 \nQ 20.015625 56 32.328125 56 \nQ 43.359375 56 49.78125 48.890625 \nQ 56.203125 41.796875 56.203125 29.59375 \nz\nM 47.21875 32.234375 \nQ 47.125 39.59375 43.09375 43.984375 \nQ 39.0625 48.390625 32.421875 48.390625 \nQ 24.90625 48.390625 20.390625 44.140625 \nQ 15.875 39.890625 15.1875 32.171875 \nz\n\" id=\"DejaVuSans-101\"/>\n      <path d=\"M 10.59375 35.5 \nL 73.1875 35.5 \nL 73.1875 27.203125 \nL 10.59375 27.203125 \nz\n\" id=\"DejaVuSans-8722\"/>\n     </defs>\n     <g transform=\"translate(31.890625 16.318125)scale(0.12 -0.12)\">\n      <use xlink:href=\"#DejaVuSans-49\"/>\n      <use x=\"63.623047\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"125.146484\" xlink:href=\"#DejaVuSans-8722\"/>\n      <use x=\"208.935547\" xlink:href=\"#DejaVuSans-49\"/>\n      <use x=\"272.558594\" xlink:href=\"#DejaVuSans-49\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_12\">\n    <path clip-path=\"url(#pc18bc85bae)\" d=\"M 47.108807 107.236463 \nL 47.311784 105.990288 \nL 47.51476 108.480425 \nL 47.616249 108.511094 \nL 47.819225 107.236463 \nL 47.920714 107.387623 \nL 48.428156 109.803022 \nL 48.529644 107.46256 \nL 48.732621 108.41166 \nL 49.037086 107.236463 \nL 49.138574 107.236463 \nL 49.240063 108.883196 \nL 49.341551 107.657146 \nL 49.443039 107.7141 \nL 49.646016 108.257055 \nL 49.747505 107.672174 \nL 49.848993 107.760456 \nL 49.950481 109.815006 \nL 50.153458 107.415696 \nL 50.254946 109.645021 \nL 50.356435 108.758152 \nL 50.457923 109.973329 \nL 50.559412 109.097445 \nL 50.6609 109.720532 \nL 50.762388 109.56842 \nL 50.965365 107.835247 \nL 51.168342 108.4453 \nL 51.26983 108.123533 \nL 51.472807 109.098663 \nL 51.574295 108.265095 \nL 51.675784 108.405756 \nL 51.777272 108.333078 \nL 51.87876 108.736589 \nL 52.081737 107.38797 \nL 52.284714 109.47145 \nL 52.386202 109.149922 \nL 52.487691 107.658946 \nL 52.589179 109.751417 \nL 52.792156 108.560509 \nL 52.995133 109.535092 \nL 53.096621 108.20461 \nL 53.198109 109.700295 \nL 53.401086 108.629914 \nL 53.604063 109.799692 \nL 53.80704 108.245477 \nL 53.908528 108.99597 \nL 54.010016 107.407372 \nL 54.314481 109.853131 \nL 54.41597 109.853131 \nL 54.618947 108.358779 \nL 54.720435 108.719851 \nL 54.821923 107.535741 \nL 54.923412 109.510528 \nL 55.0249 107.858557 \nL 55.329365 109.373668 \nL 55.430854 107.338268 \nL 55.532342 109.641846 \nL 55.63383 107.978927 \nL 55.735319 109.551815 \nL 55.836807 108.984371 \nL 55.938295 109.048401 \nL 56.039784 110.700996 \nL 56.141272 108.105964 \nL 56.344249 108.544797 \nL 56.547226 111.787611 \nL 56.648714 106.692082 \nL 56.750202 109.863257 \nL 56.953179 108.544797 \nL 57.156156 110.889478 \nL 57.460621 108.544797 \nL 57.663598 108.544797 \nL 57.765086 109.007808 \nL 57.866575 110.722389 \nL 57.968063 109.145773 \nL 58.069551 111.797708 \nL 58.17104 107.786835 \nL 58.272528 108.02803 \nL 58.374016 112.309814 \nL 58.475505 108.280139 \nL 58.678482 109.890159 \nL 58.881458 108.544797 \nL 58.982947 108.760429 \nL 59.185923 110.84409 \nL 59.490389 108.544797 \nL 59.591877 108.544797 \nL 59.693365 112.360682 \nL 59.794854 109.09208 \nL 59.99783 110.807622 \nL 60.099319 112.034034 \nL 60.302296 108.713165 \nL 60.403784 110.481656 \nL 60.606761 108.544797 \nL 60.708249 108.544797 \nL 60.911226 109.573459 \nL 61.114203 108.415228 \nL 61.215691 109.42562 \nL 61.317179 108.812582 \nL 61.418668 109.213735 \nL 61.520156 110.401516 \nL 61.621644 110.047151 \nL 61.723133 109.001332 \nL 61.824621 110.769824 \nL 62.027598 108.544797 \nL 62.129086 108.665839 \nL 62.332063 109.994645 \nL 62.433551 112.231525 \nL 62.53504 110.322107 \nL 62.636528 110.915997 \nL 62.839505 108.544797 \nL 62.940993 108.544797 \nL 63.042482 111.052917 \nL 63.245458 108.544797 \nL 63.7529 108.604368 \nL 63.955877 110.807794 \nL 64.057365 110.703543 \nL 64.158854 109.409868 \nL 64.260342 109.634657 \nL 64.361831 108.717614 \nL 64.463319 111.36844 \nL 64.564807 107.981771 \nL 64.666296 109.556864 \nL 64.767784 108.94351 \nL 64.869272 109.376119 \nL 64.970761 109.275921 \nL 65.072249 110.497616 \nL 65.173738 109.877941 \nL 65.275226 110.905198 \nL 65.579691 108.544797 \nL 65.681179 109.982008 \nL 65.782668 109.338859 \nL 65.884156 106.690346 \nL 65.985645 110.301926 \nL 66.29011 108.9315 \nL 66.391598 111.059719 \nL 66.594575 108.765017 \nL 66.797552 108.357008 \nL 67.000528 109.853131 \nL 67.102017 109.853131 \nL 67.203505 111.512118 \nL 67.406482 109.853131 \nL 67.609459 109.853131 \nL 67.710947 109.731147 \nL 67.812435 107.559198 \nL 67.913924 109.54904 \nL 68.1169 108.677359 \nL 68.319877 110.792167 \nL 68.421366 108.620218 \nL 68.624342 110.849588 \nL 68.725831 107.610082 \nL 69.131784 111.068145 \nL 69.334761 108.544797 \nL 69.537738 108.544797 \nL 69.639226 110.293358 \nL 69.740714 109.695216 \nL 69.842203 110.924654 \nL 69.943691 108.704782 \nL 70.04518 108.715408 \nL 70.248156 109.853131 \nL 70.349645 109.853131 \nL 70.552621 111.01339 \nL 70.755598 109.348094 \nL 70.857087 111.115927 \nL 70.958575 108.960202 \nL 71.060063 110.612747 \nL 71.161552 109.172005 \nL 71.26304 112.023767 \nL 71.364528 110.189439 \nL 71.466017 110.717336 \nL 71.567505 108.748844 \nL 71.770482 110.613486 \nL 71.87197 108.91045 \nL 71.973459 109.449225 \nL 72.074947 111.061428 \nL 72.277924 109.033893 \nL 72.480901 110.299502 \nL 72.582389 109.955 \nL 72.683877 108.877207 \nL 72.785366 110.569353 \nL 72.988342 109.205579 \nL 73.089831 109.337126 \nL 73.394296 110.453846 \nL 73.495784 112.105816 \nL 73.597273 109.099763 \nL 73.698761 109.884781 \nL 73.800249 109.79785 \nL 73.901738 110.276714 \nL 74.104715 108.544797 \nL 74.307691 108.544797 \nL 74.40918 108.775155 \nL 74.713645 111.161465 \nL 74.815133 111.161465 \nL 74.916622 109.554534 \nL 75.221087 110.750151 \nL 75.322575 108.578202 \nL 75.525552 112.681285 \nL 75.728529 109.041094 \nL 75.830017 109.423683 \nL 75.931505 110.781141 \nL 76.134482 109.012389 \nL 76.337459 110.4071 \nL 76.438947 109.351683 \nL 76.540436 111.157532 \nL 76.743412 109.911337 \nL 76.946389 110.967998 \nL 77.149366 108.612351 \nL 77.250854 110.730435 \nL 77.453831 108.783088 \nL 77.656808 110.91352 \nL 77.859784 110.207856 \nL 77.961273 111.518168 \nL 78.16425 107.872716 \nL 78.265738 112.377683 \nL 78.468715 110.010685 \nL 78.570203 111.908853 \nL 78.671691 110.209914 \nL 78.77318 110.777078 \nL 78.874668 109.274779 \nL 78.976157 111.025774 \nL 79.280622 109.853131 \nL 79.585087 109.853131 \nL 79.788064 108.822203 \nL 79.99104 111.989661 \nL 80.194017 109.853131 \nL 80.396994 111.517306 \nL 80.599971 107.460033 \nL 80.701459 111.052037 \nL 80.802947 110.162683 \nL 81.005924 110.97981 \nL 81.208901 109.853131 \nL 81.310389 109.853131 \nL 81.411878 109.513094 \nL 81.513366 110.897041 \nL 81.614854 108.84338 \nL 81.716343 109.811245 \nL 81.817831 108.889091 \nL 81.919319 111.060031 \nL 82.223785 109.853131 \nL 82.325273 109.853131 \nL 82.426761 111.867224 \nL 82.629738 110.453702 \nL 82.731226 110.975889 \nL 82.832715 107.738567 \nL 82.934203 110.961874 \nL 83.13718 109.970512 \nL 83.340157 111.125445 \nL 83.644622 109.853131 \nL 83.74611 109.853131 \nL 83.847599 112.437634 \nL 83.949087 110.625369 \nL 84.050575 111.871625 \nL 84.152064 110.644485 \nL 84.253552 112.090489 \nL 84.456529 108.8216 \nL 84.558017 110.432231 \nL 84.659506 109.105972 \nL 84.760994 112.529745 \nL 84.862482 110.024476 \nL 84.963971 111.458904 \nL 85.166947 108.605919 \nL 85.268436 112.129605 \nL 85.471413 110.504488 \nL 85.572901 109.507966 \nL 85.775878 111.161465 \nL 85.877366 108.549798 \nL 85.978854 110.792542 \nL 86.181831 109.853131 \nL 86.28332 109.853131 \nL 86.384808 110.33203 \nL 86.486296 112.02141 \nL 86.689273 110.579012 \nL 86.790761 110.927083 \nL 86.89225 112.153238 \nL 86.993738 110.143545 \nL 87.095227 110.766827 \nL 87.196715 108.626275 \nL 87.298203 110.037922 \nL 87.399692 110.013823 \nL 87.602668 112.267866 \nL 87.704157 110.258826 \nL 87.805645 110.882404 \nL 87.907134 107.459066 \nL 88.11011 112.05358 \nL 88.313087 109.575689 \nL 88.414575 110.720752 \nL 88.516064 109.298872 \nL 88.617552 111.005449 \nL 88.820529 110.232874 \nL 88.922017 110.537047 \nL 89.124994 111.9525 \nL 89.429459 107.679597 \nL 89.530948 109.998537 \nL 89.632436 107.363847 \nL 89.733924 110.842007 \nL 89.835413 110.385087 \nL 90.038389 111.161465 \nL 90.64732 111.161465 \nL 90.748808 108.754664 \nL 90.951785 111.69174 \nL 91.154762 111.161465 \nL 91.25625 111.161465 \nL 91.357738 107.750014 \nL 91.560715 112.31991 \nL 91.763692 107.945081 \nL 91.86518 108.755296 \nL 92.068157 111.762272 \nL 92.169645 113.661927 \nL 92.271134 109.739874 \nL 92.372622 110.04588 \nL 92.575599 111.161465 \nL 93.286017 111.161465 \nL 93.488994 109.511479 \nL 93.691971 112.191208 \nL 93.793459 110.465946 \nL 93.894948 112.233163 \nL 93.996436 109.934529 \nL 94.199413 112.15906 \nL 94.300901 110.727458 \nL 94.40239 111.285 \nL 94.503878 110.24243 \nL 94.706855 111.161465 \nL 94.808343 111.161465 \nL 94.909831 110.932962 \nL 95.01132 110.309875 \nL 95.112808 110.387195 \nL 95.214297 112.387678 \nL 95.417273 109.853131 \nL 95.62025 109.853131 \nL 95.823227 111.03558 \nL 96.22918 109.853131 \nL 96.533645 111.403653 \nL 96.736622 110.818207 \nL 96.838111 112.183589 \nL 97.041087 110.791676 \nL 97.142576 110.139101 \nL 97.244064 110.847825 \nL 97.345552 110.234777 \nL 97.548529 106.745522 \nL 97.650018 106.217624 \nL 97.852994 108.544797 \nL 97.954483 108.544797 \nL 98.157459 110.753455 \nL 98.258948 110.266164 \nL 98.360436 110.309025 \nL 98.563413 113.572674 \nL 98.76639 111.161465 \nL 98.867878 109.609909 \nL 98.969366 110.900432 \nL 99.273832 110.075174 \nL 99.37532 111.727755 \nL 99.578297 109.101868 \nL 99.679785 108.594977 \nL 99.882762 110.815862 \nL 99.98425 108.962801 \nL 100.085739 109.700762 \nL 100.187227 109.002816 \nL 100.390204 110.430175 \nL 100.59318 111.161465 \nL 100.694669 110.482572 \nL 100.796157 110.99809 \nL 100.897646 110.6609 \nL 101.100622 108.544797 \nL 101.202111 108.526231 \nL 101.405087 107.33845 \nL 101.506576 107.737241 \nL 101.608064 108.824766 \nL 101.709553 107.655614 \nL 101.811041 111.569588 \nL 102.014018 107.495708 \nL 102.216994 107.236463 \nL 102.318483 109.047927 \nL 102.52146 107.236463 \nL 102.622948 107.3688 \nL 102.724436 107.790054 \nL 102.825925 110.544238 \nL 103.028901 107.610482 \nL 103.13039 108.099753 \nL 103.231878 107.385002 \nL 103.333367 108.446061 \nL 103.434855 106.294622 \nL 103.536343 109.691339 \nL 103.637832 107.455511 \nL 103.840808 109.853131 \nL 104.145274 109.902712 \nL 104.34825 111.090494 \nL 104.551227 109.629153 \nL 104.754204 111.161465 \nL 104.957181 112.107599 \nL 105.160157 110.670768 \nL 105.261646 111.595747 \nL 105.464622 107.979465 \nL 105.566111 107.514141 \nL 105.667599 108.127179 \nL 105.769088 107.709197 \nL 105.870576 106.124635 \nL 106.073553 107.236463 \nL 106.276529 107.236463 \nL 106.580995 104.619794 \nL 106.682483 104.619794 \nL 107.595878 82.022908 \nL 107.697367 84.737824 \nL 107.798855 81.228132 \nL 108.001832 84.996113 \nL 108.10332 85.204195 \nL 108.204809 91.118731 \nL 108.306297 89.174374 \nL 108.407785 89.573414 \nL 108.610762 81.921547 \nL 108.71225 78.856358 \nL 108.813739 81.6823 \nL 108.915227 74.245847 \nL 109.118204 84.432521 \nL 109.321181 82.379944 \nL 109.625646 84.380088 \nL 109.727134 86.072251 \nL 109.828623 83.472475 \nL 109.930111 88.473684 \nL 110.133088 81.764293 \nL 110.234576 86.140349 \nL 110.336064 84.205658 \nL 110.437553 86.783188 \nL 110.64053 83.686446 \nL 110.742018 83.961317 \nL 110.843506 84.584251 \nL 110.944995 86.695829 \nL 111.046483 92.634736 \nL 111.147971 88.352245 \nL 111.24946 88.620686 \nL 111.350948 85.194519 \nL 111.452437 87.908661 \nL 111.553925 84.233375 \nL 111.655413 86.594415 \nL 111.756902 84.221316 \nL 111.85839 84.834354 \nL 111.959878 89.671802 \nL 112.162855 82.612204 \nL 112.365832 87.464709 \nL 112.771785 29.044515 \nL 113.076251 35.882055 \nL 113.177739 38.9979 \nL 113.380716 27.112529 \nL 113.482204 25.353411 \nL 113.583692 32.427542 \nL 113.685181 23.810687 \nL 113.786669 24.433621 \nL 114.091134 27.109644 \nL 114.294111 25.046593 \nL 114.598576 28.736407 \nL 114.700065 28.736407 \nL 114.903041 26.489083 \nL 115.00453 26.964516 \nL 115.308995 29.705089 \nL 115.410483 29.78665 \nL 115.816437 27.454324 \nL 116.019413 31.017724 \nL 116.22239 26.910172 \nL 116.323879 28.231001 \nL 116.526855 32.323529 \nL 117.135786 28.773504 \nL 117.237274 38.209479 \nL 117.440251 30.044741 \nL 117.541739 31.304184 \nL 117.744716 34.905311 \nL 117.846204 27.881111 \nL 118.252158 31.986581 \nL 118.353646 33.82525 \nL 118.658111 32.180622 \nL 118.7596 31.595868 \nL 118.861088 31.717638 \nL 119.064065 32.661409 \nL 119.165553 32.661409 \nL 119.267041 32.88071 \nL 119.672995 35.20601 \nL 120.078948 32.733906 \nL 120.281925 35.966536 \nL 120.383414 44.786345 \nL 120.58639 31.700832 \nL 120.789367 37.684465 \nL 120.992344 31.843173 \nL 121.093832 40.391619 \nL 121.195321 36.11904 \nL 121.296809 38.201471 \nL 121.398297 32.644924 \nL 121.702762 38.321976 \nL 121.804251 39.023504 \nL 122.311693 36.586412 \nL 122.413181 36.586412 \nL 122.616158 35.469116 \nL 122.717646 35.706893 \nL 122.920623 37.307657 \nL 123.1236 38.919831 \nL 123.326576 37.894746 \nL 123.428065 37.894746 \nL 123.529553 38.165249 \nL 123.935507 43.11214 \nL 124.138483 40.804029 \nL 124.34146 44.206268 \nL 124.544437 37.47022 \nL 124.747414 39.203081 \nL 124.848902 39.203081 \nL 125.051879 40.969653 \nL 125.153367 41.645463 \nL 125.559321 39.222982 \nL 125.965274 45.343938 \nL 126.371228 40.511415 \nL 126.574204 40.511415 \nL 126.675693 39.994932 \nL 126.878669 38.087461 \nL 127.081646 39.424573 \nL 127.284623 41.761786 \nL 127.4876 39.268783 \nL 128.09653 41.819749 \nL 128.299507 42.787896 \nL 128.400995 42.599557 \nL 128.603972 40.659513 \nL 129.111414 43.128083 \nL 129.415879 43.128083 \nL 129.618856 42.040047 \nL 129.821832 39.871044 \nL 129.923321 40.007943 \nL 130.329274 45.644162 \nL 130.532251 44.456103 \nL 130.735228 40.93217 \nL 131.141181 45.404191 \nL 131.24267 45.221581 \nL 131.547135 42.322717 \nL 131.750111 41.819749 \nL 131.8516 42.037315 \nL 132.054577 49.391991 \nL 132.156065 42.869485 \nL 132.359042 44.436418 \nL 132.46053 44.436418 \nL 132.663507 45.367626 \nL 132.764995 45.025404 \nL 132.967972 42.69364 \nL 133.170949 48.002746 \nL 133.475414 42.573594 \nL 133.779879 40.753948 \nL 134.185832 47.053086 \nL 134.287321 46.411959 \nL 134.490298 43.128083 \nL 134.693274 43.175775 \nL 135.099228 46.868133 \nL 135.302205 43.920096 \nL 135.403693 44.436418 \nL 135.505181 44.436418 \nL 135.60667 44.735346 \nL 135.809646 48.287625 \nL 136.2156 44.544662 \nL 136.418577 46.676154 \nL 136.520065 46.628569 \nL 136.723042 45.049253 \nL 136.82453 43.802732 \nL 136.926019 44.815564 \nL 137.128995 50.381114 \nL 137.43346 46.345925 \nL 137.534949 45.751896 \nL 137.737926 48.221506 \nL 137.940902 44.888835 \nL 138.143879 47.662397 \nL 138.245367 47.625104 \nL 138.448344 45.744752 \nL 138.651321 45.676905 \nL 138.854298 44.450512 \nL 139.057274 51.825716 \nL 139.158763 44.836767 \nL 139.36174 47.053086 \nL 139.564716 47.016825 \nL 139.97067 44.544427 \nL 140.173647 47.846415 \nL 140.275135 47.472812 \nL 140.478112 46.107035 \nL 140.681088 46.768542 \nL 140.884065 45.744752 \nL 141.087042 45.818978 \nL 141.492995 48.291492 \nL 141.695972 46.010859 \nL 141.797461 46.226855 \nL 142.000437 47.852732 \nL 142.203414 49.669755 \nL 142.304902 49.669755 \nL 142.406391 49.156932 \nL 142.710856 44.65256 \nL 142.812344 46.197285 \nL 142.913833 50.731707 \nL 143.116809 47.359225 \nL 143.319786 48.15414 \nL 143.522763 47.199748 \nL 143.72574 52.184772 \nL 143.928716 43.344032 \nL 144.233182 51.092706 \nL 144.33467 47.816894 \nL 144.436158 49.95354 \nL 144.537647 47.316268 \nL 144.740623 49.519174 \nL 144.9436 45.779609 \nL 145.349554 50.70547 \nL 145.451042 50.31498 \nL 145.654019 48.602777 \nL 145.856996 49.415707 \nL 146.059972 47.171233 \nL 146.364437 49.669755 \nL 146.465926 49.669755 \nL 146.668903 48.69745 \nL 146.770391 48.900492 \nL 147.074856 51.741012 \nL 147.176344 52.133596 \nL 147.379321 49.682038 \nL 147.683786 52.069624 \nL 147.785275 53.29572 \nL 147.988251 50.36508 \nL 148.08974 50.375389 \nL 148.191228 51.509987 \nL 148.292717 51.499242 \nL 148.495693 47.319097 \nL 148.901647 52.223491 \nL 149.206112 49.669755 \nL 149.510577 49.669755 \nL 149.713554 48.679412 \nL 149.815042 48.951686 \nL 150.018019 50.771851 \nL 150.220996 50.02348 \nL 150.423972 54.882615 \nL 150.728438 50.203689 \nL 151.032903 54.7301 \nL 151.134391 45.811866 \nL 151.337368 51.943927 \nL 151.438856 51.732794 \nL 151.641833 50.978089 \nL 151.743321 50.978089 \nL 151.946298 54.021704 \nL 152.047786 52.782387 \nL 152.250763 48.531398 \nL 152.45374 52.286423 \nL 152.859693 52.190309 \nL 153.265647 49.738137 \nL 153.367135 55.143513 \nL 153.468624 49.745883 \nL 153.874577 53.427349 \nL 154.077554 53.594758 \nL 154.280531 53.594758 \nL 154.382019 52.93051 \nL 154.584996 49.721263 \nL 155.193926 53.42063 \nL 155.295414 53.155732 \nL 155.396903 52.542535 \nL 155.59988 50.978089 \nL 155.701368 51.042857 \nL 155.904345 52.283957 \nL 156.107321 51.114449 \nL 156.310298 54.280717 \nL 156.411787 53.676295 \nL 156.513275 51.837152 \nL 156.716252 56.126732 \nL 156.81774 52.878189 \nL 157.122205 54.729063 \nL 157.325182 49.556525 \nL 157.42667 59.458992 \nL 157.528159 54.327263 \nL 157.629647 56.702789 \nL 157.731135 52.532321 \nL 157.832624 53.224198 \nL 157.934112 57.058959 \nL 158.340066 50.994295 \nL 158.644531 53.594758 \nL 159.354949 53.594758 \nL 159.456438 53.448184 \nL 159.862391 50.995981 \nL 159.96388 56.602578 \nL 160.065368 55.33659 \nL 160.166856 56.729979 \nL 160.674298 51.459001 \nL 160.775787 52.279063 \nL 160.877275 57.980306 \nL 161.080252 53.153425 \nL 161.18174 57.738045 \nL 161.283229 53.04191 \nL 161.486205 54.302552 \nL 161.689182 52.286423 \nL 161.993647 52.286423 \nL 162.095136 52.4278 \nL 162.298112 54.894381 \nL 162.602577 53.594758 \nL 162.704066 53.594758 \nL 162.907043 57.947542 \nL 163.008531 57.638714 \nL 163.211508 55.222459 \nL 163.414484 55.970042 \nL 163.617461 54.68453 \nL 163.820438 52.332797 \nL 164.124903 53.594758 \nL 164.226391 53.594758 \nL 164.429368 55.726945 \nL 164.530857 55.457852 \nL 164.733833 53.904165 \nL 164.93681 54.675682 \nL 165.038298 54.062634 \nL 165.139787 58.994767 \nL 165.342764 54.575033 \nL 165.54574 57.053416 \nL 165.647229 56.440368 \nL 165.748717 56.595532 \nL 165.951694 57.51976 \nL 166.053182 57.51976 \nL 166.154671 56.987547 \nL 166.256159 55.148403 \nL 166.357647 55.561473 \nL 166.459136 58.290058 \nL 166.560624 54.192173 \nL 166.763601 55.843561 \nL 166.966578 53.698386 \nL 167.575508 57.359089 \nL 167.981461 56.211426 \nL 168.08295 56.388611 \nL 168.285926 57.326742 \nL 168.488903 55.039602 \nL 168.69188 59.943905 \nL 168.894857 55.347333 \nL 168.996345 55.910633 \nL 169.199322 57.51976 \nL 169.30081 57.51976 \nL 169.402299 62.124417 \nL 169.605275 56.734971 \nL 169.706764 57.36116 \nL 169.808252 61.651137 \nL 170.011229 55.173503 \nL 170.112717 56.291094 \nL 170.315694 59.05933 \nL 170.518671 54.903092 \nL 170.924624 54.94319 \nL 171.330578 57.325974 \nL 171.533554 55.486078 \nL 171.635043 55.556574 \nL 171.83802 56.999762 \nL 172.142485 54.112127 \nL 172.243973 61.902094 \nL 172.44695 55.501536 \nL 172.548438 54.917965 \nL 172.852903 56.211426 \nL 173.157368 56.211426 \nL 173.360345 57.247789 \nL 173.461834 56.888513 \nL 173.66481 55.209679 \nL 173.867787 57.447806 \nL 174.375229 54.903092 \nL 174.476717 54.903092 \nL 174.781182 57.51976 \nL 174.882671 57.51976 \nL 175.085648 56.575983 \nL 175.390113 55.075203 \nL 175.694578 57.573335 \nL 175.796066 58.761116 \nL 175.999043 56.445081 \nL 176.100531 56.716036 \nL 176.303508 57.51976 \nL 176.81095 57.51976 \nL 176.912438 57.309661 \nL 177.216903 55.458569 \nL 177.318392 55.661598 \nL 177.41988 62.666055 \nL 177.724345 57.51976 \nL 177.825834 57.528303 \nL 178.130299 58.828095 \nL 178.231787 58.828095 \nL 178.536252 56.396909 \nL 178.637741 57.009798 \nL 178.840717 58.975597 \nL 178.942206 60.056033 \nL 179.145183 57.716476 \nL 179.246671 61.471871 \nL 179.348159 56.258977 \nL 179.754113 58.731484 \nL 179.95709 56.532098 \nL 180.058578 57.321982 \nL 180.160066 56.825421 \nL 180.56602 58.828095 \nL 180.870485 58.828095 \nL 180.971973 58.633936 \nL 181.17495 57.51976 \nL 181.377927 57.473619 \nL 181.580904 56.285838 \nL 181.885369 60.136429 \nL 182.088345 60.073279 \nL 182.494299 54.40204 \nL 182.595787 56.040233 \nL 182.697276 60.511844 \nL 182.798764 60.458564 \nL 183.001741 58.828095 \nL 183.103229 58.828095 \nL 183.306206 64.848195 \nL 183.407694 59.620407 \nL 183.509183 61.489668 \nL 183.610671 60.993262 \nL 183.712159 57.166429 \nL 183.813648 65.168363 \nL 183.915136 56.484558 \nL 184.016625 57.069312 \nL 184.219601 57.51976 \nL 184.32109 57.361064 \nL 184.524066 54.908279 \nL 184.828532 60.075043 \nL 185.031508 64.960303 \nL 185.234485 58.828095 \nL 185.640439 60.136429 \nL 185.741927 58.815777 \nL 185.843415 54.306323 \nL 185.944904 61.811175 \nL 186.046392 56.317324 \nL 186.452346 62.536424 \nL 186.553834 57.134252 \nL 186.655322 59.586443 \nL 186.756811 54.540791 \nL 186.959787 59.780283 \nL 187.061276 60.116885 \nL 187.162764 66.052436 \nL 187.365741 58.828095 \nL 187.568718 58.828095 \nL 187.771694 66.279679 \nL 187.873183 58.025281 \nL 188.07616 63.608023 \nL 188.177648 60.932455 \nL 188.279136 63.458866 \nL 188.583601 60.390776 \nL 188.786578 63.763319 \nL 188.989555 57.722651 \nL 189.091043 64.624708 \nL 189.192532 59.277385 \nL 189.395508 60.136429 \nL 189.699974 60.136429 \nL 189.801462 59.973335 \nL 190.004439 59.126017 \nL 190.207415 62.736558 \nL 190.511881 60.43278 \nL 190.816346 57.823709 \nL 191.120811 63.562948 \nL 191.222299 60.459817 \nL 191.323788 61.073023 \nL 191.425276 58.363397 \nL 191.526764 62.604132 \nL 191.628253 53.780653 \nL 191.729741 60.446725 \nL 191.831229 56.894605 \nL 191.932718 59.440573 \nL 192.034206 58.865281 \nL 192.237183 60.091376 \nL 192.338671 66.005658 \nL 192.44016 58.93292 \nL 192.541648 59.545968 \nL 192.744625 61.428516 \nL 192.846113 62.67469 \nL 192.947602 58.086473 \nL 193.04909 59.332974 \nL 193.252067 68.72536 \nL 193.353555 57.241806 \nL 193.556532 69.066337 \nL 193.759509 59.87307 \nL 193.860997 61.087944 \nL 193.962485 60.388478 \nL 194.063974 61.011575 \nL 194.26695 57.607457 \nL 194.368439 58.771017 \nL 194.571416 62.218158 \nL 194.672904 62.666361 \nL 194.977369 60.191049 \nL 195.078857 58.946466 \nL 195.180346 66.479943 \nL 195.281834 59.371754 \nL 195.383323 59.993893 \nL 195.586299 54.709619 \nL 195.687788 61.111364 \nL 195.789276 60.488267 \nL 195.890764 62.540174 \nL 195.992253 68.061701 \nL 196.093741 64.322946 \nL 196.19523 72.298599 \nL 196.398206 59.311524 \nL 196.499695 60.207949 \nL 196.601183 66.740746 \nL 196.702671 60.222473 \nL 196.80416 60.836293 \nL 196.905648 61.382652 \nL 197.007137 54.255964 \nL 197.108625 70.357329 \nL 197.210113 60.459143 \nL 197.311602 61.485126 \nL 197.41309 57.540574 \nL 197.920532 62.665019 \nL 198.123509 56.883097 \nL 198.326485 64.639539 \nL 198.427974 61.800282 \nL 198.529462 68.653455 \nL 198.630951 58.718168 \nL 198.732439 63.322486 \nL 198.935416 61.444763 \nL 199.036904 61.492082 \nL 199.442858 63.902385 \nL 199.544346 58.822821 \nL 199.645834 59.158855 \nL 199.747323 59.771982 \nL 199.848811 56.508654 \nL 199.950299 62.127695 \nL 200.051788 57.376025 \nL 200.254765 63.464667 \nL 200.356253 60.686287 \nL 200.457741 61.912541 \nL 200.55923 56.989204 \nL 200.660718 58.565034 \nL 200.863695 66.393208 \nL 200.965183 60.677026 \nL 201.066672 66.330872 \nL 201.16816 62.68711 \nL 201.371137 65.168169 \nL 201.472625 62.560459 \nL 201.574113 64.507983 \nL 201.675602 61.614644 \nL 201.77709 67.176975 \nL 201.878579 61.869954 \nL 201.980067 62.493062 \nL 202.183044 70.119226 \nL 202.284532 62.458998 \nL 202.38602 63.685113 \nL 202.487509 63.636533 \nL 202.588997 63.023476 \nL 202.690486 55.862536 \nL 202.893462 62.753097 \nL 202.994951 62.388995 \nL 203.096439 57.969309 \nL 203.197927 71.967656 \nL 203.299416 62.764842 \nL 203.400904 63.388103 \nL 203.502393 64.011364 \nL 204.009834 61.483713 \nL 204.212811 63.935864 \nL 204.415788 62.753097 \nL 204.618765 61.825898 \nL 204.720253 65.815457 \nL 204.821741 61.656088 \nL 204.92323 62.250267 \nL 205.024718 61.22924 \nL 205.126207 51.317202 \nL 205.227695 63.140326 \nL 205.430672 60.585614 \nL 205.735137 63.521136 \nL 205.836625 63.898517 \nL 206.14109 61.444763 \nL 206.242579 61.444763 \nL 206.445555 63.772442 \nL 206.547044 59.068953 \nL 206.648532 63.688779 \nL 206.851509 59.311285 \nL 206.952997 65.512257 \nL 207.155974 60.549444 \nL 207.257462 65.581624 \nL 207.358951 56.066714 \nL 207.561928 67.456326 \nL 207.663416 63.373307 \nL 207.764904 65.209193 \nL 207.866393 64.867774 \nL 207.967881 68.019784 \nL 208.170858 53.606342 \nL 208.373835 64.680765 \nL 208.475323 59.71633 \nL 208.6783 64.096669 \nL 208.779788 60.219502 \nL 208.881276 66.160361 \nL 208.982765 49.932772 \nL 209.185742 61.567802 \nL 209.28723 61.035923 \nL 209.388718 63.82638 \nL 209.490207 60.774784 \nL 209.591695 61.629313 \nL 209.693183 59.797114 \nL 209.794672 60.753385 \nL 209.89616 74.627789 \nL 209.997649 62.171125 \nL 210.099137 68.279578 \nL 210.200625 63.980299 \nL 210.302114 66.359318 \nL 210.403602 61.706532 \nL 210.606579 64.839791 \nL 210.708067 71.926616 \nL 210.911044 67.960167 \nL 211.012532 71.633773 \nL 211.114021 63.323617 \nL 211.215509 68.409303 \nL 211.316997 56.229767 \nL 211.519974 70.623176 \nL 211.722951 59.652485 \nL 211.824439 67.560118 \nL 212.027416 62.971812 \nL 212.128904 64.657008 \nL 212.230393 60.185396 \nL 212.331881 75.372826 \nL 212.43337 57.810946 \nL 212.534858 67.163003 \nL 212.636346 63.280737 \nL 212.737835 64.370141 \nL 212.940811 71.726714 \nL 213.0423 64.762368 \nL 213.143788 68.663216 \nL 213.245277 61.793863 \nL 213.549742 65.203237 \nL 213.752718 61.534615 \nL 213.955695 67.530493 \nL 214.158672 57.143621 \nL 214.361649 64.061432 \nL 214.463137 64.19487 \nL 214.666114 65.712881 \nL 214.767602 69.845681 \nL 214.869091 65.45109 \nL 214.970579 68.673002 \nL 215.072067 62.141908 \nL 215.173556 65.727639 \nL 215.275044 65.056129 \nL 215.376532 66.613276 \nL 215.478021 50.237301 \nL 215.579509 61.025387 \nL 215.680998 51.60606 \nL 215.782486 56.021957 \nL 215.883974 67.268775 \nL 215.985463 56.593766 \nL 216.086951 65.574007 \nL 216.391416 62.960548 \nL 216.492905 62.867844 \nL 216.594393 68.175143 \nL 216.79737 62.032602 \nL 216.898858 53.013693 \nL 217.101835 64.392759 \nL 217.203323 62.139428 \nL 217.304812 67.111806 \nL 217.4063 61.808305 \nL 217.507788 66.440278 \nL 217.609277 60.368293 \nL 217.710765 67.494758 \nL 217.913742 61.328681 \nL 218.01523 62.275999 \nL 218.218207 65.369766 \nL 218.319695 65.369766 \nL 218.421184 59.035584 \nL 218.522672 63.971567 \nL 218.62416 62.666843 \nL 218.725649 67.417998 \nL 218.827137 59.523072 \nL 219.030114 66.242447 \nL 219.233091 62.503489 \nL 219.334579 61.119241 \nL 219.436067 71.728167 \nL 219.639044 61.6313 \nL 219.740533 70.798694 \nL 219.943509 64.386212 \nL 220.044998 65.009462 \nL 220.146486 69.589855 \nL 220.247974 67.745377 \nL 220.349463 72.435268 \nL 220.55244 63.109452 \nL 220.653928 70.728641 \nL 220.755416 60.933057 \nL 220.856905 66.10099 \nL 221.059881 60.032824 \nL 221.16137 67.794927 \nL 221.262858 66.69303 \nL 221.364347 69.460638 \nL 221.567323 63.091375 \nL 221.668812 62.491019 \nL 221.7703 64.145393 \nL 221.871788 70.966198 \nL 222.074765 64.203956 \nL 222.176254 70.097101 \nL 222.37923 55.045075 \nL 222.582207 66.404521 \nL 222.683695 60.999672 \nL 222.886672 67.663667 \nL 222.988161 63.26263 \nL 223.089649 63.309081 \nL 223.292626 66.747924 \nL 223.394114 67.439804 \nL 223.495602 61.850932 \nL 223.698579 70.364585 \nL 223.901556 55.080989 \nL 224.003044 65.500775 \nL 224.104533 64.520578 \nL 224.206021 67.811316 \nL 224.510486 65.539295 \nL 224.611975 67.882715 \nL 224.713463 64.320106 \nL 224.814951 67.601944 \nL 224.91644 62.79915 \nL 225.322393 69.034422 \nL 225.423882 63.280747 \nL 225.728347 70.304895 \nL 225.829835 71.150091 \nL 225.931323 65.859971 \nL 226.1343 67.50781 \nL 226.337277 69.17836 \nL 226.438765 67.18046 \nL 226.641742 56.437982 \nL 226.844719 69.821439 \nL 226.946207 57.599728 \nL 227.149184 68.839543 \nL 227.453649 64.386847 \nL 227.758114 70.098647 \nL 227.859603 78.654148 \nL 227.961091 64.251806 \nL 228.062579 68.55509 \nL 228.164068 65.69277 \nL 228.265556 66.53415 \nL 228.468533 61.728384 \nL 228.570021 63.343236 \nL 228.67151 67.070091 \nL 228.874486 64.174494 \nL 229.077463 66.549204 \nL 229.28044 65.499142 \nL 229.381928 67.530792 \nL 229.584905 65.369766 \nL 229.686393 65.542073 \nL 229.787882 66.155151 \nL 229.88937 68.075063 \nL 230.092347 65.826128 \nL 230.193835 71.016211 \nL 230.396812 65.830191 \nL 230.4983 70.951918 \nL 230.701277 62.986851 \nL 230.802765 66.296921 \nL 230.904254 64.399081 \nL 231.107231 71.038584 \nL 231.208719 55.895884 \nL 231.310207 65.362626 \nL 231.411696 64.519463 \nL 231.513184 62.834911 \nL 231.614672 74.263154 \nL 231.716161 64.91407 \nL 231.817649 69.668315 \nL 232.020626 62.912878 \nL 232.223603 70.359519 \nL 232.528068 65.300257 \nL 232.629556 66.025796 \nL 232.731045 62.804648 \nL 232.832533 69.388007 \nL 232.934021 64.803908 \nL 233.03551 72.405756 \nL 233.136998 62.331378 \nL 233.238486 71.295653 \nL 233.441463 64.525206 \nL 233.542952 64.059302 \nL 233.64444 65.139718 \nL 233.745928 68.132476 \nL 233.847417 61.991145 \nL 233.948905 68.9727 \nL 234.050393 65.620426 \nL 234.25337 67.889589 \nL 234.659324 65.568357 \nL 234.760812 68.776922 \nL 234.8623 61.925013 \nL 234.963789 71.107934 \nL 235.065277 68.707732 \nL 235.166766 72.93093 \nL 235.268254 67.569848 \nL 235.369742 69.940026 \nL 235.572719 62.681689 \nL 235.674207 68.738149 \nL 235.775696 61.611461 \nL 235.978673 68.117677 \nL 236.080161 64.897457 \nL 236.283138 71.69771 \nL 236.486114 50.186342 \nL 236.689091 76.265687 \nL 236.892068 66.571478 \nL 237.095045 71.600564 \nL 237.298021 60.995793 \nL 237.39951 67.407553 \nL 237.500998 64.013907 \nL 237.602487 64.546953 \nL 237.703975 66.372332 \nL 237.906952 63.24312 \nL 238.00844 57.260282 \nL 238.109928 64.831002 \nL 238.211417 62.338612 \nL 238.312905 69.305881 \nL 238.414394 68.358092 \nL 238.61737 74.315388 \nL 238.718859 67.999912 \nL 238.820347 70.42736 \nL 238.921835 64.665568 \nL 239.023324 68.969117 \nL 239.124812 64.218081 \nL 239.327789 68.195513 \nL 239.530766 61.817826 \nL 239.632254 67.115047 \nL 239.733742 65.868872 \nL 239.835231 67.149921 \nL 239.936719 70.119374 \nL 240.139696 66.252977 \nL 240.241184 72.624834 \nL 240.342673 64.507928 \nL 240.444161 67.599773 \nL 240.545649 74.790696 \nL 240.748626 67.695524 \nL 240.850115 66.890177 \nL 241.053091 69.208387 \nL 241.357556 66.6781 \nL 241.459045 66.6781 \nL 241.662022 71.169694 \nL 241.76351 70.619629 \nL 241.864998 68.780486 \nL 241.966487 72.488909 \nL 242.169463 50.931053 \nL 242.37244 66.276686 \nL 242.473929 58.185548 \nL 242.778394 75.034143 \nL 242.879882 65.851168 \nL 242.98137 70.28781 \nL 243.082859 69.472607 \nL 243.184347 74.223643 \nL 243.285836 65.968795 \nL 243.488812 67.775715 \nL 243.894766 65.422169 \nL 244.097743 71.361075 \nL 244.300719 63.580233 \nL 244.503696 69.294769 \nL 244.605184 68.400377 \nL 244.808161 64.937245 \nL 245.011138 68.837682 \nL 245.112626 63.906363 \nL 245.214115 73.638439 \nL 245.417091 66.936351 \nL 245.51858 66.371933 \nL 245.620068 56.41712 \nL 245.721557 77.777291 \nL 245.924533 67.299492 \nL 246.026022 66.686454 \nL 246.12751 62.433857 \nL 246.330487 68.281895 \nL 246.533464 66.6781 \nL 246.634952 60.158066 \nL 246.837929 64.992166 \nL 246.939417 64.981481 \nL 247.243882 79.248424 \nL 247.446859 67.198538 \nL 247.548347 67.190863 \nL 247.649836 70.585478 \nL 247.751324 67.341442 \nL 247.852812 71.295169 \nL 248.055789 67.402121 \nL 248.258766 66.6781 \nL 248.360254 73.597278 \nL 248.461743 69.809484 \nL 248.563231 70.675281 \nL 248.664719 74.354517 \nL 248.867696 65.747653 \nL 248.969185 71.051276 \nL 249.070673 67.41678 \nL 249.172161 69.756373 \nL 249.27365 69.66327 \nL 249.375138 67.878854 \nL 249.476626 70.349805 \nL 249.679603 69.624611 \nL 249.781092 50.620016 \nL 249.88258 68.321427 \nL 249.984068 62.71355 \nL 250.187045 68.817598 \nL 250.288533 68.305732 \nL 250.390022 64.082612 \nL 250.49151 74.43805 \nL 250.592999 70.089703 \nL 250.795975 73.092465 \nL 250.897464 63.97635 \nL 251.10044 80.259998 \nL 251.303417 66.51468 \nL 251.404906 68.944369 \nL 251.506394 68.593861 \nL 251.607882 62.406444 \nL 251.709371 70.78965 \nL 251.912347 68.225919 \nL 252.115324 67.986435 \nL 252.318301 61.23554 \nL 252.521278 70.323466 \nL 252.622766 70.265188 \nL 252.724254 69.65215 \nL 252.927231 63.440494 \nL 253.02872 60.679627 \nL 253.130208 71.127757 \nL 253.231696 69.881562 \nL 253.434673 63.176922 \nL 253.536161 66.409914 \nL 253.63765 76.756819 \nL 253.739138 69.511307 \nL 253.840627 70.105189 \nL 253.942115 70.504039 \nL 254.145092 69.311594 \nL 254.449557 70.603103 \nL 254.551045 70.603103 \nL 254.956999 68.217648 \nL 255.159975 64.941318 \nL 255.261464 66.699883 \nL 255.464441 74.821669 \nL 255.768906 63.813315 \nL 255.870394 73.351571 \nL 256.073371 68.054443 \nL 256.174859 64.912255 \nL 256.276348 71.292325 \nL 256.479324 65.641609 \nL 256.580813 70.836544 \nL 256.682301 69.590349 \nL 256.783789 64.271473 \nL 256.885278 70.092307 \nL 256.986766 69.479417 \nL 257.088255 69.73025 \nL 257.189743 70.3535 \nL 257.39272 76.232325 \nL 257.595696 69.294769 \nL 257.798673 68.35183 \nL 257.900162 68.741641 \nL 258.103138 70.778887 \nL 258.204627 67.051375 \nL 258.306115 73.055541 \nL 258.61058 63.150175 \nL 258.712069 70.006442 \nL 258.813557 68.78003 \nL 258.915045 72.723605 \nL 259.016534 70.620921 \nL 259.118022 61.655248 \nL 259.21951 73.443471 \nL 259.320999 55.249979 \nL 259.523976 70.379172 \nL 259.625464 78.394782 \nL 259.726952 71.019215 \nL 259.828441 71.603825 \nL 259.929929 69.261838 \nL 260.031417 71.673662 \nL 260.437371 68.070096 \nL 260.640348 69.698107 \nL 260.843324 71.388979 \nL 260.944813 64.891435 \nL 261.14779 76.816623 \nL 261.249278 62.840496 \nL 261.350766 68.009111 \nL 261.452255 67.366831 \nL 261.553743 69.848511 \nL 261.655231 65.099375 \nL 261.858208 70.603103 \nL 261.959697 70.246067 \nL 262.162673 66.681888 \nL 262.36565 70.35153 \nL 262.568627 78.729688 \nL 262.771604 70.593829 \nL 262.97458 68.254813 \nL 263.076069 72.543605 \nL 263.177557 67.10067 \nL 263.279045 71.060911 \nL 263.482022 69.672362 \nL 263.583511 70.295449 \nL 263.684999 74.303422 \nL 263.786487 73.572477 \nL 263.989464 69.769236 \nL 264.192441 75.462158 \nL 264.598394 66.713182 \nL 264.699883 73.075214 \nL 264.801371 69.931982 \nL 264.902859 73.892532 \nL 265.207325 63.970692 \nL 265.308813 67.319378 \nL 265.410301 64.912851 \nL 265.51179 66.893402 \nL 265.613278 61.890935 \nL 265.816255 70.603103 \nL 266.019232 68.810242 \nL 266.12072 70.467412 \nL 266.323697 66.83009 \nL 266.425185 67.453177 \nL 266.526673 69.428508 \nL 266.628162 73.927112 \nL 266.72965 72.701036 \nL 266.831139 73.60215 \nL 266.932627 78.351405 \nL 267.034115 70.410859 \nL 267.237092 71.911437 \nL 267.33858 71.911437 \nL 267.440069 69.075205 \nL 267.541557 70.880109 \nL 267.744534 69.294769 \nL 267.846022 69.294769 \nL 268.048999 72.188861 \nL 268.150487 67.967523 \nL 268.251976 59.113985 \nL 268.353464 72.474641 \nL 268.454953 71.468457 \nL 268.556441 72.714325 \nL 268.657929 72.108867 \nL 269.063883 65.793028 \nL 269.26686 79.709485 \nL 269.469836 67.848479 \nL 269.571325 72.269708 \nL 269.672813 68.104094 \nL 269.87579 74.107709 \nL 269.977278 72.260397 \nL 270.078767 75.85581 \nL 270.180255 71.164677 \nL 270.281743 74.385716 \nL 270.383232 71.060579 \nL 270.48472 76.634061 \nL 270.586208 67.237839 \nL 270.687697 73.649119 \nL 270.789185 71.736642 \nL 270.890674 72.559877 \nL 270.992162 68.240636 \nL 271.195139 73.888619 \nL 271.296627 68.129857 \nL 271.499604 71.174048 \nL 271.601092 72.380682 \nL 271.702581 71.29019 \nL 271.804069 64.955461 \nL 271.905557 76.350194 \nL 272.007046 59.780334 \nL 272.108534 65.807172 \nL 272.210022 59.252222 \nL 272.412999 74.070988 \nL 272.615976 67.604395 \nL 272.717464 70.680393 \nL 272.818953 64.028943 \nL 273.021929 69.294769 \nL 273.224906 69.294769 \nL 273.326394 79.668282 \nL 273.427883 78.168003 \nL 273.529371 73.742605 \nL 273.63086 80.527006 \nL 273.732348 71.301135 \nL 273.833836 75.448682 \nL 274.036813 65.033172 \nL 274.341278 74.37593 \nL 274.544255 65.774367 \nL 274.747232 72.592519 \nL 274.84872 74.432137 \nL 274.950208 68.899196 \nL 275.254674 72.436571 \nL 275.356162 70.812578 \nL 275.559139 74.283059 \nL 275.660627 68.09799 \nL 275.762115 74.191631 \nL 275.863604 73.578583 \nL 276.066581 69.692898 \nL 276.168069 71.773238 \nL 276.269557 71.430943 \nL 276.371046 69.84088 \nL 276.574022 75.1428 \nL 276.675511 65.456527 \nL 276.776999 66.574337 \nL 276.878488 71.837066 \nL 277.182953 70.603103 \nL 277.284441 70.603103 \nL 277.487418 75.231383 \nL 277.690395 67.884096 \nL 277.791883 69.385348 \nL 277.99486 78.2806 \nL 278.096348 66.020484 \nL 278.197836 72.176992 \nL 278.299325 70.30773 \nL 278.400813 74.043362 \nL 278.502302 61.182919 \nL 278.60379 74.662519 \nL 278.705278 66.611488 \nL 278.908255 69.211887 \nL 279.009743 66.940809 \nL 279.111232 71.767329 \nL 279.21272 69.985685 \nL 279.314209 70.565438 \nL 279.517185 69.339343 \nL 279.618674 73.863592 \nL 279.720162 70.640996 \nL 280.126116 75.507041 \nL 280.227604 68.682708 \nL 280.430581 72.505977 \nL 280.532069 67.754941 \nL 280.735046 73.219772 \nL 280.836534 70.672637 \nL 280.938023 72.699678 \nL 281.039511 77.171289 \nL 281.242488 70.091082 \nL 281.445464 71.947286 \nL 281.648441 73.186894 \nL 281.851418 73.219772 \nL 282.155883 70.889954 \nL 282.35886 72.226865 \nL 282.561837 74.34004 \nL 282.764813 71.786082 \nL 282.866302 65.270422 \nL 283.069278 77.023947 \nL 283.272255 70.227709 \nL 283.475232 69.294769 \nL 283.57672 69.904898 \nL 283.678209 75.819733 \nL 283.982674 70.794677 \nL 284.084162 75.847541 \nL 284.185651 72.298137 \nL 284.287139 73.649842 \nL 284.388627 91.478802 \nL 284.490116 73.561804 \nL 284.591604 74.644099 \nL 284.794581 60.613001 \nL 284.896069 84.391318 \nL 284.997558 72.292889 \nL 285.200534 74.994278 \nL 285.302023 75.588355 \nL 285.403511 71.50129 \nL 285.504999 72.434746 \nL 285.606488 66.892055 \nL 285.809465 72.922212 \nL 286.012441 73.219772 \nL 286.11393 77.280892 \nL 286.215418 86.249233 \nL 286.316906 67.103622 \nL 286.418395 76.806366 \nL 286.519883 70.112103 \nL 286.621372 73.662068 \nL 286.72286 67.459072 \nL 286.824348 71.796193 \nL 287.027325 70.608301 \nL 287.128813 78.26107 \nL 287.230302 64.613653 \nL 287.433279 78.937976 \nL 287.534767 67.783715 \nL 287.636255 73.113455 \nL 287.839232 71.935102 \nL 288.042209 73.12292 \nL 288.143697 67.594716 \nL 288.245186 73.175436 \nL 288.346674 71.336233 \nL 288.549651 74.540138 \nL 288.651139 74.210682 \nL 288.752627 66.352436 \nL 288.854116 77.293301 \nL 289.057093 71.911175 \nL 289.260069 74.887722 \nL 289.361558 74.831587 \nL 289.564534 73.770463 \nL 289.666023 71.500338 \nL 289.869 78.968027 \nL 289.970488 68.373583 \nL 290.071976 72.812231 \nL 290.173465 72.199183 \nL 290.274953 66.309145 \nL 290.47793 74.528106 \nL 290.579418 73.355872 \nL 290.680907 64.242495 \nL 290.782395 73.442109 \nL 290.883883 71.722963 \nL 290.985372 78.347708 \nL 291.188348 72.061383 \nL 291.391325 70.817685 \nL 291.492814 71.84714 \nL 291.69579 70.620748 \nL 291.797279 72.443834 \nL 291.898767 72.367242 \nL 292.000255 68.405454 \nL 292.203232 75.888451 \nL 292.406209 63.162657 \nL 292.609186 72.211763 \nL 292.710674 67.79218 \nL 292.812162 73.342483 \nL 292.913651 71.50334 \nL 293.015139 66.932143 \nL 293.218116 74.82941 \nL 293.319604 73.851516 \nL 293.421093 74.393705 \nL 293.522581 71.651104 \nL 293.624069 65.296125 \nL 293.725558 72.745084 \nL 293.827046 72.151194 \nL 293.928535 72.276989 \nL 294.030023 72.890027 \nL 294.233 86.509208 \nL 294.435976 69.086967 \nL 294.638953 74.388909 \nL 294.740442 68.452785 \nL 294.943418 76.929987 \nL 295.044907 92.133601 \nL 295.247883 70.195487 \nL 295.349372 69.57239 \nL 295.45086 81.957826 \nL 295.856814 72.580277 \nL 295.958302 71.967387 \nL 296.05979 64.76172 \nL 296.161279 75.400155 \nL 296.364256 71.911437 \nL 296.567232 74.304689 \nL 296.668721 91.78939 \nL 296.770209 73.565342 \nL 296.871697 77.936287 \nL 296.973186 67.281337 \nL 297.176163 84.584478 \nL 297.277651 73.109202 \nL 297.379139 73.873088 \nL 297.480628 72.418584 \nL 297.582116 74.657954 \nL 297.785093 69.457717 \nL 297.886581 75.904929 \nL 297.98807 73.614655 \nL 298.191046 74.528106 \nL 298.394023 69.081621 \nL 298.495511 74.408652 \nL 298.597 69.272418 \nL 298.698488 75.594812 \nL 298.799977 71.605557 \nL 298.901465 71.893035 \nL 299.104442 80.230075 \nL 299.20593 79.564626 \nL 299.307418 78.346896 \nL 299.408907 74.52052 \nL 299.510395 79.155682 \nL 299.611884 66.910301 \nL 299.81486 76.660955 \nL 299.916349 80.000564 \nL 300.017837 66.808936 \nL 300.119325 72.290345 \nL 300.220814 69.838193 \nL 300.322302 72.993015 \nL 300.423791 71.672992 \nL 300.525279 78.718194 \nL 300.626767 67.404154 \nL 300.829744 74.528106 \nL 300.931232 75.283831 \nL 301.032721 77.823472 \nL 301.235698 73.872095 \nL 301.337186 73.278204 \nL 301.438674 81.787102 \nL 301.641651 72.96238 \nL 301.743139 73.105644 \nL 301.844628 73.048052 \nL 301.946116 72.454022 \nL 302.047605 73.407579 \nL 302.250581 63.708635 \nL 302.35207 79.720728 \nL 302.453558 70.778463 \nL 302.555046 77.849962 \nL 302.758023 66.258617 \nL 302.859512 72.720526 \nL 302.961 69.202172 \nL 303.062488 73.86472 \nL 303.163977 88.7033 \nL 303.366953 73.219772 \nL 303.468442 77.436853 \nL 303.56993 74.842901 \nL 303.671419 79.769966 \nL 303.772907 74.735288 \nL 303.874395 77.004485 \nL 303.975884 72.000635 \nL 304.077372 72.705537 \nL 304.280349 75.068425 \nL 304.381837 72.491551 \nL 304.584814 78.382783 \nL 304.686302 73.709948 \nL 304.889279 75.370973 \nL 305.092256 78.526472 \nL 305.193744 74.034474 \nL 305.295233 78.497348 \nL 305.498209 51.750447 \nL 305.599698 74.098879 \nL 305.701186 73.485841 \nL 305.904163 89.341875 \nL 306.005651 72.089821 \nL 306.10714 79.901076 \nL 306.310116 74.528106 \nL 306.513093 80.563007 \nL 306.71607 75.660027 \nL 306.817558 75.415719 \nL 307.020535 73.219772 \nL 307.122023 73.393846 \nL 307.426488 78.180569 \nL 307.527977 72.786849 \nL 307.629465 73.7909 \nL 307.730954 72.931512 \nL 307.832442 69.205169 \nL 307.93393 77.842629 \nL 308.035419 74.574512 \nL 308.136907 75.200755 \nL 308.238395 69.899227 \nL 308.339884 80.073492 \nL 308.542861 71.081088 \nL 308.745837 80.22396 \nL 308.847326 68.096435 \nL 309.151791 80.007141 \nL 309.253279 79.558597 \nL 309.354768 82.450673 \nL 309.557744 74.726883 \nL 309.659233 78.849741 \nL 309.760721 73.94246 \nL 309.862209 75.366119 \nL 309.963698 73.799597 \nL 310.065186 74.433079 \nL 310.166675 79.940887 \nL 310.47114 72.15831 \nL 310.572628 77.500229 \nL 310.674116 75.37069 \nL 310.775605 76.596786 \nL 310.877093 74.040834 \nL 311.08007 81.934693 \nL 311.283047 67.529904 \nL 311.384535 74.797445 \nL 311.486023 74.22324 \nL 311.587512 74.514909 \nL 311.689 79.214784 \nL 311.891977 63.605732 \nL 312.094954 76.695343 \nL 312.196442 74.166317 \nL 312.29793 68.013917 \nL 312.500907 75.613145 \nL 312.703884 71.913944 \nL 312.805372 71.153512 \nL 312.906861 68.34681 \nL 313.008349 76.871633 \nL 313.109837 75.725612 \nL 313.211326 72.916401 \nL 313.312814 65.983408 \nL 313.515791 77.940929 \nL 313.617279 72.299107 \nL 313.820256 75.099929 \nL 313.921744 79.735205 \nL 314.023233 79.558363 \nL 314.124721 80.789587 \nL 314.327698 74.61763 \nL 314.429186 76.248438 \nL 314.530675 71.828854 \nL 314.632163 77.142893 \nL 314.733651 70.682289 \nL 314.83514 77.465429 \nL 314.936628 74.661675 \nL 315.038117 77.995785 \nL 315.241093 72.921271 \nL 315.342582 73.085083 \nL 315.44407 74.331584 \nL 315.647047 73.380148 \nL 315.748535 64.238886 \nL 316.053 85.332686 \nL 316.255977 65.802935 \nL 316.560442 88.584615 \nL 316.661931 91.523391 \nL 316.864907 75.052625 \nL 316.966396 63.534056 \nL 317.067884 66.14912 \nL 317.169372 79.96243 \nL 317.270861 73.152936 \nL 317.372349 73.526076 \nL 317.473838 87.683567 \nL 317.778303 73.454357 \nL 317.879791 77.677555 \nL 317.981279 75.299116 \nL 318.082768 81.300409 \nL 318.285745 71.029487 \nL 318.488721 78.521259 \nL 318.59021 73.456542 \nL 318.894675 75.312956 \nL 319.097652 72.812414 \nL 319.19914 82.050353 \nL 319.503605 73.888538 \nL 319.605093 78.190117 \nL 319.80807 74.054603 \nL 320.011047 82.169957 \nL 320.112535 71.801494 \nL 320.315512 80.190376 \nL 320.417 71.84284 \nL 320.518489 75.858462 \nL 320.619977 72.755716 \nL 320.721466 74.194879 \nL 320.822954 83.196818 \nL 320.924442 67.219836 \nL 321.025931 74.15714 \nL 321.127419 73.534206 \nL 321.228907 75.43497 \nL 321.431884 84.630842 \nL 321.533373 70.900515 \nL 321.634861 73.548508 \nL 321.736349 79.487228 \nL 321.837838 68.954142 \nL 321.939326 78.851806 \nL 322.040814 68.154625 \nL 322.142303 77.824842 \nL 322.243791 69.70964 \nL 322.34528 82.459774 \nL 322.446768 71.551977 \nL 322.548256 74.904372 \nL 322.649745 73.678277 \nL 322.852721 78.737892 \nL 322.95421 68.774573 \nL 323.258675 79.096691 \nL 323.360163 75.865887 \nL 323.461652 82.939853 \nL 323.664628 72.130039 \nL 323.766117 75.387678 \nL 323.867605 69.648327 \nL 323.969094 73.758747 \nL 324.070582 72.570984 \nL 324.273559 74.569704 \nL 324.476535 75.79578 \nL 324.578024 75.612543 \nL 324.679512 81.778691 \nL 324.781001 77.512786 \nL 324.882489 77.902962 \nL 324.983977 76.116968 \nL 325.085466 79.338007 \nL 325.288442 75.906725 \nL 325.389931 76.436177 \nL 325.491419 77.343198 \nL 325.592908 69.738176 \nL 325.694396 78.913844 \nL 325.795884 77.797976 \nL 325.897373 73.984847 \nL 325.998861 81.903306 \nL 326.303326 75.181694 \nL 326.404815 74.568647 \nL 326.607791 75.676308 \nL 326.70928 75.356107 \nL 326.810768 72.688818 \nL 326.912256 73.823236 \nL 327.013745 81.231137 \nL 327.115233 76.294097 \nL 327.216722 57.161404 \nL 327.419698 74.493968 \nL 327.622675 73.247467 \nL 327.724163 79.750389 \nL 327.825652 76.384349 \nL 327.92714 76.978379 \nL 328.130117 67.172921 \nL 328.333094 80.108938 \nL 328.53607 72.622556 \nL 328.739047 77.827535 \nL 328.942024 73.93678 \nL 329.043512 80.832636 \nL 329.145001 78.124037 \nL 329.246489 79.021018 \nL 329.347977 72.117627 \nL 329.449466 79.782824 \nL 329.550954 70.38009 \nL 329.652443 76.042222 \nL 329.753931 74.071107 \nL 329.855419 69.321615 \nL 330.058396 75.687284 \nL 330.159884 75.064187 \nL 330.261373 75.58968 \nL 330.362861 83.191283 \nL 330.46435 73.504683 \nL 330.565838 74.872115 \nL 330.667326 72.391916 \nL 330.768815 72.453026 \nL 330.870303 74.279673 \nL 330.971791 72.011755 \nL 331.07328 74.825044 \nL 331.174768 72.372853 \nL 331.377745 79.602735 \nL 331.580722 74.212692 \nL 331.68221 77.566848 \nL 331.783698 77.083816 \nL 331.885187 80.20007 \nL 331.986675 73.486835 \nL 332.189652 79.880466 \nL 332.29114 78.205556 \nL 332.392629 76.600635 \nL 332.494117 79.092371 \nL 332.595605 76.310266 \nL 332.697094 77.790806 \nL 332.798582 73.317791 \nL 332.900071 76.71007 \nL 333.001559 75.028372 \nL 333.103047 75.622253 \nL 333.204536 79.884409 \nL 333.306024 75.156626 \nL 333.509001 77.144774 \nL 333.610489 77.144774 \nL 333.711978 77.022719 \nL 333.914954 74.530983 \nL 334.016443 61.526878 \nL 334.117931 78.712804 \nL 334.320908 75.197589 \nL 334.422396 65.147578 \nL 334.523885 80.89179 \nL 334.625373 77.311669 \nL 334.726861 81.79731 \nL 334.82835 80.657694 \nL 334.929838 74.144187 \nL 335.132815 75.83644 \nL 335.234303 75.83644 \nL 335.335792 78.561634 \nL 335.538768 75.948018 \nL 335.741745 82.293244 \nL 335.843233 77.33955 \nL 335.944722 81.585599 \nL 336.04621 80.915422 \nL 336.147699 71.629848 \nL 336.249187 74.829417 \nL 336.350675 73.286407 \nL 336.553652 80.194699 \nL 336.65514 75.950703 \nL 336.756629 90.746938 \nL 336.858117 73.324095 \nL 336.959606 79.839942 \nL 337.162582 78.071325 \nL 337.264071 91.317217 \nL 337.365559 73.717966 \nL 337.467047 90.435363 \nL 337.670024 69.424441 \nL 337.873001 80.788793 \nL 337.974489 76.806627 \nL 338.075978 80.807489 \nL 338.177466 72.705141 \nL 338.278954 73.294292 \nL 338.380443 78.14895 \nL 338.481931 74.6132 \nL 338.887885 77.993374 \nL 338.989373 75.82858 \nL 339.090861 78.535472 \nL 339.19235 74.589486 \nL 339.293838 82.548297 \nL 339.496815 73.799129 \nL 339.598303 85.725938 \nL 339.80128 67.847847 \nL 339.902768 74.884737 \nL 340.004257 73.045594 \nL 340.308722 83.325122 \nL 340.41021 72.58977 \nL 340.613187 75.180122 \nL 340.917652 77.030009 \nL 341.120629 88.103391 \nL 341.222117 70.695411 \nL 341.323606 71.664031 \nL 341.425094 64.592532 \nL 341.526582 84.922723 \nL 341.628071 83.755147 \nL 341.729559 83.006573 \nL 341.932536 71.339388 \nL 342.135513 79.71175 \nL 342.237001 71.3913 \nL 342.541466 78.224456 \nL 342.744443 79.603318 \nL 342.94742 74.528106 \nL 343.048908 80.887351 \nL 343.150396 78.932125 \nL 343.251885 82.238078 \nL 343.353373 67.096141 \nL 343.55635 78.453109 \nL 343.657838 76.888366 \nL 343.759327 71.18584 \nL 343.860815 75.701162 \nL 343.962303 74.986561 \nL 344.16528 68.324956 \nL 344.266769 90.524531 \nL 344.368257 77.056647 \nL 344.469745 77.464963 \nL 344.571234 75.240824 \nL 344.875699 78.001576 \nL 344.977187 78.124593 \nL 345.281652 75.156087 \nL 345.383141 74.571324 \nL 345.586117 78.453109 \nL 345.789094 77.443465 \nL 345.890583 66.058329 \nL 346.093559 92.791728 \nL 346.296536 75.789924 \nL 346.398024 71.566648 \nL 346.499513 77.455207 \nL 346.601001 74.046795 \nL 346.70249 75.423213 \nL 346.803978 74.081854 \nL 346.905466 81.22392 \nL 347.006955 76.047983 \nL 347.108443 76.315603 \nL 347.209931 72.782229 \nL 347.31142 77.578595 \nL 347.412908 74.570586 \nL 347.514397 90.12013 \nL 347.615885 80.075947 \nL 347.717373 89.586659 \nL 347.92035 76.860311 \nL 348.021838 77.14018 \nL 348.123327 80.518714 \nL 348.224815 74.60997 \nL 348.326304 82.215811 \nL 348.427792 76.822637 \nL 348.52928 77.450113 \nL 348.630769 79.103909 \nL 348.833745 69.072134 \nL 348.935234 82.296289 \nL 349.036722 77.558069 \nL 349.138211 90.792395 \nL 349.239699 74.757664 \nL 349.442676 79.86748 \nL 349.544164 74.337274 \nL 349.645652 107.011695 \nL 349.747141 105.781904 \nL 349.848629 105.038248 \nL 350.051606 105.886408 \nL 350.153094 106.839041 \nL 350.254583 104.668085 \nL 350.457559 107.236463 \nL 350.863513 107.236463 \nL 351.06649 106.240778 \nL 351.167978 106.341409 \nL 351.370955 108.368565 \nL 351.472443 105.928128 \nL 351.472443 105.928128 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 31.890625 118.154489 \nL 31.890625 19.318125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 366.690625 118.154489 \nL 366.690625 19.318125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 31.890625 118.154489 \nL 366.690625 118.154489 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 31.890625 19.318125 \nL 366.690625 19.318125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n  </g>\n  <g id=\"axes_2\">\n   <g id=\"patch_7\">\n    <path d=\"M 31.890625 236.758125 \nL 366.690625 236.758125 \nL 366.690625 137.921761 \nL 31.890625 137.921761 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_3\">\n    <g id=\"xtick_8\">\n     <g id=\"line2d_13\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"47.108807\" xlink:href=\"#mdaca23a825\" y=\"236.758125\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 0 -->\n      <g transform=\"translate(43.291307 252.87625)scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_9\">\n     <g id=\"line2d_14\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"85.345445\" xlink:href=\"#mdaca23a825\" y=\"236.758125\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 25 -->\n      <g transform=\"translate(77.710445 252.87625)scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_10\">\n     <g id=\"line2d_15\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"123.582082\" xlink:href=\"#mdaca23a825\" y=\"236.758125\"/>\n      </g>\n     </g>\n     <g id=\"text_15\">\n      <!-- 50 -->\n      <g transform=\"translate(115.947082 252.87625)scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_11\">\n     <g id=\"line2d_16\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"161.81872\" xlink:href=\"#mdaca23a825\" y=\"236.758125\"/>\n      </g>\n     </g>\n     <g id=\"text_16\">\n      <!-- 75 -->\n      <defs>\n       <path d=\"M 8.203125 72.90625 \nL 55.078125 72.90625 \nL 55.078125 68.703125 \nL 28.609375 0 \nL 18.3125 0 \nL 43.21875 64.59375 \nL 8.203125 64.59375 \nz\n\" id=\"DejaVuSans-55\"/>\n      </defs>\n      <g transform=\"translate(154.18372 252.87625)scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-55\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_12\">\n     <g id=\"line2d_17\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"200.055358\" xlink:href=\"#mdaca23a825\" y=\"236.758125\"/>\n      </g>\n     </g>\n     <g id=\"text_17\">\n      <!-- 100 -->\n      <g transform=\"translate(188.602858 252.87625)scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_13\">\n     <g id=\"line2d_18\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"238.291995\" xlink:href=\"#mdaca23a825\" y=\"236.758125\"/>\n      </g>\n     </g>\n     <g id=\"text_18\">\n      <!-- 125 -->\n      <g transform=\"translate(226.839495 252.87625)scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_14\">\n     <g id=\"line2d_19\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"276.528633\" xlink:href=\"#mdaca23a825\" y=\"236.758125\"/>\n      </g>\n     </g>\n     <g id=\"text_19\">\n      <!-- 150 -->\n      <g transform=\"translate(265.076133 252.87625)scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_15\">\n     <g id=\"line2d_20\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"314.765271\" xlink:href=\"#mdaca23a825\" y=\"236.758125\"/>\n      </g>\n     </g>\n     <g id=\"text_20\">\n      <!-- 175 -->\n      <g transform=\"translate(303.312771 252.87625)scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-55\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_16\">\n     <g id=\"line2d_21\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"353.001909\" xlink:href=\"#mdaca23a825\" y=\"236.758125\"/>\n      </g>\n     </g>\n     <g id=\"text_21\">\n      <!-- 200 -->\n      <g transform=\"translate(341.549409 252.87625)scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_4\">\n    <g id=\"ytick_5\">\n     <g id=\"line2d_22\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"31.890625\" xlink:href=\"#m80a1977b82\" y=\"235.807228\"/>\n      </g>\n     </g>\n     <g id=\"text_22\">\n      <!-- âˆ’2 -->\n      <g transform=\"translate(7.2 240.366291)scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-8722\"/>\n       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_23\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"31.890625\" xlink:href=\"#m80a1977b82\" y=\"210.464236\"/>\n      </g>\n     </g>\n     <g id=\"text_23\">\n      <!-- âˆ’1 -->\n      <g transform=\"translate(7.2 215.023298)scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-8722\"/>\n       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-49\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_7\">\n     <g id=\"line2d_24\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"31.890625\" xlink:href=\"#m80a1977b82\" y=\"185.121243\"/>\n      </g>\n     </g>\n     <g id=\"text_24\">\n      <!-- 0 -->\n      <g transform=\"translate(17.255625 189.680306)scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_8\">\n     <g id=\"line2d_25\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"31.890625\" xlink:href=\"#m80a1977b82\" y=\"159.778251\"/>\n      </g>\n     </g>\n     <g id=\"text_25\">\n      <!-- 1 -->\n      <g transform=\"translate(17.255625 164.337313)scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_26\">\n    <path clip-path=\"url(#paf4d790050)\" d=\"M 47.108807 230.706339 \nL 56.2856 230.706339 \nL 57.815065 231.138528 \nL 62.403462 231.138528 \nL 63.932927 231.365529 \nL 65.462393 231.870289 \nL 66.991858 231.870289 \nL 68.521324 232.021176 \nL 80.757048 232.027 \nL 82.286514 231.238536 \nL 83.815979 231.238536 \nL 85.345445 231.095649 \nL 86.87491 231.095649 \nL 88.404376 232.027 \nL 89.933841 232.265563 \nL 91.463307 232.027 \nL 96.051703 232.07961 \nL 97.581169 231.095649 \nL 99.110634 230.616388 \nL 100.6401 230.497625 \nL 102.169565 229.400852 \nL 105.228496 229.202899 \nL 106.757962 200.83534 \nL 108.287427 200.210983 \nL 109.816893 192.080124 \nL 111.346358 187.395304 \nL 112.875824 142.414323 \nL 118.993686 142.414323 \nL 120.523151 142.536552 \nL 122.052617 146.924714 \nL 123.582082 149.254994 \nL 125.111548 149.97377 \nL 126.641013 151.272903 \nL 128.170479 152.050751 \nL 129.699944 152.968921 \nL 131.22941 153.078886 \nL 132.758875 154.320014 \nL 134.288341 154.977089 \nL 135.817806 156.629192 \nL 137.347272 156.629192 \nL 138.876737 157.383533 \nL 143.465134 157.808631 \nL 144.994599 158.931258 \nL 146.524065 158.96882 \nL 148.05353 160.551807 \nL 149.582996 160.723988 \nL 151.112461 162.135711 \nL 152.641927 162.308073 \nL 154.171392 163.329464 \nL 155.700858 163.52131 \nL 157.230323 164.984876 \nL 160.289255 165.005713 \nL 161.81872 166.508432 \nL 163.348186 166.562431 \nL 164.877651 168.152658 \nL 167.936582 168.634456 \nL 169.466048 169.555532 \nL 170.995513 169.555532 \nL 172.524979 169.714499 \nL 177.113375 169.755956 \nL 180.172306 169.755956 \nL 181.701772 170.202385 \nL 183.231237 170.87973 \nL 189.349099 170.87973 \nL 190.878565 169.561573 \nL 192.40803 171.861245 \nL 195.466961 171.861245 \nL 196.996427 171.425206 \nL 200.055358 171.425206 \nL 201.584823 170.672803 \nL 203.114289 170.672803 \nL 204.643754 171.100442 \nL 207.702685 171.100442 \nL 209.232151 170.672803 \nL 210.761616 168.04547 \nL 212.291082 171.100442 \nL 213.820547 171.100442 \nL 215.350013 172.164623 \nL 218.408944 172.164623 \nL 219.938409 171.342911 \nL 221.467875 171.342911 \nL 222.99734 172.695758 \nL 232.174133 172.695758 \nL 233.703599 177.367411 \nL 235.233064 177.50357 \nL 236.76253 177.367411 \nL 238.291995 177.607723 \nL 239.821461 177.367411 \nL 241.350927 175.67494 \nL 244.409858 175.67494 \nL 245.939323 176.929656 \nL 247.468789 176.282294 \nL 248.998254 176.282294 \nL 250.52772 176.929656 \nL 253.586651 176.929656 \nL 255.116116 178.798623 \nL 256.645582 178.798623 \nL 258.175047 179.159242 \nL 259.704513 179.159242 \nL 261.233978 179.931467 \nL 262.763444 179.159242 \nL 264.292909 179.159242 \nL 265.822375 178.798623 \nL 267.35184 180.182567 \nL 268.881306 181.35199 \nL 274.999168 181.35199 \nL 276.528633 181.628267 \nL 281.11703 181.628267 \nL 282.646495 181.844983 \nL 284.175961 182.501712 \nL 285.705426 181.628267 \nL 288.764357 181.628267 \nL 290.293823 181.035883 \nL 291.823288 181.035883 \nL 293.352754 182.837857 \nL 296.411685 182.837857 \nL 297.94115 183.419859 \nL 299.470616 183.419859 \nL 301.000081 183.537898 \nL 302.529547 183.537898 \nL 304.059012 183.969972 \nL 305.588478 183.537898 \nL 307.117943 183.419859 \nL 308.647409 184.919153 \nL 310.176874 184.919153 \nL 311.70634 182.458537 \nL 313.235805 184.919153 \nL 314.765271 183.898353 \nL 317.824202 183.898353 \nL 319.353667 184.986912 \nL 320.883133 185.708842 \nL 322.412599 184.986912 \nL 325.47153 186.345871 \nL 328.530461 186.345871 \nL 330.059926 186.830951 \nL 331.589392 186.830951 \nL 333.118857 189.033801 \nL 334.648323 186.465612 \nL 337.707254 186.465612 \nL 339.236719 185.18526 \nL 340.766185 184.629671 \nL 342.29565 185.18526 \nL 346.884047 185.18526 \nL 348.413512 186.055348 \nL 349.942978 190.375744 \nL 351.472443 227.506752 \nL 351.472443 227.506752 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_8\">\n    <path d=\"M 31.890625 236.758125 \nL 31.890625 137.921761 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_9\">\n    <path d=\"M 366.690625 236.758125 \nL 366.690625 137.921761 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_10\">\n    <path d=\"M 31.890625 236.758125 \nL 366.690625 236.758125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_11\">\n    <path d=\"M 31.890625 137.921761 \nL 366.690625 137.921761 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"pc18bc85bae\">\n   <rect height=\"98.836364\" width=\"334.8\" x=\"31.890625\" y=\"19.318125\"/>\n  </clipPath>\n  <clipPath id=\"paf4d790050\">\n   <rect height=\"98.836364\" width=\"334.8\" x=\"31.890625\" y=\"137.921761\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 2 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"262.571875pt\" version=\"1.1\" viewBox=\"0 0 375.437057 262.571875\" width=\"375.437057pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <defs>\n  <style type=\"text/css\">\n*{stroke-linecap:butt;stroke-linejoin:round;}\n  </style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 262.571875 \nL 375.437057 262.571875 \nL 375.437057 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 33.28375 118.154489 \nL 368.08375 118.154489 \nL 368.08375 19.318125 \nL 33.28375 19.318125 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m7274dfab3f\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"48.501932\" xlink:href=\"#m7274dfab3f\" y=\"118.154489\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <defs>\n       <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n      </defs>\n      <g transform=\"translate(44.684432 134.272614)scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"99.246119\" xlink:href=\"#m7274dfab3f\" y=\"118.154489\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 500 -->\n      <defs>\n       <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n      </defs>\n      <g transform=\"translate(87.793619 134.272614)scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"149.990307\" xlink:href=\"#m7274dfab3f\" y=\"118.154489\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 1000 -->\n      <defs>\n       <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n      </defs>\n      <g transform=\"translate(134.720307 134.272614)scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"200.734494\" xlink:href=\"#m7274dfab3f\" y=\"118.154489\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 1500 -->\n      <g transform=\"translate(185.464494 134.272614)scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"251.478682\" xlink:href=\"#m7274dfab3f\" y=\"118.154489\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 2000 -->\n      <defs>\n       <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n      </defs>\n      <g transform=\"translate(236.208682 134.272614)scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"302.222869\" xlink:href=\"#m7274dfab3f\" y=\"118.154489\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 2500 -->\n      <g transform=\"translate(286.952869 134.272614)scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_7\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"352.967057\" xlink:href=\"#m7274dfab3f\" y=\"118.154489\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 3000 -->\n      <defs>\n       <path d=\"M 40.578125 39.3125 \nQ 47.65625 37.796875 51.625 33 \nQ 55.609375 28.21875 55.609375 21.1875 \nQ 55.609375 10.40625 48.1875 4.484375 \nQ 40.765625 -1.421875 27.09375 -1.421875 \nQ 22.515625 -1.421875 17.65625 -0.515625 \nQ 12.796875 0.390625 7.625 2.203125 \nL 7.625 11.71875 \nQ 11.71875 9.328125 16.59375 8.109375 \nQ 21.484375 6.890625 26.8125 6.890625 \nQ 36.078125 6.890625 40.9375 10.546875 \nQ 45.796875 14.203125 45.796875 21.1875 \nQ 45.796875 27.640625 41.28125 31.265625 \nQ 36.765625 34.90625 28.71875 34.90625 \nL 20.21875 34.90625 \nL 20.21875 43.015625 \nL 29.109375 43.015625 \nQ 36.375 43.015625 40.234375 45.921875 \nQ 44.09375 48.828125 44.09375 54.296875 \nQ 44.09375 59.90625 40.109375 62.90625 \nQ 36.140625 65.921875 28.71875 65.921875 \nQ 24.65625 65.921875 20.015625 65.03125 \nQ 15.375 64.15625 9.8125 62.3125 \nL 9.8125 71.09375 \nQ 15.4375 72.65625 20.34375 73.4375 \nQ 25.25 74.21875 29.59375 74.21875 \nQ 40.828125 74.21875 47.359375 69.109375 \nQ 53.90625 64.015625 53.90625 55.328125 \nQ 53.90625 49.265625 50.4375 45.09375 \nQ 46.96875 40.921875 40.578125 39.3125 \nz\n\" id=\"DejaVuSans-51\"/>\n      </defs>\n      <g transform=\"translate(337.697057 134.272614)scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_8\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"m6c4aab5eba\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.28375\" xlink:href=\"#m6c4aab5eba\" y=\"115.224836\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 0.0 -->\n      <defs>\n       <path d=\"M 10.6875 12.40625 \nL 21 12.40625 \nL 21 0 \nL 10.6875 0 \nz\n\" id=\"DejaVuSans-46\"/>\n      </defs>\n      <g transform=\"translate(7.2 119.783898)scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_9\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.28375\" xlink:href=\"#m6c4aab5eba\" y=\"69.499777\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 0.5 -->\n      <g transform=\"translate(7.2 74.058839)scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.28375\" xlink:href=\"#m6c4aab5eba\" y=\"23.774717\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 1.0 -->\n      <g transform=\"translate(7.2 28.33378)scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-46\"/>\n       <use x=\"95.410156\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_11\">\n     <!-- 1eâˆ’9 -->\n     <defs>\n      <path d=\"M 56.203125 29.59375 \nL 56.203125 25.203125 \nL 14.890625 25.203125 \nQ 15.484375 15.921875 20.484375 11.0625 \nQ 25.484375 6.203125 34.421875 6.203125 \nQ 39.59375 6.203125 44.453125 7.46875 \nQ 49.3125 8.734375 54.109375 11.28125 \nL 54.109375 2.78125 \nQ 49.265625 0.734375 44.1875 -0.34375 \nQ 39.109375 -1.421875 33.890625 -1.421875 \nQ 20.796875 -1.421875 13.15625 6.1875 \nQ 5.515625 13.8125 5.515625 26.8125 \nQ 5.515625 40.234375 12.765625 48.109375 \nQ 20.015625 56 32.328125 56 \nQ 43.359375 56 49.78125 48.890625 \nQ 56.203125 41.796875 56.203125 29.59375 \nz\nM 47.21875 32.234375 \nQ 47.125 39.59375 43.09375 43.984375 \nQ 39.0625 48.390625 32.421875 48.390625 \nQ 24.90625 48.390625 20.390625 44.140625 \nQ 15.875 39.890625 15.1875 32.171875 \nz\n\" id=\"DejaVuSans-101\"/>\n      <path d=\"M 10.59375 35.5 \nL 73.1875 35.5 \nL 73.1875 27.203125 \nL 10.59375 27.203125 \nz\n\" id=\"DejaVuSans-8722\"/>\n      <path d=\"M 10.984375 1.515625 \nL 10.984375 10.5 \nQ 14.703125 8.734375 18.5 7.8125 \nQ 22.3125 6.890625 25.984375 6.890625 \nQ 35.75 6.890625 40.890625 13.453125 \nQ 46.046875 20.015625 46.78125 33.40625 \nQ 43.953125 29.203125 39.59375 26.953125 \nQ 35.25 24.703125 29.984375 24.703125 \nQ 19.046875 24.703125 12.671875 31.3125 \nQ 6.296875 37.9375 6.296875 49.421875 \nQ 6.296875 60.640625 12.9375 67.421875 \nQ 19.578125 74.21875 30.609375 74.21875 \nQ 43.265625 74.21875 49.921875 64.515625 \nQ 56.59375 54.828125 56.59375 36.375 \nQ 56.59375 19.140625 48.40625 8.859375 \nQ 40.234375 -1.421875 26.421875 -1.421875 \nQ 22.703125 -1.421875 18.890625 -0.6875 \nQ 15.09375 0.046875 10.984375 1.515625 \nz\nM 30.609375 32.421875 \nQ 37.25 32.421875 41.125 36.953125 \nQ 45.015625 41.5 45.015625 49.421875 \nQ 45.015625 57.28125 41.125 61.84375 \nQ 37.25 66.40625 30.609375 66.40625 \nQ 23.96875 66.40625 20.09375 61.84375 \nQ 16.21875 57.28125 16.21875 49.421875 \nQ 16.21875 41.5 20.09375 36.953125 \nQ 23.96875 32.421875 30.609375 32.421875 \nz\n\" id=\"DejaVuSans-57\"/>\n     </defs>\n     <g transform=\"translate(33.28375 16.318125)scale(0.12 -0.12)\">\n      <use xlink:href=\"#DejaVuSans-49\"/>\n      <use x=\"63.623047\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"125.146484\" xlink:href=\"#DejaVuSans-8722\"/>\n      <use x=\"208.935547\" xlink:href=\"#DejaVuSans-57\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_11\">\n    <path clip-path=\"url(#p4e985cf6a1)\" d=\"M 48.501932 113.578734 \nL 49.618304 113.395833 \nL 50.227234 113.491377 \nL 51.851048 113.559663 \nL 52.054025 113.557778 \nL 52.459978 113.557102 \nL 53.068909 113.578734 \nL 54.591234 113.470914 \nL 58.549281 113.283769 \nL 59.158211 113.496925 \nL 59.665653 113.578734 \nL 61.187979 113.455445 \nL 62.304351 113.541534 \nL 64.435607 113.185302 \nL 64.740072 113.121483 \nL 65.856444 113.488497 \nL 66.668351 113.487284 \nL 69.002584 113.38062 \nL 70.524909 113.367301 \nL 71.133839 113.449156 \nL 71.945746 113.520889 \nL 72.859142 113.487284 \nL 81.993096 113.593672 \nL 82.602026 113.635981 \nL 82.805003 113.587534 \nL 83.210956 113.634777 \nL 83.515421 113.52671 \nL 83.819886 113.487284 \nL 84.124351 112.215831 \nL 84.327328 100.000603 \nL 84.428817 99.268838 \nL 84.631793 89.666853 \nL 84.733282 88.992474 \nL 84.936258 82.414939 \nL 85.240724 84.07013 \nL 85.342212 81.059491 \nL 85.4437 81.999746 \nL 85.646677 76.839147 \nL 85.748165 77.390782 \nL 85.951142 78.494052 \nL 86.154119 70.930239 \nL 86.255607 70.630457 \nL 86.357096 72.870934 \nL 86.560072 67.172968 \nL 86.661561 67.851967 \nL 86.864538 64.64023 \nL 87.067514 64.129403 \nL 87.169003 64.369631 \nL 87.574956 66.428511 \nL 87.676445 66.706898 \nL 87.98091 60.440137 \nL 88.285375 57.611261 \nL 88.488352 57.52094 \nL 88.691328 52.362552 \nL 88.894305 51.212982 \nL 89.097282 46.736435 \nL 89.401747 45.722745 \nL 89.604724 45.722745 \nL 89.8077 41.313039 \nL 90.112166 39.375131 \nL 90.315142 37.549938 \nL 90.619607 27.370547 \nL 91.025561 26.577947 \nL 91.330026 28.347226 \nL 91.73598 28.347226 \nL 92.040445 29.475801 \nL 92.446398 32.522035 \nL 92.852352 33.753638 \nL 93.56277 32.909841 \nL 93.968724 31.127985 \nL 94.679142 36.229946 \nL 94.882119 36.577732 \nL 95.897003 36.474653 \nL 96.404445 33.781649 \nL 97.013375 28.967064 \nL 97.419329 24.438591 \nL 97.723794 23.810687 \nL 98.434212 24.674779 \nL 98.941654 23.821722 \nL 99.85505 25.603722 \nL 100.261003 25.603722 \nL 100.869933 26.518224 \nL 101.07291 26.54494 \nL 101.783329 27.432725 \nL 101.986305 27.432725 \nL 102.290771 28.412446 \nL 102.798212 30.148513 \nL 103.407143 30.398753 \nL 103.914585 31.090725 \nL 104.117561 31.166115 \nL 104.422026 32.005226 \nL 104.625003 32.005226 \nL 104.726492 32.126696 \nL 105.030957 32.919727 \nL 105.43691 32.919727 \nL 105.842864 33.834229 \nL 106.147329 33.834229 \nL 106.451794 34.386238 \nL 106.654771 34.74873 \nL 106.959236 34.765412 \nL 107.263701 35.663231 \nL 107.669654 35.663231 \nL 107.872631 36.034887 \nL 108.177096 36.577732 \nL 108.380073 36.577732 \nL 108.887515 37.305356 \nL 109.090492 37.492234 \nL 109.394957 37.492234 \nL 109.699422 38.335161 \nL 110.003887 37.492234 \nL 110.206864 37.492234 \nL 110.511329 38.322213 \nL 111.526213 40.235738 \nL 112.33812 40.297151 \nL 113.251515 42.06474 \nL 113.657469 42.148735 \nL 113.961934 42.887107 \nL 114.063422 42.825145 \nL 114.367887 42.086263 \nL 115.382771 43.869761 \nL 115.991701 43.924586 \nL 116.296166 44.808244 \nL 116.70212 44.808244 \nL 117.209562 45.583561 \nL 117.412538 44.916229 \nL 117.514027 44.95034 \nL 118.427422 46.637246 \nL 119.036352 46.637246 \nL 119.340818 47.515901 \nL 119.645283 46.645902 \nL 119.746771 46.815751 \nL 120.254213 47.551748 \nL 120.45719 47.551748 \nL 120.863143 48.360984 \nL 121.472073 47.671415 \nL 122.182492 49.197586 \nL 122.385469 49.38075 \nL 122.689934 49.38075 \nL 122.994399 50.293784 \nL 123.400353 49.461133 \nL 123.704818 50.295251 \nL 124.110771 50.326426 \nL 124.415236 51.108916 \nL 124.719701 50.295251 \nL 125.125655 50.357715 \nL 125.734585 51.400876 \nL 126.445004 52.064511 \nL 126.749469 51.353703 \nL 127.053934 52.124254 \nL 127.358399 52.231287 \nL 127.764353 53.038755 \nL 128.779236 53.064015 \nL 129.083701 53.953256 \nL 129.692632 54.05703 \nL 131.011981 54.867758 \nL 131.214957 54.949312 \nL 131.620911 55.782259 \nL 131.823888 55.782259 \nL 132.128353 55.176924 \nL 132.229841 54.944378 \nL 132.331329 55.050199 \nL 132.635795 55.782259 \nL 133.346213 55.782259 \nL 133.54919 56.157341 \nL 133.752167 56.677904 \nL 134.056632 55.872902 \nL 134.15812 55.961567 \nL 134.868539 57.611261 \nL 135.477469 57.712275 \nL 136.69533 58.525763 \nL 136.999795 58.565191 \nL 137.507237 59.440264 \nL 138.319144 59.530548 \nL 139.029562 60.354765 \nL 139.435516 60.354765 \nL 139.739981 61.002736 \nL 139.841469 61.249353 \nL 140.247423 60.354765 \nL 140.450399 60.403267 \nL 141.465283 62.048985 \nL 141.566772 62.157837 \nL 141.871237 61.379731 \nL 142.175702 62.183768 \nL 142.581655 62.250424 \nL 142.987609 63.098269 \nL 143.393562 63.177541 \nL 144.509934 63.970666 \nL 144.611423 63.882375 \nL 144.915888 63.24179 \nL 145.626307 64.927272 \nL 146.133748 65.030958 \nL 146.438214 65.814147 \nL 146.742679 65.01018 \nL 146.844167 65.134284 \nL 147.148632 65.881791 \nL 148.569469 66.756274 \nL 148.873935 66.756274 \nL 149.381376 67.603285 \nL 149.685842 66.844736 \nL 150.294772 67.909524 \nL 151.00519 68.585277 \nL 151.817097 68.683386 \nL 152.324539 69.499778 \nL 153.440911 69.564409 \nL 154.15133 70.414279 \nL 154.658772 70.486735 \nL 155.775144 71.32878 \nL 156.384074 71.414703 \nL 157.195981 72.219072 \nL 157.500446 71.353877 \nL 158.312353 72.982639 \nL 158.413842 73.157613 \nL 158.718307 72.30111 \nL 159.327237 73.405885 \nL 159.936167 74.001339 \nL 160.240633 73.202814 \nL 160.748074 74.239749 \nL 161.458493 74.986783 \nL 161.864447 75.085305 \nL 162.87933 75.888484 \nL 163.183795 75.023143 \nL 163.894214 76.13871 \nL 164.706121 76.815785 \nL 165.41654 76.888291 \nL 166.532912 77.674106 \nL 166.837377 76.878446 \nL 167.040354 77.141416 \nL 167.547796 77.869547 \nL 168.664168 78.644788 \nL 168.968633 78.661984 \nL 169.983517 79.559289 \nL 170.287982 79.578442 \nL 171.404354 80.47379 \nL 171.810307 80.542401 \nL 173.028168 81.388292 \nL 173.53561 81.441476 \nL 174.449005 82.302793 \nL 174.956447 82.403274 \nL 176.377284 83.217294 \nL 176.783238 83.297918 \nL 177.595145 84.051374 \nL 177.89961 83.2238 \nL 178.407052 84.235521 \nL 179.624912 85.037579 \nL 179.929377 84.186137 \nL 180.639796 85.396 \nL 181.248726 85.93689 \nL 181.553191 85.140933 \nL 181.65468 85.263437 \nL 181.959145 86.004963 \nL 183.785936 86.875299 \nL 184.090401 86.906685 \nL 185.206773 87.789801 \nL 186.01868 87.877118 \nL 187.135052 88.704302 \nL 187.642494 88.764554 \nL 188.961843 89.605288 \nL 189.266308 88.744143 \nL 189.875238 89.831867 \nL 190.99161 90.533304 \nL 191.296075 90.598871 \nL 193.021378 91.447806 \nL 193.52882 91.556395 \nL 195.35561 92.362307 \nL 195.964541 92.447544 \nL 197.994308 93.23574 \nL 198.298773 92.469482 \nL 198.400262 92.530988 \nL 198.806215 93.389673 \nL 199.922587 94.191308 \nL 200.430029 94.257104 \nL 202.358308 95.105809 \nL 202.86575 95.181327 \nL 204.997006 96.020311 \nL 205.301471 96.118245 \nL 206.925285 96.918021 \nL 207.026773 96.091312 \nL 207.635704 96.983976 \nL 209.969936 97.847173 \nL 210.071425 97.019721 \nL 210.274401 97.849313 \nL 210.578867 97.938425 \nL 212.507146 98.740678 \nL 212.710122 97.938412 \nL 212.913099 98.763814 \nL 213.217564 98.843213 \nL 215.044355 99.660572 \nL 215.145843 99.158312 \nL 215.247332 99.192722 \nL 215.450309 99.678316 \nL 215.754774 99.749397 \nL 217.784541 100.579894 \nL 217.88603 99.806723 \nL 218.089006 100.592817 \nL 218.799425 100.693524 \nL 222.453006 101.506888 \nL 222.655983 100.922465 \nL 222.85896 101.507318 \nL 223.264913 101.605622 \nL 225.396169 102.394518 \nL 225.497658 102.169726 \nL 225.700634 102.421819 \nL 226.208076 102.560113 \nL 228.542309 103.320118 \nL 228.643797 103.190923 \nL 228.846774 103.336321 \nL 229.252728 103.42238 \nL 232.094402 104.250409 \nL 232.19589 103.905716 \nL 232.398867 104.250822 \nL 232.804821 104.337513 \nL 235.34203 105.164721 \nL 235.443518 104.582174 \nL 235.545007 104.972549 \nL 235.747984 104.53368 \nL 235.95096 105.165323 \nL 236.356914 105.253906 \nL 238.894123 106.054829 \nL 238.995612 105.247943 \nL 239.0971 105.28448 \nL 239.401565 106.079824 \nL 245.084914 106.173182 \nL 245.998309 106.354174 \nL 246.60724 106.48522 \nL 250.768263 107.085775 \nL 251.783147 107.154691 \nL 252.392077 107.177225 \nL 253.305472 107.281871 \nL 253.812914 107.360126 \nL 256.045659 107.454707 \nL 256.654589 107.491165 \nL 256.959054 107.490711 \nL 257.872449 107.611702 \nL 258.379891 107.543026 \nL 259.191798 107.656917 \nL 259.496263 107.704708 \nL 260.105194 107.797418 \nL 260.511147 107.772929 \nL 260.917101 107.817376 \nL 261.526031 107.737402 \nL 261.931984 107.890759 \nL 262.337938 107.862627 \nL 262.642403 107.86119 \nL 262.946868 107.885097 \nL 263.352822 107.966213 \nL 263.961752 107.908826 \nL 265.991519 108.083953 \nL 266.701938 108.020066 \nL 267.006403 108.065513 \nL 267.81831 108.183176 \nL 270.254031 108.283509 \nL 271.57338 108.354398 \nL 272.080822 108.313836 \nL 272.689752 108.320139 \nL 273.603147 108.274627 \nL 274.212078 108.359624 \nL 274.719519 108.531668 \nL 275.125473 108.483858 \nL 276.241845 108.366077 \nL 278.170124 108.4274 \nL 278.677566 108.623847 \nL 279.185008 108.627116 \nL 279.996915 108.472992 \nL 281.620729 108.532822 \nL 282.229659 108.57692 \nL 282.534124 108.607902 \nL 282.838589 108.608491 \nL 283.346031 108.593498 \nL 283.650496 108.605456 \nL 284.05645 108.601404 \nL 284.462403 108.640427 \nL 285.375799 108.548977 \nL 287.507055 108.655854 \nL 289.130869 108.899432 \nL 289.536822 108.960355 \nL 289.841287 108.853806 \nL 290.145752 108.876262 \nL 290.856171 108.762552 \nL 291.465101 109.028495 \nL 291.972543 109.044245 \nL 292.78445 108.914778 \nL 293.291892 108.832813 \nL 293.494869 108.738726 \nL 294.002311 108.988176 \nL 295.220171 109.114797 \nL 295.626125 109.189128 \nL 296.235055 109.006228 \nL 298.163334 109.10108 \nL 298.873753 109.187607 \nL 299.381195 109.097678 \nL 300.396078 109.068355 \nL 300.90352 109.006228 \nL 301.410962 109.041232 \nL 301.715427 109.063354 \nL 302.324357 109.146703 \nL 302.831799 109.105676 \nL 303.237753 109.15765 \nL 303.643706 109.15263 \nL 304.760078 109.372028 \nL 305.470497 109.261624 \nL 305.977939 109.189128 \nL 307.094311 109.372028 \nL 310.950869 109.286591 \nL 311.5598 109.132921 \nL 312.574683 109.415488 \nL 312.980637 109.54452 \nL 313.589567 109.463478 \nL 314.198497 109.393407 \nL 314.807428 109.263314 \nL 315.314869 109.189128 \nL 315.9238 109.276236 \nL 316.735707 109.433083 \nL 317.547614 109.38348 \nL 318.156544 109.646378 \nL 319.475893 109.544566 \nL 320.2878 109.488083 \nL 320.795242 109.554928 \nL 321.810125 109.372028 \nL 324.956265 109.455227 \nL 325.971149 109.738926 \nL 326.986033 109.438798 \nL 327.189009 109.415703 \nL 328.711335 109.829376 \nL 329.218777 109.721482 \nL 330.030684 109.372028 \nL 330.538126 109.483062 \nL 331.147056 109.554928 \nL 331.958963 109.532873 \nL 332.466405 109.516758 \nL 333.481289 109.773382 \nL 333.887242 109.737829 \nL 334.597661 109.737829 \nL 335.003614 109.664364 \nL 335.612544 109.414458 \nL 336.018498 109.165493 \nL 336.119986 109.110346 \nL 336.830405 109.866985 \nL 337.439335 109.975865 \nL 337.946777 109.788427 \nL 338.251242 109.737829 \nL 338.555707 109.592434 \nL 339.063149 109.451795 \nL 339.570591 109.412131 \nL 339.875056 109.423339 \nL 340.382498 109.384771 \nL 341.295893 109.554928 \nL 341.701847 109.477791 \nL 342.006312 109.372028 \nL 342.209289 109.459054 \nL 342.716731 109.984688 \nL 343.224173 110.012179 \nL 344.03608 109.806003 \nL 344.64501 109.480065 \nL 345.050963 109.683685 \nL 345.558405 110.071071 \nL 345.964359 110.103629 \nL 346.471801 110.034552 \nL 347.689661 109.398491 \nL 348.298591 110.026933 \nL 348.806033 110.103629 \nL 349.719429 110.006776 \nL 350.328359 109.664597 \nL 350.835801 109.49944 \nL 351.343243 109.189128 \nL 351.850684 109.10382 \nL 351.952173 109.369043 \nL 352.256638 111.283454 \nL 352.662591 111.794719 \nL 352.865568 111.932631 \nL 352.865568 111.932631 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 33.28375 118.154489 \nL 33.28375 19.318125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 368.08375 118.154489 \nL 368.08375 19.318125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 33.28375 118.154489 \nL 368.08375 118.154489 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 33.28375 19.318125 \nL 368.08375 19.318125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n  </g>\n  <g id=\"axes_2\">\n   <g id=\"patch_7\">\n    <path d=\"M 33.28375 236.758125 \nL 368.08375 236.758125 \nL 368.08375 137.921761 \nL 33.28375 137.921761 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_3\">\n    <g id=\"xtick_8\">\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"48.501932\" xlink:href=\"#m7274dfab3f\" y=\"236.758125\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 0 -->\n      <g transform=\"translate(44.684432 252.87625)scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_9\">\n     <g id=\"line2d_13\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"86.73857\" xlink:href=\"#m7274dfab3f\" y=\"236.758125\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 25 -->\n      <g transform=\"translate(79.10357 252.87625)scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_10\">\n     <g id=\"line2d_14\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"124.975207\" xlink:href=\"#m7274dfab3f\" y=\"236.758125\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 50 -->\n      <g transform=\"translate(117.340207 252.87625)scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_11\">\n     <g id=\"line2d_15\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"163.211845\" xlink:href=\"#m7274dfab3f\" y=\"236.758125\"/>\n      </g>\n     </g>\n     <g id=\"text_15\">\n      <!-- 75 -->\n      <defs>\n       <path d=\"M 8.203125 72.90625 \nL 55.078125 72.90625 \nL 55.078125 68.703125 \nL 28.609375 0 \nL 18.3125 0 \nL 43.21875 64.59375 \nL 8.203125 64.59375 \nz\n\" id=\"DejaVuSans-55\"/>\n      </defs>\n      <g transform=\"translate(155.576845 252.87625)scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-55\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_12\">\n     <g id=\"line2d_16\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"201.448483\" xlink:href=\"#m7274dfab3f\" y=\"236.758125\"/>\n      </g>\n     </g>\n     <g id=\"text_16\">\n      <!-- 100 -->\n      <g transform=\"translate(189.995983 252.87625)scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_13\">\n     <g id=\"line2d_17\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"239.68512\" xlink:href=\"#m7274dfab3f\" y=\"236.758125\"/>\n      </g>\n     </g>\n     <g id=\"text_17\">\n      <!-- 125 -->\n      <g transform=\"translate(228.23262 252.87625)scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_14\">\n     <g id=\"line2d_18\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"277.921758\" xlink:href=\"#m7274dfab3f\" y=\"236.758125\"/>\n      </g>\n     </g>\n     <g id=\"text_18\">\n      <!-- 150 -->\n      <g transform=\"translate(266.469258 252.87625)scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_15\">\n     <g id=\"line2d_19\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"316.158396\" xlink:href=\"#m7274dfab3f\" y=\"236.758125\"/>\n      </g>\n     </g>\n     <g id=\"text_19\">\n      <!-- 175 -->\n      <g transform=\"translate(304.705896 252.87625)scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-55\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_16\">\n     <g id=\"line2d_20\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"354.395034\" xlink:href=\"#m7274dfab3f\" y=\"236.758125\"/>\n      </g>\n     </g>\n     <g id=\"text_20\">\n      <!-- 200 -->\n      <g transform=\"translate(342.942534 252.87625)scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_4\">\n    <g id=\"ytick_4\">\n     <g id=\"line2d_21\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.28375\" xlink:href=\"#m6c4aab5eba\" y=\"234.951426\"/>\n      </g>\n     </g>\n     <g id=\"text_21\">\n      <!-- âˆ’1 -->\n      <g transform=\"translate(8.593125 239.510489)scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-8722\"/>\n       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-49\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_22\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.28375\" xlink:href=\"#m6c4aab5eba\" y=\"207.946161\"/>\n      </g>\n     </g>\n     <g id=\"text_22\">\n      <!-- 0 -->\n      <g transform=\"translate(18.64875 212.505224)scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_23\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.28375\" xlink:href=\"#m6c4aab5eba\" y=\"180.940896\"/>\n      </g>\n     </g>\n     <g id=\"text_23\">\n      <!-- 1 -->\n      <g transform=\"translate(18.64875 185.499959)scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_7\">\n     <g id=\"line2d_24\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"33.28375\" xlink:href=\"#m6c4aab5eba\" y=\"153.935632\"/>\n      </g>\n     </g>\n     <g id=\"text_24\">\n      <!-- 2 -->\n      <g transform=\"translate(18.64875 158.494694)scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_25\">\n    <path clip-path=\"url(#p43a50355df)\" d=\"M 48.501932 232.265563 \nL 59.20819 232.140839 \nL 82.150173 232.150353 \nL 83.679639 199.893525 \nL 85.209104 185.346972 \nL 86.73857 177.02045 \nL 88.268035 161.701452 \nL 89.797501 148.304412 \nL 91.326966 146.510095 \nL 92.856432 142.765341 \nL 94.385897 142.414323 \nL 95.915363 142.414323 \nL 97.444828 142.663779 \nL 100.503759 142.765341 \nL 102.033225 142.765341 \nL 103.56269 145.570343 \nL 105.092156 147.865689 \nL 108.151087 151.617577 \nL 112.739483 156.26674 \nL 114.268949 157.916321 \nL 115.798414 159.797683 \nL 117.32788 160.861967 \nL 118.857345 162.653335 \nL 120.386811 163.412366 \nL 121.916276 163.996292 \nL 123.445742 165.592652 \nL 124.975207 166.460869 \nL 126.504673 167.562586 \nL 128.034138 169.31652 \nL 131.093069 171.104958 \nL 132.622535 171.30004 \nL 134.152 172.266515 \nL 135.681466 174.075937 \nL 141.799328 177.998453 \nL 143.328793 179.772269 \nL 144.858259 179.93663 \nL 146.387724 181.691008 \nL 147.91719 182.904351 \nL 149.446655 183.686856 \nL 150.976121 185.034892 \nL 152.505586 185.97607 \nL 154.035052 186.667647 \nL 155.564517 187.836593 \nL 157.093983 188.380317 \nL 160.152914 190.304833 \nL 161.68238 191.880793 \nL 163.211845 192.199573 \nL 164.741311 193.662706 \nL 166.270776 194.130713 \nL 167.800242 194.78878 \nL 169.329707 195.969261 \nL 176.977035 200.728679 \nL 178.5065 200.735451 \nL 181.565431 202.730952 \nL 183.094897 203.916812 \nL 184.624362 204.536214 \nL 187.683293 206.439982 \nL 189.212759 206.481451 \nL 190.742224 207.770851 \nL 193.801155 209.295633 \nL 195.330621 209.98256 \nL 196.860086 210.359073 \nL 198.389552 210.423253 \nL 199.919017 211.644621 \nL 202.977948 213.103167 \nL 206.036879 214.128954 \nL 207.566345 214.156989 \nL 209.09581 215.095314 \nL 210.625276 215.340405 \nL 212.154741 216.051558 \nL 213.684207 216.910702 \nL 215.213672 217.321326 \nL 216.743138 217.996242 \nL 218.272603 218.023017 \nL 219.802069 218.966326 \nL 222.861 219.319082 \nL 224.390465 219.994169 \nL 227.449396 220.99976 \nL 228.978862 221.515678 \nL 235.096724 222.916426 \nL 236.626189 222.966901 \nL 238.155655 223.659884 \nL 239.68512 223.96621 \nL 241.214586 224.541397 \nL 245.802983 224.620958 \nL 248.861914 225.11189 \nL 250.391379 225.381157 \nL 268.744965 226.624927 \nL 270.274431 226.626638 \nL 271.803896 226.810291 \nL 277.921758 226.901023 \nL 280.980689 227.038409 \nL 296.275344 227.476609 \nL 299.334275 227.571799 \nL 305.452137 227.668198 \nL 308.511068 227.762176 \nL 316.158396 227.871697 \nL 319.217327 227.952552 \nL 346.747706 227.952552 \nL 349.806637 228.178982 \nL 351.336103 228.446742 \nL 352.865568 228.538984 \nL 352.865568 228.538984 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_8\">\n    <path d=\"M 33.28375 236.758125 \nL 33.28375 137.921761 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_9\">\n    <path d=\"M 368.08375 236.758125 \nL 368.08375 137.921761 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_10\">\n    <path d=\"M 33.28375 236.758125 \nL 368.08375 236.758125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_11\">\n    <path d=\"M 33.28375 137.921761 \nL 368.08375 137.921761 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p4e985cf6a1\">\n   <rect height=\"98.836364\" width=\"334.8\" x=\"33.28375\" y=\"19.318125\"/>\n  </clipPath>\n  <clipPath id=\"p43a50355df\">\n   <rect height=\"98.836364\" width=\"334.8\" x=\"33.28375\" y=\"137.921761\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 2 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"262.571875pt\" version=\"1.1\" viewBox=\"0 0 374.043932 262.571875\" width=\"374.043932pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <defs>\n  <style type=\"text/css\">\n*{stroke-linecap:butt;stroke-linejoin:round;}\n  </style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 262.571875 \nL 374.043932 262.571875 \nL 374.043932 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 31.890625 118.154489 \nL 366.690625 118.154489 \nL 366.690625 19.318125 \nL 31.890625 19.318125 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m4971bb263b\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"47.108807\" xlink:href=\"#m4971bb263b\" y=\"118.154489\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <defs>\n       <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n      </defs>\n      <g transform=\"translate(43.291307 134.272614)scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"97.852994\" xlink:href=\"#m4971bb263b\" y=\"118.154489\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 500 -->\n      <defs>\n       <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n      </defs>\n      <g transform=\"translate(86.400494 134.272614)scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"148.597182\" xlink:href=\"#m4971bb263b\" y=\"118.154489\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 1000 -->\n      <defs>\n       <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n      </defs>\n      <g transform=\"translate(133.327182 134.272614)scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"199.341369\" xlink:href=\"#m4971bb263b\" y=\"118.154489\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 1500 -->\n      <g transform=\"translate(184.071369 134.272614)scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"250.085557\" xlink:href=\"#m4971bb263b\" y=\"118.154489\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 2000 -->\n      <defs>\n       <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n      </defs>\n      <g transform=\"translate(234.815557 134.272614)scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"300.829744\" xlink:href=\"#m4971bb263b\" y=\"118.154489\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 2500 -->\n      <g transform=\"translate(285.559744 134.272614)scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_7\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"351.573932\" xlink:href=\"#m4971bb263b\" y=\"118.154489\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 3000 -->\n      <defs>\n       <path d=\"M 40.578125 39.3125 \nQ 47.65625 37.796875 51.625 33 \nQ 55.609375 28.21875 55.609375 21.1875 \nQ 55.609375 10.40625 48.1875 4.484375 \nQ 40.765625 -1.421875 27.09375 -1.421875 \nQ 22.515625 -1.421875 17.65625 -0.515625 \nQ 12.796875 0.390625 7.625 2.203125 \nL 7.625 11.71875 \nQ 11.71875 9.328125 16.59375 8.109375 \nQ 21.484375 6.890625 26.8125 6.890625 \nQ 36.078125 6.890625 40.9375 10.546875 \nQ 45.796875 14.203125 45.796875 21.1875 \nQ 45.796875 27.640625 41.28125 31.265625 \nQ 36.765625 34.90625 28.71875 34.90625 \nL 20.21875 34.90625 \nL 20.21875 43.015625 \nL 29.109375 43.015625 \nQ 36.375 43.015625 40.234375 45.921875 \nQ 44.09375 48.828125 44.09375 54.296875 \nQ 44.09375 59.90625 40.109375 62.90625 \nQ 36.140625 65.921875 28.71875 65.921875 \nQ 24.65625 65.921875 20.015625 65.03125 \nQ 15.375 64.15625 9.8125 62.3125 \nL 9.8125 71.09375 \nQ 15.4375 72.65625 20.34375 73.4375 \nQ 25.25 74.21875 29.59375 74.21875 \nQ 40.828125 74.21875 47.359375 69.109375 \nQ 53.90625 64.015625 53.90625 55.328125 \nQ 53.90625 49.265625 50.4375 45.09375 \nQ 46.96875 40.921875 40.578125 39.3125 \nz\n\" id=\"DejaVuSans-51\"/>\n      </defs>\n      <g transform=\"translate(336.303932 134.272614)scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_8\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"m5ec4abc662\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"31.890625\" xlink:href=\"#m5ec4abc662\" y=\"114.031307\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 0 -->\n      <g transform=\"translate(17.255625 118.59037)scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_9\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"31.890625\" xlink:href=\"#m5ec4abc662\" y=\"88.253987\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 1 -->\n      <g transform=\"translate(17.255625 92.81305)scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"31.890625\" xlink:href=\"#m5ec4abc662\" y=\"62.476667\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 2 -->\n      <g transform=\"translate(17.255625 67.03573)scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"31.890625\" xlink:href=\"#m5ec4abc662\" y=\"36.699347\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 3 -->\n      <g transform=\"translate(17.255625 41.25841)scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-51\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_12\">\n     <!-- 1eâˆ’8 -->\n     <defs>\n      <path d=\"M 56.203125 29.59375 \nL 56.203125 25.203125 \nL 14.890625 25.203125 \nQ 15.484375 15.921875 20.484375 11.0625 \nQ 25.484375 6.203125 34.421875 6.203125 \nQ 39.59375 6.203125 44.453125 7.46875 \nQ 49.3125 8.734375 54.109375 11.28125 \nL 54.109375 2.78125 \nQ 49.265625 0.734375 44.1875 -0.34375 \nQ 39.109375 -1.421875 33.890625 -1.421875 \nQ 20.796875 -1.421875 13.15625 6.1875 \nQ 5.515625 13.8125 5.515625 26.8125 \nQ 5.515625 40.234375 12.765625 48.109375 \nQ 20.015625 56 32.328125 56 \nQ 43.359375 56 49.78125 48.890625 \nQ 56.203125 41.796875 56.203125 29.59375 \nz\nM 47.21875 32.234375 \nQ 47.125 39.59375 43.09375 43.984375 \nQ 39.0625 48.390625 32.421875 48.390625 \nQ 24.90625 48.390625 20.390625 44.140625 \nQ 15.875 39.890625 15.1875 32.171875 \nz\n\" id=\"DejaVuSans-101\"/>\n      <path d=\"M 10.59375 35.5 \nL 73.1875 35.5 \nL 73.1875 27.203125 \nL 10.59375 27.203125 \nz\n\" id=\"DejaVuSans-8722\"/>\n      <path d=\"M 31.78125 34.625 \nQ 24.75 34.625 20.71875 30.859375 \nQ 16.703125 27.09375 16.703125 20.515625 \nQ 16.703125 13.921875 20.71875 10.15625 \nQ 24.75 6.390625 31.78125 6.390625 \nQ 38.8125 6.390625 42.859375 10.171875 \nQ 46.921875 13.96875 46.921875 20.515625 \nQ 46.921875 27.09375 42.890625 30.859375 \nQ 38.875 34.625 31.78125 34.625 \nz\nM 21.921875 38.8125 \nQ 15.578125 40.375 12.03125 44.71875 \nQ 8.5 49.078125 8.5 55.328125 \nQ 8.5 64.0625 14.71875 69.140625 \nQ 20.953125 74.21875 31.78125 74.21875 \nQ 42.671875 74.21875 48.875 69.140625 \nQ 55.078125 64.0625 55.078125 55.328125 \nQ 55.078125 49.078125 51.53125 44.71875 \nQ 48 40.375 41.703125 38.8125 \nQ 48.828125 37.15625 52.796875 32.3125 \nQ 56.78125 27.484375 56.78125 20.515625 \nQ 56.78125 9.90625 50.3125 4.234375 \nQ 43.84375 -1.421875 31.78125 -1.421875 \nQ 19.734375 -1.421875 13.25 4.234375 \nQ 6.78125 9.90625 6.78125 20.515625 \nQ 6.78125 27.484375 10.78125 32.3125 \nQ 14.796875 37.15625 21.921875 38.8125 \nz\nM 18.3125 54.390625 \nQ 18.3125 48.734375 21.84375 45.5625 \nQ 25.390625 42.390625 31.78125 42.390625 \nQ 38.140625 42.390625 41.71875 45.5625 \nQ 45.3125 48.734375 45.3125 54.390625 \nQ 45.3125 60.0625 41.71875 63.234375 \nQ 38.140625 66.40625 31.78125 66.40625 \nQ 25.390625 66.40625 21.84375 63.234375 \nQ 18.3125 60.0625 18.3125 54.390625 \nz\n\" id=\"DejaVuSans-56\"/>\n     </defs>\n     <g transform=\"translate(31.890625 16.318125)scale(0.12 -0.12)\">\n      <use xlink:href=\"#DejaVuSans-49\"/>\n      <use x=\"63.623047\" xlink:href=\"#DejaVuSans-101\"/>\n      <use x=\"125.146484\" xlink:href=\"#DejaVuSans-8722\"/>\n      <use x=\"208.935547\" xlink:href=\"#DejaVuSans-56\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_12\">\n    <path clip-path=\"url(#p2fe587beab)\" d=\"M 47.108807 113.386874 \nL 47.311784 113.275921 \nL 47.413272 113.3531 \nL 47.51476 113.270834 \nL 47.616249 113.412261 \nL 47.819225 113.138933 \nL 48.225179 113.497381 \nL 48.428156 113.218496 \nL 48.529644 113.439178 \nL 48.935598 113.078435 \nL 49.341551 113.508921 \nL 49.747505 113.217312 \nL 49.848993 113.183244 \nL 49.950481 113.301895 \nL 50.05197 113.163328 \nL 50.153458 113.365389 \nL 50.356435 113.176809 \nL 50.559412 113.212257 \nL 50.762388 113.151298 \nL 50.863877 113.144909 \nL 51.26983 113.628372 \nL 51.472807 113.176548 \nL 51.87876 113.104236 \nL 52.081737 113.228644 \nL 52.183226 113.192745 \nL 52.284714 113.470905 \nL 52.386202 113.210966 \nL 52.589179 113.288899 \nL 52.792156 113.142528 \nL 52.995133 113.375473 \nL 53.198109 113.122203 \nL 53.299598 113.266384 \nL 53.401086 113.182597 \nL 53.705551 113.321422 \nL 54.010016 113.125182 \nL 54.314481 113.344376 \nL 54.517458 113.23413 \nL 54.618947 113.200189 \nL 54.821923 113.531035 \nL 54.923412 113.198787 \nL 55.126388 113.361384 \nL 55.329365 113.092437 \nL 55.532342 113.327359 \nL 55.735319 113.245757 \nL 55.938295 113.221992 \nL 56.344249 113.217389 \nL 56.445737 113.254212 \nL 56.547226 113.485573 \nL 56.648714 113.149316 \nL 56.953179 113.320318 \nL 57.054668 113.137043 \nL 57.257644 113.582392 \nL 57.460621 113.170919 \nL 57.663598 113.155809 \nL 57.765086 113.096392 \nL 57.968063 113.480993 \nL 58.069551 113.217451 \nL 58.272528 113.213278 \nL 58.475505 113.195259 \nL 58.576993 113.130892 \nL 58.881458 113.27555 \nL 58.982947 113.099799 \nL 59.185923 113.38577 \nL 59.287412 113.583703 \nL 59.3889 113.161676 \nL 59.693365 113.282586 \nL 60.403784 113.147461 \nL 60.505272 113.245164 \nL 60.606761 113.162083 \nL 60.809737 113.257537 \nL 61.012714 113.203432 \nL 61.520156 113.160678 \nL 61.621644 113.480241 \nL 61.824621 113.180009 \nL 62.332063 113.369326 \nL 62.433551 113.15237 \nL 62.53504 113.400337 \nL 62.738017 113.267966 \nL 62.839505 113.316973 \nL 63.042482 113.177806 \nL 63.346947 113.383107 \nL 63.549924 113.278163 \nL 63.651412 113.394116 \nL 64.057365 113.16808 \nL 64.260342 113.229389 \nL 64.463319 113.222595 \nL 64.666296 113.130641 \nL 64.869272 113.214253 \nL 64.970761 113.17469 \nL 65.072249 113.587551 \nL 65.173738 113.158461 \nL 65.275226 113.195728 \nL 65.478203 113.242228 \nL 65.681179 113.30491 \nL 65.782668 113.415422 \nL 65.985645 113.219206 \nL 66.188621 113.297266 \nL 66.29011 113.200132 \nL 66.493086 113.34754 \nL 66.594575 113.214716 \nL 66.696063 113.364233 \nL 66.89904 113.22951 \nL 67.102017 113.308686 \nL 67.304993 113.241963 \nL 67.50797 113.393242 \nL 67.710947 113.250214 \nL 67.812435 113.244034 \nL 67.913924 113.455908 \nL 68.1169 113.158475 \nL 68.319877 113.104292 \nL 68.522854 113.27645 \nL 68.624342 113.234582 \nL 68.725831 113.325228 \nL 68.928807 113.258218 \nL 69.334761 113.300051 \nL 69.639226 113.282646 \nL 69.943691 113.241275 \nL 70.04518 113.433377 \nL 70.248156 113.229911 \nL 70.349645 113.324152 \nL 70.451133 113.151405 \nL 70.755598 113.254643 \nL 70.958575 113.092141 \nL 71.060063 113.274175 \nL 71.26304 113.17666 \nL 71.466017 113.331383 \nL 71.567505 113.487857 \nL 71.668994 113.143899 \nL 71.87197 113.342888 \nL 71.973459 113.220548 \nL 72.074947 113.424406 \nL 72.277924 113.17578 \nL 72.379412 113.114522 \nL 72.683877 113.402475 \nL 72.785366 113.14892 \nL 72.886854 113.30305 \nL 73.191319 113.118133 \nL 73.394296 113.35024 \nL 73.597273 113.15511 \nL 73.800249 113.295548 \nL 73.901738 113.181994 \nL 74.003226 113.380163 \nL 74.104715 113.239801 \nL 74.307691 113.373384 \nL 74.40918 113.232852 \nL 74.510668 113.291915 \nL 74.612156 113.125496 \nL 74.815133 113.237062 \nL 75.119598 113.350301 \nL 75.322575 113.189931 \nL 75.424063 113.339643 \nL 75.525552 113.192804 \nL 75.830017 113.282949 \nL 75.931505 113.262825 \nL 76.032994 113.476681 \nL 76.134482 113.289304 \nL 76.23597 113.411262 \nL 76.337459 113.203057 \nL 76.540436 113.245653 \nL 76.743412 113.105317 \nL 76.844901 113.370756 \nL 76.946389 113.215216 \nL 77.047877 113.344064 \nL 77.149366 113.197611 \nL 77.250854 113.268765 \nL 77.352343 113.136731 \nL 77.453831 113.433147 \nL 77.656808 113.174302 \nL 77.758296 113.134714 \nL 77.961273 113.369407 \nL 78.265738 113.140676 \nL 78.874668 113.523985 \nL 79.077645 113.138349 \nL 79.179133 113.099301 \nL 79.280622 113.366252 \nL 79.483598 113.226639 \nL 79.686575 113.266346 \nL 79.889552 113.245826 \nL 80.092529 113.304624 \nL 80.194017 113.152535 \nL 80.295505 113.408965 \nL 80.498482 113.197358 \nL 80.701459 113.379552 \nL 81.005924 113.168284 \nL 81.513366 113.343876 \nL 81.614854 113.22354 \nL 81.817831 113.390783 \nL 82.020808 113.232783 \nL 82.223785 113.326409 \nL 82.426761 113.275466 \nL 82.629738 113.362964 \nL 82.832715 113.149717 \nL 82.934203 113.386905 \nL 83.035692 113.276403 \nL 83.13718 113.386626 \nL 83.340157 113.218669 \nL 83.543133 113.207626 \nL 84.862482 113.217051 \nL 84.963971 113.162847 \nL 85.268436 113.314679 \nL 85.572901 113.28664 \nL 85.877366 113.461526 \nL 86.080343 113.253589 \nL 86.28332 113.260937 \nL 86.384808 113.307749 \nL 86.587785 113.210221 \nL 87.399692 113.406277 \nL 87.602668 113.253612 \nL 87.805645 113.252223 \nL 88.211599 113.193653 \nL 88.617552 113.208362 \nL 88.719041 113.290339 \nL 88.922017 113.24176 \nL 89.023506 113.32307 \nL 89.124994 113.247347 \nL 89.226482 113.342364 \nL 89.429459 113.254304 \nL 89.835413 113.320764 \nL 90.038389 113.207037 \nL 90.241366 113.488695 \nL 90.342855 113.298787 \nL 90.444343 113.42761 \nL 90.545831 113.252929 \nL 90.951785 113.51553 \nL 91.154762 113.204841 \nL 91.459227 113.265266 \nL 91.662203 113.2436 \nL 92.068157 113.462489 \nL 92.169645 113.604391 \nL 92.271134 113.142438 \nL 92.372622 113.372276 \nL 92.575599 113.225421 \nL 92.677087 113.289727 \nL 92.880064 113.130001 \nL 93.184529 113.336213 \nL 93.286017 113.381648 \nL 93.387506 113.246315 \nL 93.488994 113.325942 \nL 93.691971 113.169151 \nL 93.894948 113.118951 \nL 94.097924 113.468141 \nL 94.300901 113.241081 \nL 94.605366 113.371106 \nL 94.706855 113.589779 \nL 94.808343 113.230652 \nL 95.01132 113.333447 \nL 95.214297 113.264791 \nL 95.518762 113.282149 \nL 95.62025 113.416756 \nL 95.721738 113.255599 \nL 96.026204 113.528346 \nL 96.330669 113.159883 \nL 96.635134 113.252638 \nL 96.939599 113.145453 \nL 97.142576 113.192299 \nL 97.345552 113.243332 \nL 97.852994 113.164408 \nL 98.055971 113.344226 \nL 98.258948 113.115412 \nL 98.461925 113.27349 \nL 98.867878 113.329771 \nL 98.969366 113.137244 \nL 99.172343 113.206433 \nL 99.882762 113.262863 \nL 99.98425 113.324772 \nL 100.085739 113.184371 \nL 100.187227 113.352351 \nL 100.390204 113.237081 \nL 100.796157 113.39406 \nL 100.897646 113.232234 \nL 100.999134 113.318286 \nL 101.303599 113.2141 \nL 101.506576 113.354119 \nL 101.608064 113.230428 \nL 101.709553 113.311601 \nL 101.912529 113.228557 \nL 102.216994 113.406794 \nL 102.318483 113.126766 \nL 102.419971 113.171408 \nL 102.52146 113.26253 \nL 102.724436 113.098122 \nL 102.825925 113.41432 \nL 102.927413 112.550749 \nL 103.028901 113.231466 \nL 103.13039 112.389547 \nL 103.231878 113.30498 \nL 103.333367 113.277181 \nL 103.434855 113.661927 \nL 103.637832 113.131369 \nL 103.73932 112.963173 \nL 103.840808 113.609148 \nL 104.043785 112.626764 \nL 104.145274 113.512074 \nL 104.246762 112.756395 \nL 104.449739 113.408167 \nL 104.551227 113.224237 \nL 104.652715 112.490376 \nL 104.754204 112.948337 \nL 104.855692 112.443863 \nL 105.058669 110.182348 \nL 105.160157 113.071691 \nL 105.261646 109.973382 \nL 105.363134 110.021096 \nL 105.464622 113.261003 \nL 105.566111 109.984533 \nL 105.667599 110.382548 \nL 105.769088 112.485852 \nL 105.870576 105.396825 \nL 105.972064 108.594208 \nL 106.175041 108.057277 \nL 106.378018 107.906655 \nL 106.783971 108.067573 \nL 106.986948 107.478617 \nL 107.088436 107.586977 \nL 107.697367 107.501422 \nL 107.900343 105.718828 \nL 108.001832 105.981377 \nL 108.204809 107.096193 \nL 108.306297 106.976354 \nL 108.509274 105.140498 \nL 108.813739 104.538055 \nL 109.016716 105.329816 \nL 109.219692 103.289372 \nL 109.321181 102.887911 \nL 109.625646 104.276554 \nL 109.727134 105.266827 \nL 109.930111 103.646731 \nL 110.336064 103.483176 \nL 110.539041 104.593033 \nL 110.742018 100.361102 \nL 110.843506 104.180976 \nL 111.046483 99.545915 \nL 111.24946 101.789919 \nL 111.350948 100.970699 \nL 111.452437 103.201147 \nL 111.655413 101.609315 \nL 111.959878 100.866457 \nL 112.061367 101.117494 \nL 112.264344 103.079676 \nL 112.365832 100.092415 \nL 112.568809 102.231717 \nL 112.670297 100.611926 \nL 112.771785 101.441959 \nL 112.873274 101.099612 \nL 112.974762 102.386924 \nL 113.177739 100.442779 \nL 113.380716 99.65118 \nL 113.482204 102.651157 \nL 113.685181 101.293764 \nL 113.888158 100.824435 \nL 114.395599 100.731592 \nL 114.801553 102.408133 \nL 114.903041 100.688178 \nL 115.106018 101.547163 \nL 115.207506 100.391353 \nL 115.511972 101.935487 \nL 115.61346 99.13436 \nL 115.714948 100.610021 \nL 116.019413 99.019043 \nL 116.120902 100.671842 \nL 116.22239 100.103349 \nL 116.526855 102.156669 \nL 116.83132 99.580047 \nL 117.135786 98.752918 \nL 117.338762 99.476327 \nL 117.440251 100.468067 \nL 117.947693 99.180728 \nL 118.049181 99.423415 \nL 118.150669 100.103231 \nL 118.353646 98.944236 \nL 118.455134 100.094275 \nL 118.7596 99.078573 \nL 118.861088 100.365977 \nL 118.962576 99.287082 \nL 119.165553 100.616658 \nL 119.267041 99.289603 \nL 119.571507 100.87276 \nL 119.774483 98.225963 \nL 119.875972 98.886649 \nL 119.97746 98.845237 \nL 120.180437 100.056306 \nL 120.383414 99.174534 \nL 120.484902 101.44629 \nL 120.58639 100.024531 \nL 120.789367 101.800199 \nL 120.890855 99.639137 \nL 121.195321 101.523096 \nL 121.398297 99.547302 \nL 121.905739 99.339613 \nL 122.108716 100.030564 \nL 122.210204 99.302829 \nL 122.413181 100.298501 \nL 122.514669 99.161186 \nL 122.616158 99.779259 \nL 122.717646 99.196298 \nL 122.819135 100.672573 \nL 123.022111 99.080462 \nL 123.428065 99.080462 \nL 123.631042 99.731852 \nL 124.036995 100.977176 \nL 124.239972 98.801479 \nL 124.544437 97.927313 \nL 124.645925 98.387971 \nL 124.95039 100.702691 \nL 125.153367 97.734191 \nL 125.254856 98.034067 \nL 125.356344 99.224669 \nL 125.559321 98.320418 \nL 125.863786 100.821703 \nL 126.066763 98.564915 \nL 126.472716 98.564915 \nL 126.878669 97.80622 \nL 127.081646 97.397637 \nL 127.183135 98.306179 \nL 127.792065 97.533969 \nL 128.198018 99.42552 \nL 128.299507 99.013817 \nL 128.502483 96.424992 \nL 128.70546 98.049369 \nL 129.111414 98.049369 \nL 129.212902 98.186621 \nL 129.618856 100.117686 \nL 129.720344 98.035122 \nL 129.923321 99.32179 \nL 130.126297 97.270632 \nL 130.430763 95.790348 \nL 130.938204 96.433696 \nL 131.039693 96.312882 \nL 131.445646 94.798628 \nL 131.547135 96.519613 \nL 131.750111 94.887847 \nL 131.8516 96.582543 \nL 132.054577 95.60612 \nL 132.562018 95.273356 \nL 132.663507 96.482611 \nL 132.866484 94.550887 \nL 133.373925 95.136505 \nL 133.475414 94.559477 \nL 133.576902 93.243948 \nL 133.678391 95.663069 \nL 133.779879 93.789119 \nL 133.881367 94.578722 \nL 133.982856 93.260566 \nL 134.084344 95.186779 \nL 134.185832 95.103722 \nL 134.693274 94.784563 \nL 134.997739 96.959708 \nL 135.099228 93.469208 \nL 135.200716 93.552298 \nL 135.809646 94.184886 \nL 136.2156 94.871307 \nL 136.317088 91.898731 \nL 136.418577 94.133696 \nL 136.723042 92.382592 \nL 137.940902 92.889094 \nL 138.549833 97.493752 \nL 138.651321 95.745731 \nL 138.752809 95.788636 \nL 139.158763 95.960256 \nL 139.260251 96.183319 \nL 139.666205 98.290124 \nL 139.767693 96.840123 \nL 140.072158 98.158991 \nL 140.173647 95.870784 \nL 140.275135 96.975957 \nL 140.478112 95.987183 \nL 140.985554 95.987183 \nL 141.18853 97.117514 \nL 141.492995 99.300645 \nL 141.594484 96.307883 \nL 141.695972 96.392345 \nL 142.101926 96.730197 \nL 142.507879 95.323853 \nL 142.609368 94.948117 \nL 142.812344 96.698334 \nL 143.522763 96.086273 \nL 144.131693 94.914773 \nL 144.842112 92.883607 \nL 145.55253 91.914136 \nL 146.161461 91.522715 \nL 146.770391 91.385381 \nL 147.277833 91.599945 \nL 148.08974 90.886181 \nL 148.69867 91.017555 \nL 149.916531 90.07705 \nL 150.626949 90.26688 \nL 152.555228 89.542853 \nL 153.164159 89.491804 \nL 153.773089 89.044625 \nL 154.382019 89.259791 \nL 155.295414 88.640911 \nL 155.701368 88.548189 \nL 156.310298 88.721911 \nL 157.223694 88.099242 \nL 162.602577 85.676255 \nL 163.110019 85.676255 \nL 163.312996 86.322464 \nL 163.820438 88.216646 \nL 170.721647 83.126762 \nL 170.924624 83.77241 \nL 171.432066 85.601973 \nL 174.273741 80.596133 \nL 174.375229 80.761179 \nL 174.984159 83.098523 \nL 175.694578 83.018622 \nL 178.130299 77.943059 \nL 178.840717 77.943059 \nL 178.942206 78.078637 \nL 179.551136 80.510786 \nL 180.870485 75.365327 \nL 183.813648 75.348822 \nL 186.655322 72.787595 \nL 187.264253 72.787595 \nL 187.974671 75.271666 \nL 189.801462 70.209863 \nL 190.410392 70.288723 \nL 191.019322 72.628783 \nL 191.120811 72.485312 \nL 192.135695 67.839195 \nL 192.744625 70.03982 \nL 193.455043 67.741266 \nL 194.063974 70.193386 \nL 194.774392 65.054399 \nL 197.108625 65.054399 \nL 197.819044 67.448447 \nL 199.544346 62.600575 \nL 200.153276 65.037315 \nL 203.299416 59.530788 \nL 205.227695 57.335211 \nL 205.938114 59.728506 \nL 207.866393 53.882938 \nL 208.6783 52.165739 \nL 209.185742 52.165739 \nL 209.693183 54.155315 \nL 209.89616 54.743471 \nL 210.50509 54.743471 \nL 210.606579 54.594841 \nL 211.824439 49.647857 \nL 212.128904 50.757346 \nL 212.43337 51.983698 \nL 212.534858 51.785063 \nL 213.346765 47.010275 \nL 216.594393 46.994449 \nL 218.421184 44.432543 \nL 220.349463 44.323421 \nL 222.785184 41.871466 \nL 223.292626 43.896932 \nL 223.495602 44.432543 \nL 224.104533 44.346542 \nL 226.1343 39.277079 \nL 226.641742 39.277079 \nL 227.149184 41.235294 \nL 227.352161 41.747033 \nL 229.686393 36.854914 \nL 230.295324 39.129408 \nL 230.904254 36.763599 \nL 231.513184 39.236695 \nL 233.441463 34.121615 \nL 234.659324 34.121615 \nL 235.166766 36.182594 \nL 235.268254 36.611714 \nL 235.471231 36.344962 \nL 238.00844 31.543883 \nL 238.718859 31.543883 \nL 239.327789 34.1011 \nL 239.936719 31.689077 \nL 240.038208 31.78113 \nL 240.748626 34.121615 \nL 241.459045 34.017401 \nL 244.605184 28.966151 \nL 246.533464 28.966151 \nL 246.634952 29.080643 \nL 247.243882 31.475799 \nL 247.852812 28.985376 \nL 248.664719 30.388881 \nL 249.375138 31.483355 \nL 254.145092 26.388419 \nL 267.034115 26.388419 \nL 267.33858 27.52306 \nL 267.643046 28.810421 \nL 267.744534 28.692906 \nL 268.251976 26.548449 \nL 268.353464 26.653149 \nL 268.962394 28.755807 \nL 269.672813 26.388419 \nL 270.992162 26.43219 \nL 271.702581 28.966151 \nL 272.210022 28.966151 \nL 272.412999 28.339088 \nL 272.920441 26.419219 \nL 273.63086 28.807371 \nL 274.84872 25.68579 \nL 275.45765 23.810687 \nL 276.168069 23.810687 \nL 278.299325 28.519217 \nL 278.60379 28.966151 \nL 279.923139 28.966151 \nL 280.024627 28.80409 \nL 280.735046 26.388419 \nL 281.242488 26.388419 \nL 281.343976 26.547377 \nL 281.952906 28.966151 \nL 282.561837 28.900448 \nL 283.272255 26.388419 \nL 284.388627 26.483361 \nL 286.316906 31.543883 \nL 287.534767 31.543883 \nL 287.839232 30.531455 \nL 288.346674 28.966151 \nL 289.666023 28.966151 \nL 290.173465 29.985907 \nL 292.203232 34.121615 \nL 293.421093 34.121615 \nL 293.827046 32.513822 \nL 294.131511 31.543883 \nL 297.277651 31.543883 \nL 297.379139 31.671368 \nL 298.698488 36.699347 \nL 299.307418 36.699347 \nL 299.916349 34.215246 \nL 300.017837 34.455329 \nL 300.525279 36.599252 \nL 300.728256 35.94128 \nL 301.134209 34.224799 \nL 301.337186 34.876671 \nL 301.743139 36.593153 \nL 301.844628 36.516534 \nL 302.859512 34.181379 \nL 304.17886 39.277079 \nL 304.787791 39.277079 \nL 305.092256 38.128905 \nL 305.498209 36.699347 \nL 308.339884 36.699347 \nL 311.181558 41.854811 \nL 311.790489 41.854811 \nL 311.891977 41.713319 \nL 312.500907 39.277079 \nL 314.530675 39.277079 \nL 315.951512 42.201588 \nL 317.067884 44.432543 \nL 318.996163 44.432543 \nL 319.300628 43.345048 \nL 319.706582 41.854811 \nL 320.315512 41.910021 \nL 323.664628 47.010275 \nL 324.17207 47.010275 \nL 324.476535 45.904115 \nL 324.882489 44.597946 \nL 325.491419 46.940004 \nL 326.201838 44.432543 \nL 326.912256 44.484942 \nL 329.652443 49.588007 \nL 330.768815 49.577398 \nL 331.479233 47.223725 \nL 332.088164 49.50541 \nL 332.798582 47.010275 \nL 334.422396 47.026934 \nL 337.365559 52.165739 \nL 338.58342 52.146762 \nL 339.19235 49.603086 \nL 339.80128 52.136224 \nL 340.511699 49.616173 \nL 340.613187 49.792944 \nL 342.94742 54.743471 \nL 345.078676 54.743471 \nL 345.180164 55.156627 \nL 345.586117 73.436618 \nL 345.789094 75.774879 \nL 347.006955 81.68103 \nL 347.818862 84.234416 \nL 349.239699 87.758615 \nL 349.544164 88.288635 \nL 350.965001 88.919775 \nL 351.472443 89.542853 \nL 351.472443 89.542853 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 31.890625 118.154489 \nL 31.890625 19.318125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 366.690625 118.154489 \nL 366.690625 19.318125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 31.890625 118.154489 \nL 366.690625 118.154489 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 31.890625 19.318125 \nL 366.690625 19.318125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n  </g>\n  <g id=\"axes_2\">\n   <g id=\"patch_7\">\n    <path d=\"M 31.890625 236.758125 \nL 366.690625 236.758125 \nL 366.690625 137.921761 \nL 31.890625 137.921761 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_3\">\n    <g id=\"xtick_8\">\n     <g id=\"line2d_13\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"47.108807\" xlink:href=\"#m4971bb263b\" y=\"236.758125\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 0 -->\n      <g transform=\"translate(43.291307 252.87625)scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_9\">\n     <g id=\"line2d_14\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"85.345445\" xlink:href=\"#m4971bb263b\" y=\"236.758125\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 25 -->\n      <g transform=\"translate(77.710445 252.87625)scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_10\">\n     <g id=\"line2d_15\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"123.582082\" xlink:href=\"#m4971bb263b\" y=\"236.758125\"/>\n      </g>\n     </g>\n     <g id=\"text_15\">\n      <!-- 50 -->\n      <g transform=\"translate(115.947082 252.87625)scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_11\">\n     <g id=\"line2d_16\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"161.81872\" xlink:href=\"#m4971bb263b\" y=\"236.758125\"/>\n      </g>\n     </g>\n     <g id=\"text_16\">\n      <!-- 75 -->\n      <defs>\n       <path d=\"M 8.203125 72.90625 \nL 55.078125 72.90625 \nL 55.078125 68.703125 \nL 28.609375 0 \nL 18.3125 0 \nL 43.21875 64.59375 \nL 8.203125 64.59375 \nz\n\" id=\"DejaVuSans-55\"/>\n      </defs>\n      <g transform=\"translate(154.18372 252.87625)scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-55\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_12\">\n     <g id=\"line2d_17\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"200.055358\" xlink:href=\"#m4971bb263b\" y=\"236.758125\"/>\n      </g>\n     </g>\n     <g id=\"text_17\">\n      <!-- 100 -->\n      <g transform=\"translate(188.602858 252.87625)scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_13\">\n     <g id=\"line2d_18\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"238.291995\" xlink:href=\"#m4971bb263b\" y=\"236.758125\"/>\n      </g>\n     </g>\n     <g id=\"text_18\">\n      <!-- 125 -->\n      <g transform=\"translate(226.839495 252.87625)scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_14\">\n     <g id=\"line2d_19\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"276.528633\" xlink:href=\"#m4971bb263b\" y=\"236.758125\"/>\n      </g>\n     </g>\n     <g id=\"text_19\">\n      <!-- 150 -->\n      <g transform=\"translate(265.076133 252.87625)scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_15\">\n     <g id=\"line2d_20\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"314.765271\" xlink:href=\"#m4971bb263b\" y=\"236.758125\"/>\n      </g>\n     </g>\n     <g id=\"text_20\">\n      <!-- 175 -->\n      <g transform=\"translate(303.312771 252.87625)scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-55\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_16\">\n     <g id=\"line2d_21\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"353.001909\" xlink:href=\"#m4971bb263b\" y=\"236.758125\"/>\n      </g>\n     </g>\n     <g id=\"text_21\">\n      <!-- 200 -->\n      <g transform=\"translate(341.549409 252.87625)scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_4\">\n    <g id=\"ytick_5\">\n     <g id=\"line2d_22\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"31.890625\" xlink:href=\"#m5ec4abc662\" y=\"219.163578\"/>\n      </g>\n     </g>\n     <g id=\"text_22\">\n      <!-- âˆ’1 -->\n      <g transform=\"translate(7.2 223.72264)scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-8722\"/>\n       <use x=\"83.789062\" xlink:href=\"#DejaVuSans-49\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_23\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"31.890625\" xlink:href=\"#m5ec4abc662\" y=\"185.881597\"/>\n      </g>\n     </g>\n     <g id=\"text_23\">\n      <!-- 0 -->\n      <g transform=\"translate(17.255625 190.44066)scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_7\">\n     <g id=\"line2d_24\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"31.890625\" xlink:href=\"#m5ec4abc662\" y=\"152.599617\"/>\n      </g>\n     </g>\n     <g id=\"text_24\">\n      <!-- 1 -->\n      <g transform=\"translate(17.255625 157.158679)scale(0.12 -0.12)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_25\">\n    <path clip-path=\"url(#p20e816d871)\" d=\"M 47.108807 232.245618 \nL 79.227583 232.226888 \nL 86.87491 232.265563 \nL 100.6401 232.216445 \nL 102.169565 231.521089 \nL 103.699031 231.464842 \nL 105.228496 224.557598 \nL 106.757962 224.224179 \nL 109.816893 219.041218 \nL 111.346358 219.009898 \nL 112.875824 218.274802 \nL 114.405289 218.165802 \nL 115.934755 217.781258 \nL 118.993686 217.620252 \nL 120.523151 217.34469 \nL 122.052617 216.79905 \nL 126.641013 215.941356 \nL 128.170479 214.93422 \nL 129.699944 214.277078 \nL 131.22941 213.250192 \nL 135.817806 213.250192 \nL 137.347272 212.353552 \nL 138.876737 211.657593 \nL 140.406203 211.657593 \nL 141.935668 210.834489 \nL 143.465134 210.834489 \nL 144.994599 209.9292 \nL 146.524065 209.680426 \nL 151.112461 207.967064 \nL 154.171392 206.960179 \nL 155.700858 206.704103 \nL 158.759789 205.13914 \nL 160.289255 204.962228 \nL 163.348186 203.804361 \nL 166.407117 203.799649 \nL 169.466048 201.47449 \nL 170.995513 201.164468 \nL 172.524979 200.21018 \nL 174.054444 199.470969 \nL 175.58391 198.54411 \nL 177.113375 196.081981 \nL 178.642841 195.796964 \nL 180.172306 193.127834 \nL 181.701772 193.127834 \nL 183.231237 192.913976 \nL 184.760703 191.438246 \nL 186.290168 190.458702 \nL 187.819634 190.458702 \nL 189.349099 187.789569 \nL 190.878565 187.505677 \nL 192.40803 185.334839 \nL 193.937496 182.746841 \nL 195.466961 182.451304 \nL 196.996427 182.451304 \nL 198.525892 180.614934 \nL 200.055358 179.910472 \nL 201.584823 178.420281 \nL 203.114289 176.12863 \nL 204.643754 174.45841 \nL 206.17322 173.918145 \nL 207.702685 169.649298 \nL 209.232151 169.105642 \nL 210.761616 168.275823 \nL 212.291082 165.86891 \nL 213.820547 163.767376 \nL 215.350013 163.767376 \nL 218.408944 161.098244 \nL 219.938409 160.773681 \nL 221.467875 159.186873 \nL 222.99734 158.446361 \nL 224.526806 158.24605 \nL 226.056271 156.095781 \nL 227.585737 155.75998 \nL 229.115202 153.238033 \nL 230.644668 153.157383 \nL 232.174133 152.163182 \nL 233.703599 150.421722 \nL 235.233064 150.421722 \nL 236.76253 149.522368 \nL 238.291995 149.045785 \nL 239.821461 147.902925 \nL 241.350927 147.752587 \nL 242.880392 147.066754 \nL 244.409858 145.843265 \nL 247.468789 145.083457 \nL 250.52772 145.083457 \nL 252.057185 144.112042 \nL 253.586651 142.414323 \nL 281.11703 142.414323 \nL 282.646495 143.070865 \nL 284.175961 143.399677 \nL 285.705426 145.083457 \nL 288.764357 145.083457 \nL 290.293823 147.241095 \nL 291.823288 147.257603 \nL 293.352754 147.752587 \nL 296.411685 147.752587 \nL 297.94115 149.645127 \nL 299.470616 150.483603 \nL 302.529547 150.63765 \nL 304.059012 151.393201 \nL 305.588478 153.090854 \nL 308.647409 153.090854 \nL 310.176874 154.289888 \nL 311.70634 155.75998 \nL 313.235805 155.75998 \nL 314.765271 156.829487 \nL 316.294736 157.296129 \nL 317.824202 158.429112 \nL 320.883133 159.794877 \nL 322.412599 160.093989 \nL 323.942064 161.098244 \nL 325.47153 161.269516 \nL 328.530461 162.248486 \nL 330.059926 163.767376 \nL 331.589392 163.767376 \nL 333.118857 163.963407 \nL 334.648323 164.543671 \nL 336.177788 164.747534 \nL 337.707254 166.452122 \nL 339.236719 166.465673 \nL 340.766185 167.338105 \nL 342.29565 167.390086 \nL 343.825116 170.785059 \nL 345.354581 171.774774 \nL 346.884047 189.515745 \nL 348.413512 199.667473 \nL 349.942978 204.232831 \nL 351.472443 206.703968 \nL 351.472443 206.703968 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_8\">\n    <path d=\"M 31.890625 236.758125 \nL 31.890625 137.921761 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_9\">\n    <path d=\"M 366.690625 236.758125 \nL 366.690625 137.921761 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_10\">\n    <path d=\"M 31.890625 236.758125 \nL 366.690625 236.758125 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_11\">\n    <path d=\"M 31.890625 137.921761 \nL 366.690625 137.921761 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p2fe587beab\">\n   <rect height=\"98.836364\" width=\"334.8\" x=\"31.890625\" y=\"19.318125\"/>\n  </clipPath>\n  <clipPath id=\"p20e816d871\">\n   <rect height=\"98.836364\" width=\"334.8\" x=\"31.890625\" y=\"137.921761\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAEICAYAAACgQWTXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3deXxU1fn48c+TfSchE7ISEghr2An7IiqKYF2qrRvWpUVcSqu1X61WrbS1VdtfF1u1ior71iqKFpe6oOxgWGRfA4EEQjay78n5/TFDHAJhnZk7kzzv1ysvmHtn7nnOvXeenJx77rlijEEppVTH4Gd1AEoppVxHk7pSSnUgmtSVUqoD0aSulFIdiCZ1pZTqQDSpK6VUB6JJXSmlOhCvSOoiMltEskWkXkRecsP200TkIxE5LCIFIvKkiAS4uhyllLKaVyR14ADwCDDPTdt/GigEEoGhwDnAHW4qSymlLOMVSd0YM98Y8z5Q0nadiHxPRNaLSJmILBeRwWdQRDrwb2NMnTGmAPgEyDzLsJVSyut4RVJvj4gMx956vxWIBZ4FPhCR4NPc1BPANSISJiLJwDTsiV0ppToUr07qwC3As8aYVcaYZmPMy0A9MOY0t/M19pZ5BZAHZAPvuzRSpZTyAt6e1HsAv3R0vZSJSBnQHUgCEJGvRMS087PU8R4/4FNgPhAO2IAY4HFLaqSUUm7k7Ul9P/AHY0y000+YMeZNAGPMZGOMtPMzwbGNrth/ETxpjKk3xpQALwLTramSUkq5j1ckdREJEJEQwB/wF5EQx5DD54DbRGS02IWLyMUiEnmq2zbGFAN7gNsd5UQDNwLfuqMuSillJa9I6sCDQC1wH3C94/8PGmOysferPwkcBnYBN53B9q8ALgKKHNtoAn5x1lErpZSXEX1IhlJKdRze0lJXSinlApbfKm+z2UxaWprVYSillE9Zs2ZNsTEmru1yy5N6Wloa2dnZVoehlFI+RURyj7dcu1+UUqoD0aSulFIdiCZ1pdRZW7vvMOMf+5KfvbnO6lA6PU3qSqmz9vbq/eSX1fLhtwdYu++w1eF0apZfKFVKeVZhZR1rc08/8Q5M7oItIpj1+8uoaWhiSEo0NQ3NhAX5878tBUzpH8/qPSU8vySHp2eMACB7bykx4UHYIoJZm3uY1NgwesVFuLpKyokmdaU6kf2lNfzgmeUcqqg/622d2zeORduLWl/PGJNKn/gInvl6N7kl1QjCD55ZAcAVw5KZvy4ffz/hq/+bTPeuYWddvjo+TepKdRKFFXVc/8Iq6hpbePUno7BFnPpjCV5bmcvrq/a1vr4oM4FPNhe0vk7sEsKk3nFkJkbx3JIc5i3dQ5otvHX9/HX5DE7pwsb8ct5dm8ddU/q4plLqGJrUleogiirrmfPBZkqrG4gKDSAiOJArhiczPsNGWU0DP3phNUWV9bw2czTDU2NOa9sXDIg/KqlfPbL7UUn9hyNS8PcTukWFcPnQZF5eYR9CndQlhAPlda2fiQoJ5D/Zefz8vN6s21/G3z7bgQg8fEkmGd20W8YVNKkr1UH87r9b+GzLIfonRrIix/5kyHfX5vHNA1O45ZVs9hRX8+LNI087oQOM62XjzvN7k9AlhIFJXegdH8G0gQkkdAkhJiyIG8b2aH3v/03tS3ltI2W1jfx4fDpbDlawq7CS6QMTiQgO4M631rMyp4TXVuWybt9hDPCnT7Yx94YsV+2KTs3yCb2ysrKM3lGq1KmrrGukuKqBtNgwRASAr3cUceO81dw1pTd3TelD2n0LW98fHRZIZV0TT88YztTMBKvCBqCusZmRf/icMT1jWbqzmCtHJBMbHswTX+zk4zsn0j8xirrGZvaX1rR+pltUCF1CAy2M2juJyBpjzDG/CbWlrpQPaWpu4bInl5FTXA3AzePT+NVF/Xjo/U30tIVz++ReAIxO78qqPaVclZXCv7Pz+MsPh1ie0AFCAv25fGgyr660d89MzUxgcHI0Lyzdw5Nf7uKpGcO5+9/r+Wjjd107USEBLL//fCKCNV2dCt1LSvmQd9bktSZ0gBeX7SXQ3499pTW8cctoggP8AZh300jKahuJjwzmtnN60dOLhhHec1FfxvaKJTTQnwkZNkSEm8al8dRXu9iYV84XWwuZmhnPJUOS2JBXztzFOazKKeH8/vFWh+4TtPtFKS92qKKOf321Gz8RfjIxnSufXk5idAjr9pUd9b4rh6fwl6uGWBTl2Ttc3cD4x7+ka3gQeYdreeHGLM7vH09dYzNDfvs/ZozuwaQ+NmoamomLDKagvI5ByV2OGmHT2Xik+0VEXgPOx/6A5wLgT8aY511ZhlKdydzFOby8Yi/GwMKNBzhUUc/frh5KTUMTzy7Oobq+iaiQQH49vZ/VoZ6VmPAg7jy/N3MX59A3PpLRPWMBe3dNVloMX+0oZN6yPUd95vKhSfz9mmFWhOvVXN398ijwE2NMvYj0A74SkXXGmDUuLkepDq+xuYX31+VzUWYC3+wt5VBFPRN72xjby57wOlp3xK3n9OLWc3ods3xcLxt//nT7McuX7y7BGINzZ4MIrRePOyuXJnVjzGbnl46fXoAmdaVOQVlNAz99Yy07D1WRmRRFSXUDPxiRQnOL4X9bDnHvVN9ukZ+JCRnHT+qFlfX8JzuPB9/fRENzCwA9beHMv2Mc0WFBng7Ta7i8T11Ensb+cOhQYB0wyRhT1eY9s4BZAKmpqSNyc48717tSnc7fPtvBE1/sbH1tiwhm5f3nUVrTwJ6i6tZuic7EGMPrq/YRERxAdFggkSEBBAf4871/LiXQX/AT4Y7JGTQ0N/P0V7uZOSGdBy4eYHXYbuexIY3GmDtE5GfAWGAycMwkE8aYucBcsF8odXUMSvmSnYcqWb23lKmZCby0fO9R664YnkyAvx/dIkPoFhliTYAWExGuH9PjqGXGGJKjQ8kvq2VSHxt3TukNQGFFPS8vz+WGsWnERQYzf20+9U3NhAcFtO7Ljs4tQxqNMc3AUhG5Hrgd+Ic7ylHK1xljmPXqGvYUV/PCkj2U1zYyc0I6/1mTh5/ANSO7Wx2iVxIRpmYmMG/ZHqYN/G78/S8v7MuHGw7wp0+3MzHDxq/f29i6zmC4emSqFeF6lFuHNIrI80C1MebO9t6jQxpVZ7Zu32G+//Ty1tcTMmy8NnO0hRH5DmMMlY7RP87+8r/t/PPLXfSMC6eitpHPfnEON8xbTUVdI1/cfU6Haa231/3istqJSDcRuUZEIkTEX0SmAtcCX7qqDKU6gsLKOma9ks03e0t5Y9U+woL8GZgcBcAd5x47+kMdn4gck9DBPorGFhFETlE1o9NjiQkPYvZ5GeSW1PDhhgMA1DQ0cdUzK5j9xlrqm5o9HbpbubL7xWDvankG+y+LXOAuY8wCF5ahlE8rqqznuudWsauwihZjWLqrmO8PS2b2eb1ZvKOIsZ3wQqirRQQH8OR1w/lPdh63TEoH4IL+8fRLiOSfX+7i0iHJLNtVwuq9pQD0jIvg7gs6zlTALkvqxpgi4BxXbU+pjqK5xbAyp4Tiqnqe/HIX+Ydr6Z8YxedbCwG4dlQqydGhXDuq4/f3esqYnrGMcfoF6ecn3Hl+b25/fS1PL9rF1oIKQgP9Oa9/N55etIuLMhMYkBRFQ1MLtQ3NbC2oYESPGAJ9sKtG535Rys0e/mATr620z0UeFuTPvJtGUlRVz8/fXMeIHjEMTom2OMLOYWpmAv0To/jLZzscr+P5w+UDWZVTyj3vfMu7t4+j30OftL5/+qCE1sfy+RJN6kq50WdbDvHayn3cMLYHN4ztQXxUCJEhgRhj6BMfQVps5527xNP8/IQ3Zo5unRCtT3wEkSGBPHJ5Jre9tpZbXz36HsmPNhawJvcwI3qc/vzzVtKkrpQLbcov54kvdtLU3IIB1uYeZkBiFA9c3L91BkWwX+TrlxBlXaCdVEx4ECPCj77b9KKBiVw8KJGFGw+2Lnv4kgE8tWg3j3+8jbdvHUNtYzMfbSxgU345eYdrSIkJ475p/QgJ9G9bhOU0qSvlQvPX5rNoWyH9E6PwExicEs1vL8s8KqEr7/PbyzKpaWgiPDiA0EB/rsrqToC/Hw+9v4lF2wv5entR6yP6UmJC+XxrId2igrljcobFkR9Lp95VyoV+9MIqymsb+WD2BKtDUWepsbmFC/76dWtrfFtBJQAr7z+fB9/fxIrdxSy6ZzLdIkNoaTG0GEOLgaAAz1xcdfs4daU6s8bmFnrev5AlO4vp3S3S6nCUCwT6+/F/U/uyraCyNaEDJHQJ4YGL+9PQ3ML/c0w0dufb68l44GP6PPgxa3JLrQoZ0O4XpVxiU345LY4/evsmeM9ThtTZuXhQIgHX+1Hb2MTQ7jGEBdlb7em2cG4al8bzS/dww9g0Pvz2QOtnnvhiF6/8eJRVIWtSV+pMNTW38OziHNJt4exzelByT5sm9Y5CRLho4PGf7fqz83szf20+d729/qjli3cUseNQJX3irfmLTbtflDpDH244wJ8/3c4dr69l2a5iAC4ZktT6EAvVsUWFBDLn0kyKq+qJDQ/CFhHMY1cMIjTQn2e+2m1ZXNpSV+oMGGN49uuc1tdLdhZz3ehU/vj9QRZGpTztkiFJXDIk6ahlOw5V8fKKvdx9YR9SYsI8HpO21JU6A0cunt0ztW/rsjE6b4sCbpmUjp/A5D9/RZ8HP+b++Rs8Wr621JU6Ax9tPIifwNUju5McHUphZR1TMzvWM0PVmUnsEsrfrx7Ghvwynv06hyU7iz1aviZ1pU5DSVU9JdUNLNx4kNHpsdgigrl8WLLVYSkvc/HgRC4enEhZdSNf7yjyaNma1JU6RcVV9Vzx9PLWkS43j0+3OCLl7QIDhEbHQ7E9RfvUlToFNQ1N/OTl7KOGLmp3izqZAD8/Gnw1qYtIsIi8ICK5IlIpIutEZJqrtq+Ulf6wcCsb88r457XDWpd11gdBq1MXFOBHU7Nnp2JxZfdLALAf+4My9gHTgX+LyCBjzF4XlqOUR209WMGbq/dxw9g0LhmSRHiwP0nRoVaHpXxAoL/nu19c+eSjamCO06L/isgeYASw11XlKOUp9U3NBPn78cjCLUSGBHLXlN4AnNdPu13UqQnw86OpxWCMQUQ8Uqbb+tRFJB7oA2x2VxlKucviHUX0ffAT/v75TpbtKuEXU3oTHRZ08g8q5eTIjI2NHuyCcUtSF5FA4HXgZWPMtuOsnyUi2SKSXVTk2eE+Sp2Kecv2APDEFzvJ6BbBjDE9LI5I+aJAf3vr3JNdMC4f0igifsCrQAMw+3jvMcbMBeaCfT51V8eg1OkwxvCnT7eTd7gWgFHpXflmz3fTpz54cX+ffACxsl6A35GWuo8mdbF3Gr0AxAPTjTGNrty+Uu5QUFHHv77aTVxkMI3NLa3TqH5vcCK2iGAm9+1mcYTKVwVa0P3i6pb6v4D+wBRjTK2Lt62UW+SW2Mee/+WHQ6iub+L219cSHxXME9cMw9/PMxe3VMcU5MvdLyLSA7gVqAcKnK703mqMed1V5SjlKvOW7uH99flsyCsHIC02nJjwQMKC/LlieIomdHXWfLr7xRiTC+i3QPmM3/13y1Gvk6JDCPD34/O7z8EWEWxRVKoj+a77xQeTulK+4r11edQ0NB+zPMBxMVRvLFKu8l33i+/2qSvl1XYVVvGLt79tfR0W5E9USCATetssjEp1VD7d/aKUL3h/Xf5Rr1f++nyiQgItikZ1dNr9opQbrN5Tyr3vfEtSdCj7SmuY1CeOxY45rjWhK3cK1O4XpVzr080F/OzNdTQ0tbDXMXTxlxf24d6pfQkO0BuKlHsdOcfqGo+9huMumtRVh7Ihr4w9xdUYA3tLqvnHFzsZnBLNH74/kIv/sZSwIH+mZiYQFqSnvnK/GMd8QaXVDR4rU89s1WHUNTZz9bMrqXVqFZ3bN46nZgwnLCiAUeld6RsfqQldeYwt0j40tqiy3mNl6tmtOoy1+w5T29jM41cOYlR6LAF+QkpMaOuUp/++dSzG6FRDynMigwOwRQSzvaDSY2VqUlc+7/VVuSxYf4D6phb8/YTpgxKJbOcCqKfmtFYK7OfbkJQubMgv91iZmtSVTyuraeCPC7dS7biZaEj36HYTulJWGJwSzZfbC6mqbyIi2P0pVy//K5/U0GQf9/visr1UNzQzPDUagBGpMVaGpdQxBnfvgjGwMc8zrXVN6srnPPrRVib9aRHFVfW8tHwvU/rHc8PYNMA+F7pS3mRwchcANuaXeaQ87X5RPmXnoUqeXZwDwC/eXk95bSOzz8tgSEoXMrpFMNDxBVLKW8RGBJMcHcraXM8kdW2pK69XWdfIM1/vprCyjkcWbiXAMSXukp3FTMiwMbR7NCKiCV15rUl9bCzZWeSRm5C0pa682oa8Mma/sY59pTXMX5vHjkNVPHhxf3YXVbMhr4z7p/ezOkSlTurCzATeXL2f5buLOa9fvFvL0qSuvEJjcwsBftI65NAYw7xle3ns463ERQQT6C/sOFRFWmwYN4xNa31Ku1K+YFyvWKJCAnhv3QG3J3WXfjNEZLaIZItIvYi85Mptq45pU345d721jv4PfcLMl7MBOFzdwMyXs/n9f7dwTp9ufHTnRG4/pxcA917UTxO68jnBAfanaX2y6SDFVe69u9TVLfUDwCPAVECfNKCOq6XF8PWOIp5bksPy3SWEB/kT6O/Hl9sL+d/mAn6zYDOl1Q3MuWQAN45LQ0S4fXIGI9K6MknnPVc+asboVF5avpd31uRxm6OR4g4uTerGmPkAIpIFpLhy28q3GWMoqKhj3b4y/vrZDnYVVpEQFcL90/pxzahUdhVWcuW/VjDr1TWkxYYx/45xR134DA3y55w+cRbWQKmz0zs+kpFpMby6IpcfjEhx2yMTLelTF5FZwCyA1NRUK0JQHmCMYfuhSt5bm8/SXcVsPlABQN/4SP5+9VAuHpxIoOMRcoNTohmQGEW/xEh+d9lAj9x5p5SnzT6vNze9uJrxj33Jry7qx48npLu8DHHHBEci8giQYoy56WTvzcrKMtnZ2S6PQVmjoamFF5ftIb+slqU7i8kprgbsExvdPD6NlJgwvj88uTWZK9XZ7DxUyaMfb+PLbYW8d8c4hp3hXdAissYYk9V2uTaH1Fmrrm/im72lLNxwkEXbi1ovBI1K78rMiT0Z1yuWHrFhOpmWUti7YZ6eMZwF6/MZ2j3a5dvXpK7atWJ3CXM+2Mxbs8YQEx503PfsLqpixnOrKKioA6BfQiRzLh3ARZkJBGhrXKnjCgn05+qR7ul6dmlSF5EAxzb9AX8RCQGajDFNrixHuU9Li+GxT7YxbWAC1z63EoDhj3zGE9cM49IhSUe91xjDz99cR31TM/+8dhix4UGMy9DRKUpZydVNqQeBWuA+4HrH/x90cRnKjZ5ZvJu5i3P4/tPLW5cZA++vyz/mvev2l7H5QAX3TevHJUOSNKEr5QVcPaRxDjDHldtUnrF8VzHXPb/quOvGZ8Syr7Sm9XV5bSO/WbCJ+sYWggL8mD4o0VNhKqVOQvvUOzFjDLsKqyirbWw3of/20kw2Hyhn2a4S0u5beMz6H4xI0YdSKOVF9EpWJ1VYUcfDH2zmgr8t5qH3Nx21bkSP74ZY3TgujZYTjHq98/ze7gpRKXUGtKXegX26uYCRaV3p6hi5UlBex5hHvzjmfdscD8X9/WWZZCZ3YVj3aF5avpdukSGAvfvlnTV5R30mMymKp64bTveuYW6uhVLqdGhS91F1jc2I2CcKMsbQYuDifyyhtrGZ3JKao977+JWD+NW7G0+6zR85nh4EcPP47+50+/6wFCKCA7nlle9uEvvVRf1Is4WffUWUUi6lSd1H9XvoEwCSo0PJL6vlwYv7t7a422ovoQ9LjWbdvlN7GssFA+LZ8+h0Pt1cwG2vrSUtVhO6Ut5Ik7oPOuS40Qcgv6wWgEcWbj2tbQQF+PHGzDHsKa7m1teyefnmUSf9jIhw0cBEcv44HT8/vTtUKW+kSd0HlVY3nHD9zAnpXDo0iUufXNa67MWbR/LNnlIKKuqIiwzmimEphAb5MyApiiX3nnda5WtCV8p7aVL3Mct2FXPvOxvaXR8S6MePJ6STFB3Knken85sFm5k+KJGxvWI5t283D0aqlLKCJnUfM6PNePLe3SK4c0pvxvWyERUScNR8KyLC7y8f6OkQlVIW0qTuA3JLqukaHkRtmyeRj8+I5fWZYyyKSinljTSp+4Bz/vwVAxKj2HKwonXZZUOT+PvVQy2MSinljTSp+wjnhL5hzoVE6a35Sqnj0GkCfJAmdKVUezSp+5Abx/Zg5x+mWR2GUsqLafeLl/vzp9sAuCgzgd9epiNZlFInpi11L/fUot0AfLK5wOJIlFK+wKVJXUS6ish7IlItIrkicp0rt9+Z7C+tIbek2uowlFI+xtXdL08BDUA8MBRYKCLfGmM2u7gcdhVW8f2nl1HX2ExIgD9RoYHYIoL4Nq+cuMhgKusa6d0tko355QDEhgfRKy6C2IggluwsJjjAj1HpXSmvbWTHoUqiw4LwF6FbVDDRYUH8d8MBzAnmEe8ZF05RRT0A4zNs7CisJKlLKCPTulJR10h4cADBAX4cqqijpLqBhRsOcsmQJD789gDptnCq65sIC/JnWGoMxhgOVdSTGB3CrsIqmprNUaNdAOIig129C5VSHZCYE2Wu09mQSDhwGBhojNnhWPYqkG+Mua+9z2VlZZns7Oz2Vrfr8qeWsX7/qc0w2BEsvudcUmN17nKllJ2IrDHGZLVd7sqWeh+g+UhCd/gWOOc4wcwCZgGkpqaeUWF/uWoI+0prECAyJJBukcHsL60hNiKY5JhQNuSVkdQllL0l1dQ2NNMvMYpDFXWMTOvK1oMV+PsJwQF+iAiFFXXERgRRVd9Memw45bWNhAf7s+VgBd1jwgjwt09gVVXfRGVdE1EhgdQ1NhMZEkBTi0GA2sZmesSGExEcwK7CKqLDAmkxhojgAIoq69mQV05yTCgVtY0kx4Sy5UAFtohg+sRHEh0WSGVdE0EBfhRV1hEc4M/hmgaeXZzDD0ak6JwtSqlT5sqW+kTgP8aYBKdltwAzjDGT2/vcmbbUlVKqM2uvpe7KC6VVQFSbZVHA8Z/coJRSyuVcmdR3AAEi4vwk4iGAyy+SKqWUOj6Xdb8AiMhbgAFmYh/98hEw7kSjX0SkCMg9wyJtQPEZftbbaF28T0epB2hdvNXZ1KWHMSau7UJXD2m8A5gHFAIlwO0nG854vKBOlYhkH69PyRdpXbxPR6kHaF28lTvq4tKkbowpBS535TaVUkqdOp0mQCmlOhBfT+pzrQ7AhbQu3qej1AO0Lt7K5XVx6YVSpZRS1vL1lrpSSiknmtSVUqoD0aSulFIdiE8mdV+at11EvhKROhGpcvxsd1p3nSP+ahF5X0S6Oq2zvI4iMltEskWkXkRearPufBHZJiI1IrJIRHo4rQsWkXkiUiEiBSJy96l+1tN1EZE0ETFOx6dKRB7y1ro44nnBcU5Uisg6EZnmtN5njsuJ6uKDx+U1ETnoiGeHiMw8lVjcUg9jjM/9AG8CbwMRwASgHMi0Oq52Yv0KmHmc5ZnY58WZ5KjHG8Bb3lRH4Ars9x38C3jJabnNEc8PgRDgz8BKp/WPAkuAGKA/UABcdCqftaAuadjvgg5o53NeVRcgHJjjiNsP+J7jPErzteNykrr42nHJBIId/+/niGeEFcfErV8kN54IDUAfp2WvAo9ZHVs78X7F8ZP6H4E3nF73ctQr0tvqCDzC0YlwFrC8zTGpBfo5XucDFzqt/z2OX1gn+6wFdTlZ8vDaujiVuwG40pePy3Hq4rPHBegLHASusuKY+GL3S3vztmdaFM+peFREikVkmYhMdizLxB43AMaY3TgSOd5fx7axVwO7gUwRiQGSnNdzdOztftbNMZ9MrojkiciLImID8IW6iEg89vNl84ni8cG6HOEzx0VEnhaRGmAb9qT+0YlicVc9fDGpR2D/k8RZOfYWrjf6FdATSMZ+o8GHItKLE9fD2+t4sthps945dm+rWzEwEuiB/c/lSOB1xzqvrouIBGKP9WVjzLaTxONrdfG542KMucNRxkRgPlB/kljcUg9XT+jlCT41b7sxZpXTy5dF5FpgOieuR8sJ1nmDE8Ve5fS6rs26k33W44wxVcCRp7QcEpHZwEERicKL6yIifti75BqA2acQj0/VxVePizGmGVgqItcDt58kFrfUwxdb6r4+b7sBBHu8Q44sFJGeQDD2+nl7HdvGHo79msBmY8xh7H96DnF6v3Ps7X7WzTGfqiO3WIu31kVEBHgB+wPerzTGNJ4sHh+sS1tef1zaCHAq07PHxJMXQVx4IeIt7KNDwoHxeOnoFyAamIr9ynUAMAOoxn4hJROowP6nWjjwGkePfrG8jo6YQ7BfoX/VqR5xjniudCx7nKOv6D8GfI39in4/x4l75Ir+CT9rQV1GO46HHxCLfcTRIi+vyzPASiCizXJfPC7t1cVnjgvQDbgGe3eJv+M7Xw1cZsUxcesBc+NO7Aq879hx+4DrrI6pnTjjgG+w/7lU5jh5L3Baf50j/mpgAdDVm+qIfbiZafMzx7FuCvYLQrXYR/ikOX0uGPu8+hXAIeDuNttt97OergtwLbDHsZ8PAq8ACd5aF+x9zAb7n+tVTj8zfO24nKguvnRcsH/Pv8b+Ha8ANgK3nEos7qiHTuillFIdiC/2qSullGqH5aNfbDabSUtLszoMpZTyKWvWrCk2HnhG6WlLS0sjOzv75G9USinVSkRyj7dcu1+UUqoDsbylrpTyHGMM2bmHqaxrbzi466V2DSOjm7fcDN3xaVJXqhN5/JPtPPP1bo+XO6ZnVyb37caU/t00wbuZJnWlOoHmFsPTi3bxzNe7uXZUd64ZmeqRcg2wYncJ/87ez2Mfb+OJz3fy+i2jGZ4a45HyOyPLx6lnZWUZvVCqlGu0tBi2H6pkVU4JWw5W0NxiX779UAWb8iu4ZEgSf796KP5+4vHY8stqmfHcSspqGzm/XzwAgf7CzIk9yegWcZJPq7ZEZI0xJqvtcm2pK9VBvLFqH3/+dBuHa+z95baIYIID7GMhwhhunxIAABbSSURBVIL8eeKaoVw6JAn7dCuelxwdyis/Hs3P3lrHypwSAEqrG1i9t5SFP5tIaJC/JXF1NJrUlfJxuSXVPPH5Tuavy2dsz1iuHJHC6PSudO8aZnVox0iNDWPBT8e3vl6+u5gZz6/iZ2+uY3R6VzKToxiV1pUAfx2Yd6Y0qSvlg/aX1vDwB5vZerCCgoo6AvyE2edm8IsL+ljStXKmxvWycef5vfn75zv5fOshAIL8/VrrEB8VzEs3jyLNFm5lmD5F+9SV8iE5RVV8vKmAZ7/ejTFwQWY8PW3h/DCrO/FRIVaHd8bqGpupb2xh2e5ivt1fZp9xzRjeWZOHLSKY9346nohgbYM6a69P3aVJ3TGR/U3AIOBNY8xNJ/uMJnWlTmxTfjlFlfV8urmAt7P3Y4x9iODjVw6mR2zHbsEu21XMDfNWkxEXwS8u6EOaLYzwoACiwwKJDAm0OjxLeepC6QHsD/adCoS6eNtKdTpvrNrHr9/bCECAnzBzQjo/mdCThC6+2yo/HeMzbDx7/Qh+998t3PbamtblInDJ4CTuvqCPds204dKkboyZDyAiWUCKK7etVGezcMNBHlqwicl947jz/N4kdAkhsUvnaytNGRDPpD5xrN5TSnltI9X1TWw/VMmbq/exdFcx794+jnRN7K20k0opL7KtoIJPNhWw9WAFn24+xJDu0Tx13XDCO3l/clCAHxN6245adv2YHlz5r+Vc//wqxvWKbX3fzePTO/W4d0vOFBGZBcwCSE31zJ1tSnm7irpGrn9+NcVV9USGBHDXlN7cMTmDoAAd3nc86bZwXrxpJPe+s4Flu4oBOFzTyIL1B/h/PxzCRQMTLI7QGm4Z/SIijwApeqFUqVM354PNvLJiLwt+OoFBKV2sDscnHSyv5bbX1rIhr4zHrxjMVSO7Wx2S27R3oVSbAEpZ7MNvD3DN3BW8smIv14/poQn9LCR2CeWtW8YwIcPGve9uIPM3nzDtiSV8u7/M6tA8xqXdLyIS4NimP+AvIiFAkzGmyZXlKNVRrN9fxl1vr6dHbBg/Hp/OXRf0sToknxca5M/zN2Yxb+leiqvq+WjjQa7813IuGBDPpUOSuGhggmVTJXiCq8epzwEebrP4t8aYOe19RrtfVGe0r6SG9Xll/OV/22lqNnx050S6hHbucdfuUl7byN8+28FHGw9SWFnP9wYn8sjlA4kOC7I6tLPikZuPzoQmddWZFFXW89sPN7Nw40GMgdBAf166eSSje8ZaHVqH19Ji+NfXu/nrZzsI8vfjqqwUbh6f7rPj3DWpK2Wx0uoGrpm7gn2lNdw8Pp3LhyaT2jVMZyf0sO0FlcxdnMMH3+bT1GIYmNSFET1imH1eBraIYKvDO2Wa1JWyyLaCCv755S5W5ZRSWdfIizePZFwv28k/qNyqsKKON1bv45u9pXyz5zDhwf5cMTyFtNgwzunTjdRY75vl0pnOp66UBRbvKOKO19cS6C+My7Bxw5ge2tXiJbpFhXDXFPuF6Z2HKvnNgs28tjKX+qYWYDMDEqO4eHAiP5mQTkig7/w1pS11pdzk39n7+fX8jWR0i+DFm0d2ylv8fY0xhv2ltfxvSwGfbCogO/cwk/vG8cz1I7wusWv3i1IeUFbTwI3zVpNTVE1lfRMTe9t4esbwTj+joK96a/U+7pu/kZBAP4ID/EmICmFQSheuGJbM4O7Rlk4HrN0vSrmZMYZfvbuBLQcruG5UKskxodw8Pp1AfYqPz7pmVCq2iGCW7y6hqaWFA2W1fLqpgHfW5AEwMi2GeTeN9Kpf2prUlXKRt77Zz6ebD/HA9P7cMqmn1eEoF5kyIJ4pA+JbX9c2NLN4ZxFbDlTw1KJd3PrqGn52Xm+So0O94uKqJnWlXOBQRR1/XLiVsT1j+cmEdKvDUW4UGuTP1MwEpmYmkNo1jF/+51uW7y7BT+Dqkd0Z0zOWnrYIy6Z70KSu1Fmqb2rmgfc20dDcwqNXDMLPh54Rqs7OlSNSGNI9mqLKej7feoiXl+/lzdX7CfQXltx7niUPM9GkrtQZKq1uYOGGA8xdksP+0lp+Pb2fz96dqM5cRrcIMrpFMLZXLLPPzWB3URVXPbuCl5bv5b5p/TwejyZ1pc7AoYo6Lvjr11TUNTEwOYpHfjyISb31hqLOLiY8iKzwrkwbmMjrq3KZfV6Gx0fI6GV5pc7AgvX5VNQ18e9bx/Lfn03knD5xHXrmP3V6Zk5Mp7KuiYfe30RlXaNHy9akrtQZeH/dAYZ0j2ZUelerQ1FeaFhqDD89txcL1udz+VPLaGpu8VjZmtSVOk3bCyrZcrCC7w9NsjoU5cXumdqP+6b1Y3dRNaXVDR4rV5O6Uqdh+e5ifvffzfj7Cd8bokldnVhqV/u49eIqzyV1vVCq1Cl6fkkOjyzcSmRwAL+8sI9PTdOqrBHrOEdKqus9VqYmdaVOwYL1+TyycCvTByXw16uGet3kTso7xYbbn65Uoi11pbzH/tIa7p+/kVHpXfnb1UMJDtCErk7NkZZ6cZXnWurap67UCbS0GO59ZwN+IprQ1WmLCgkg0F8o0QulSlmvpcXw4IJNrMgp4YGL+5McrfOhq9MjIsSGB1PiwZa6dr8odRyb8sv5++c7+HxrIbdP7sU1I7tbHZLyUbbIIB39opSV3v5mH796dyMRwQH8eno/bpnYU+8WVWdMW+pKeZgxhsLKenKKqjlQVssD721iYm8bT80YTpQXPfxA+abYiCB2FVZ5rDxN6qpTa2pu4foXVrEyp7R1Wa+4cJ68ThO6cg1bRDAl1fUYYzzyF59Lk7qIdAVeAC4EioH7jTFvuLIMpVzp9VX7WJlTyh2TezGul41Af2FgchfCLXz2pOpYYsODqGtsoaah2SPnlatLeApoAOKBocBCEfnWGLPZxeUoddZKqur5y/+2MyHDxj1T+2q/uXKL1rtKqxo8ktRdNqRRRMKBK4GHjDFVxpilwAfAj1xVhlKuYozhoQWbqGloZs6lAzShK7eJjbDfVVrsoakCXDlOvQ/QbIzZ4bTsWyCz7RtFZJaIZItIdlFRkQtDUOrkmlsMb67ez0cbC7j7wj5kdIu0OiTVgdnCv2upe4Ir/xaIAMrbLCsHjvnGGGPmAnMBsrKyjAtjUOqE/rvhAPf8ZwO1jc2MSu/KrZN6WR2S6uCOtNQ9NazRlUm9CohqsywKqHRhGUqdsYq6Rh5esJl0Wzg/mZDO1IEJ+OtDopWbdT0yqZeHpgpwZVLfAQSISG9jzE7HsiGAXiRVlqppaGJDXjkL1udTWtPASzePYlBKF6vDUp1ESKA/kSEBFFbUeaQ8lyV1Y0y1iMwHficiM7GPfrkMGOeqMpQ6XYu2F/LA/I0cKLd/oa7KStGErjyuR2wYe0pqPFKWq8fX3AHMAwqBEuB2Hc6orPLKir38ZsFmeneL4JnrRxAbEcTw1Birw1KdUE9bBOv2H/ZIWS5N6saYUuByV25TqVO1fn8Z767Jo6nFkHe4hiU7i5nSP54nrxumD7VQlkq3hfPhhgPUNTa7/VzU2+ZUh1BV38Qtr2RTWddIeFAACV1CmDkhnV9N60egv84wrazVMy4cY2BfaQ194t07hFaTuuoQnl60i6LKet7/6XiGdo+2OhyljtLTFgFATlGVJnWlTuSzLYd4ZcVeVuaUcMWwZE3oyiulx4UDkFNc7fayNKkrn5V3uIafv7mO2IggfpjVnV9e0MfqkJQ6rojgALpFBpNTpEldqXbN+WALAG/NGkNKTJjF0Sh1Yj3jwtnjgZa6XkFSPifvcA23vbqGz7ce4q4pvTWhK5+Qbosgp8j9D8vQlrryGYUVdfz1sx28uzYPfz/hnql9mTmxp9VhKXVKesWFc7imkcLKOrpFhritHE3qyqs1txhW7C7hm72lzFu6h/qmFq4Zmcrtk3uRFB1qdXhKnbLxGTbAfnF/xugebitHk7ryWkWV9dz19jqW7SoBYGJvG7+7bCDptnCLI1Pq9PVLiKRnXDgLNxzUpK46n9V7Spn9xlrKaxt55PKBXDI4iS5h+sxQ5btEhO8NSuRJxz0VcZHBbilHk7qyVHOLYfHOIt7JzuObvaW0OGbXL62up0dsOC//eBT9E9vO6KyUb7p4cBL/+HIXn2w6yI/GprmlDE3qyuMKK+t4bUUuu4qqWJN7mEMV9cSEBXJu326EBPkj2OegnjWpJ5Eh2jpXHUef+Aj6JUQyd0kOP8zq7pZ5YDSpK48pqarn2cU5vLJiL43Nhh6xYQztHs3lQ5M5r383ggN00i3VsYkIv7lkANc9t4onv9zF/03t6/IyNKkrt2lqbmHVnlI+2niQb/aWsqe4muYWw+VDk/n5+b1J0wueqhMa18vGFcOTeXbxbi4fluTyZ+RqUlcuZYxhnWMK3I82HuRwTSNhQf6M6RnLlP7xXDE8WR/0rDq9B6b3Jy4imPgo149X16SuXOJgeS3z1+bz7to8coqqCQn044IBCVw8KJFz+sQRGqRdK0odERsRzP3T+7tl25rU1Rk7WF7L//t0B8t3F3PQ8bi4UWlduW1SL6YNStCLnEpZQJO6OiWNzS3UN7WwKb+cJz7fyb7SGoqr6jHAtIEJ9EuIYtrABO0nV8pimtTVCZVU1fPckj28viqXyromABKiQhiXEUtUSCA/Hp9OaqxOqKWUt9CkrgDYerCCxTuKjlpWUdfIKytyqa5vYtrARIZ2j6ZLaCCXDk3SZ34q5aU0qXdy5bWNvLAkh6e/2k3Tkds5nUzsbePhSwboiBWlfIQm9U6qrrGZf365kxeX7aWmoZnLhybx6+n9iQj57pQQREetKOVjNKl3EnWNzWwvqGTLwQq2HKhg8c4icktquHRIErMm9WRgcherQ1RKuYBLkrqIzAZuAgYBbxpjbnLFdtWZaWxuoaquiX2lNazJPcwH3x5gQ15Z62RZEcEBZCZF8bvLBnJOnzhrg1VKuZSrWuoHgEeAqYA+ucBDGptb+HRzAXuKqtl/uIZv9h7mQFkt9U0tR71vQGIUPz03g8ykKAYkdiElJhQ/P7EoaqWUO7kkqRtj5gOISBaQ4optquNraTH8/YudbHV0o+SX1QIQExZIVlpXLhwQT0RwAOHBASRFhzAgsYsOOVSqE7GkT11EZgGzAFJTU60IwWe9ty6ff3yxk15x4fSMC+d3l2UysXccQQH6DHGllEVJ3RgzF5gLkJWVdew4OnVcFXWNPPrxNoalRvPubeO0C0UpdYyTNu9E5CsRMe38LPVEkMruH5/vpKS6nt9emqkJXSl1XCdtqRtjJnsgDnUSuworeWn5Xq7O6s7glGirw1FKeSlXDWkMcGzLH/AXkRCgyRjT5Irtd2aNzS2syT3MX/63nbAgf+5xw5NSlFIdh6v61B8EHnZ6fT3wW2COi7bfaT3+8TaeX7oHEXjsikHERrjnCeRKqY7BVUMa56AJ3C2W7y5heGo0z92QpQldKXVSOg7Oi1XXN7GtoILxGTZN6EqpU6JJ3YttyCunxcDw1BirQ1FK+QhN6l5s7b7DAAztrqNdlFKnRpO6F1u3r4yetnBiwoOsDkUp5SM0qXuh6vomNuSVsW7fYYZp14tS6jT47HzqH208SG5JzTHLDe3POmDOYEICc5IPidjv7PQTQQQEELG/NsYej/3f72I4suzI9o+sNwZKq+uZvzafynr7EP/R6V1PP2ilVKfls0n9P9n7WbS96ORv9DH+fsJFAxO4ZHAS0WGBZPXQlrpS6tT5bFJ/5kcjzqjlLSeYMkU4/sr2PtO21d3i1OpuMcbRapfW1vuRMlr/L9+9dn6vzuuilDpTPpvUgwP02ZlKKdWWXihVSqkORJO6Ukp1IHKy0R1uD0CkCMg9w4/bgGIXhuMq3hoXeG9sGtfp0bhOn7fGdqZx9TDGHPPkeMuT+tkQkWxjTJbVcbTlrXGB98amcZ0ejev0eWtsro5Lu1+UUqoD0aSulFIdiK8n9blWB9AOb40LvDc2jev0aFynz1tjc2lcPt2nrpRS6mi+3lJXSinlRJO6Ukp1IJrUlVKqA/HJpC4iXUXkPRGpFpFcEbnOojiCReQFRwyVIrJORKY51qWJiBGRKqefhzwY21ciUudU9nanddc5Yq4WkfdFxCPz+7bZF1Ui0iwi/3Ss8+j+EpHZIpItIvUi8lKbdeeLyDYRqRGRRSLSw2ldsIjME5EKESkQkbs9EZeIjBGRz0SkVESKROQ/IpLotH6OiDS22X89PRDXCY+bu/fXSWKb0SauGkesIxzr3bbPTpQbHOvdd47Z5/P2rR/gTeBtIAKYAJQDmRbEEQ7MAdKw/4L8HlDpeJ2GfcLGAIv20VfAzOMsz3TEOMmx/94A3rJo31UBkxyvPbq/gCuAy4F/AS85Lbc5zqcfAiHAn4GVTusfBZYAMUB/oAC4yANxTXPEFAWEAfOAT5zWzwFes2B/nfC4uXt/nSi247zvJmA33w0Qcds+O0lucOs55vYvj5t2VgPQx2nZq8BjVsfmiGUDcKUXJ/U/Am84ve7l2J+RHo7vRiDH6Qtmyf4CHmmTpGYBy51ehwO1QD/H63zgQqf1v8cNvxTbxnWc9cOBSqfXbk3qJ9hfJ0vqHtlfp7jPFgEPe3qfOZV3JDe49Rzzxe6XPkCzMWaH07JvsbdALSUi8djj2+y0OFdE8kTkRRGxeTikR0WkWESWichkx7JM7PsLAGPMbhy/JD0c243AK8Zx1jqxcn/BsfunGnvrLlNEYoAk5/VYd+5N4ujzDOASR/fMZhG53cPxHHPcvGl/Obo3JgGvtFnlkX3WJje49RzzxaQegf1PF2flQKQFsbQSkUDgdeBlY8w27BP0jAR6ACOwx/e6B0P6FdATSMZ+c8OHItILL9h/IpIKnAO87LTY6v11xIn2T4TT67brPEZEBgO/Ae5xWvxv7H+qxwG3AL8RkWs9EM6JjptX7C+HG4Alxpg9Tss8ss+Okxvceo75YlKvwt6v6CwKe3+VJUTED3sXUAMwG8AYU2WMyTbGNBljDjmWXygibWN3C2PMKmNMpTGm3hjzMrAMmI537L8bgKXOXzCr95eTE+2fKqfXbdd5hIhkAB8DdxpjlhxZbozZYow5YIxpNsYsB54AfuDueE5y3CzfX05u4OhGhEf22fFyA24+x3wxqe8AAkSkt9OyIRz7p6hHiIgALwDxwJXGmMZ23nqkm8GqZ9UZR9mbse8vezD2q/3B2PerpxzzBTsOq/ZX2/0Tjv26w2ZjzGHgoPN6PHjuOboQPgd+b4x59SRvP3K8Pa31uFm9v44QkfHYuzTeOclbXbrPTpAb3HuOeeoigYsvOLyFfQRMODAei0a/OGJ5BlgJRLRZPhroi/0XZyz20TqLPBRTNDAV+5X1AGAGUO2IJxOoACY69t9reHD0CzDOEUtkm+Ue3V+O/RKCfaTBq077Ks5xPl3pWPY4R49MeAz4GvvIhH6OL6ArR7+0F1cy9n7Xe9r53GWOmAQYhf1i240eiOuEx83d++tEsTmtn4v9+o2n91l7ucGt55hbvjDu/gG6Au87ksM+4DqL4uiB/bd7HfY/m478zACuBfY4YjyI/QJNgofiigO+wf4nW5njxLrAaf11jv1WDSwAunpwnz0LvHqc5R7dX9hHPpg2P3Mc66YA27CPSPgKSHP6XDD24YQVwCHgbk/EBTzs+L/zeVbl9Lk3gRLH8m3Azz0U1wmPm7v31ykcyxDHd+D843zObfvsRLnB3eeYTuillFIdiC/2qSullGqHJnWllOpANKkrpVQHokldKaU6EE3qSinVgWhSV0qpDkSTulJKdSCa1JVSqgP5/3o3nSiYN8poAAAAAElFTkSuQmCC\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    plt.subplot(2,1,1)\n",
    "    plt.plot(range(3000),X_train_[i])\n",
    "    plt.subplot(2,1,2)\n",
    "    plt.plot(X_norm[i])\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nreshape (Reshape)            (None, 3000, 1)           0         \n_________________________________________________________________\nmax_pooling1d (MaxPooling1D) (None, 200, 1)            0         \n_________________________________________________________________\nkeras_preprocess (KerasPrepr (None, None, None)        0         \n_________________________________________________________________\nreshape_1 (Reshape)          (None, 200, 1)            0         \n_________________________________________________________________\nconv1d (Conv1D)              (None, 200, 5)            105       \n_________________________________________________________________\nmax_pooling1d_1 (MaxPooling1 (None, 100, 5)            0         \n_________________________________________________________________\nflatten (Flatten)            (None, 500)               0         \n_________________________________________________________________\ndense (Dense)                (None, 1)                 501       \n=================================================================\nTotal params: 606\nTrainable params: 606\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "%run imports/VacuumGauge_functions.ipynb\n",
    "keras.backend.clear_session()\n",
    "from scipy.signal import medfilt, savgol_filter\n",
    "\n",
    "\n",
    "def build_CNN(layers=1, filters=32, kernel_size=10):\n",
    "    \n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.Reshape((3000, 1), input_shape=[3000]))\n",
    "    model.add(keras.layers.MaxPool1D(pool_size=15, strides=15, padding='same'))\n",
    "    # model.add(keras.layers.Lambda(lambda X: preprocess(X)))\n",
    "    model.add(KerasPreprocess())\n",
    "    model.add(keras.layers.Reshape(( 200, 1)))\n",
    "\n",
    "\n",
    "    for layer in range(layers):\n",
    "        model.add(keras.layers.Conv1D(filters=filters, kernel_size=kernel_size,\n",
    "                                      activation='relu', strides=1, input_shape = [None, 1],\n",
    "                                      padding='same', use_bias=True, kernel_initializer='he_normal',\n",
    "                                      ))\n",
    "        model.add(keras.layers.MaxPool1D(pool_size=2, padding='same'))\n",
    "\n",
    "    \n",
    "    model.add(keras.layers.Flatten())\n",
    "    model.add(keras.layers.Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "    # learning_rate = keras.optimizers.schedules.ExponentialDecay(initial_learning_rate=0.1,\n",
    "    #                                                             decay_steps= batch_size ,\n",
    "    #                                                             decay_rate=0.1)\n",
    "    optimizer = keras.optimizers.Nadam(learning_rate=1e-5)\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=keras.metrics.binary_accuracy)\n",
    "    return model\n",
    "\n",
    "model = build_CNN(layers=1, filters=5, kernel_size=20 )\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/400\n6/6 [==============================] - 0s 76ms/step - loss: 1.0705 - binary_accuracy: 0.4880 - val_loss: 0.9744 - val_binary_accuracy: 0.4911\nEpoch 2/400\n6/6 [==============================] - 0s 31ms/step - loss: 1.0640 - binary_accuracy: 0.4880 - val_loss: 0.9676 - val_binary_accuracy: 0.4911\nEpoch 3/400\n6/6 [==============================] - 0s 28ms/step - loss: 1.0567 - binary_accuracy: 0.4880 - val_loss: 0.9609 - val_binary_accuracy: 0.5000\nEpoch 4/400\n6/6 [==============================] - 0s 36ms/step - loss: 1.0494 - binary_accuracy: 0.4880 - val_loss: 0.9536 - val_binary_accuracy: 0.5000\nEpoch 5/400\n6/6 [==============================] - 0s 31ms/step - loss: 1.0417 - binary_accuracy: 0.4880 - val_loss: 0.9461 - val_binary_accuracy: 0.5000\nEpoch 6/400\n6/6 [==============================] - 0s 41ms/step - loss: 1.0338 - binary_accuracy: 0.4880 - val_loss: 0.9384 - val_binary_accuracy: 0.5000\nEpoch 7/400\n6/6 [==============================] - 0s 46ms/step - loss: 1.0258 - binary_accuracy: 0.4880 - val_loss: 0.9315 - val_binary_accuracy: 0.5000\nEpoch 8/400\n6/6 [==============================] - 0s 32ms/step - loss: 1.0183 - binary_accuracy: 0.4880 - val_loss: 0.9236 - val_binary_accuracy: 0.5089\nEpoch 9/400\n6/6 [==============================] - 0s 30ms/step - loss: 1.0101 - binary_accuracy: 0.4819 - val_loss: 0.9163 - val_binary_accuracy: 0.5089\nEpoch 10/400\n6/6 [==============================] - 0s 30ms/step - loss: 1.0025 - binary_accuracy: 0.4819 - val_loss: 0.9093 - val_binary_accuracy: 0.5089\nEpoch 11/400\n6/6 [==============================] - 0s 33ms/step - loss: 0.9951 - binary_accuracy: 0.4819 - val_loss: 0.9025 - val_binary_accuracy: 0.5089\nEpoch 12/400\n6/6 [==============================] - 0s 30ms/step - loss: 0.9879 - binary_accuracy: 0.4880 - val_loss: 0.8958 - val_binary_accuracy: 0.5089\nEpoch 13/400\n6/6 [==============================] - 0s 27ms/step - loss: 0.9809 - binary_accuracy: 0.4880 - val_loss: 0.8890 - val_binary_accuracy: 0.5089\nEpoch 14/400\n6/6 [==============================] - 0s 39ms/step - loss: 0.9736 - binary_accuracy: 0.4880 - val_loss: 0.8823 - val_binary_accuracy: 0.5089\nEpoch 15/400\n6/6 [==============================] - 0s 37ms/step - loss: 0.9664 - binary_accuracy: 0.4880 - val_loss: 0.8753 - val_binary_accuracy: 0.5089\nEpoch 16/400\n6/6 [==============================] - 0s 32ms/step - loss: 0.9590 - binary_accuracy: 0.4880 - val_loss: 0.8686 - val_binary_accuracy: 0.5089\nEpoch 17/400\n6/6 [==============================] - 0s 32ms/step - loss: 0.9519 - binary_accuracy: 0.4880 - val_loss: 0.8624 - val_binary_accuracy: 0.5089\nEpoch 18/400\n6/6 [==============================] - 0s 29ms/step - loss: 0.9453 - binary_accuracy: 0.4880 - val_loss: 0.8556 - val_binary_accuracy: 0.5089\nEpoch 19/400\n6/6 [==============================] - 0s 31ms/step - loss: 0.9381 - binary_accuracy: 0.4880 - val_loss: 0.8486 - val_binary_accuracy: 0.5089\nEpoch 20/400\n6/6 [==============================] - 0s 34ms/step - loss: 0.9307 - binary_accuracy: 0.4880 - val_loss: 0.8417 - val_binary_accuracy: 0.5089\nEpoch 21/400\n6/6 [==============================] - 0s 31ms/step - loss: 0.9234 - binary_accuracy: 0.4880 - val_loss: 0.8354 - val_binary_accuracy: 0.5089\nEpoch 22/400\n6/6 [==============================] - 0s 29ms/step - loss: 0.9168 - binary_accuracy: 0.4880 - val_loss: 0.8287 - val_binary_accuracy: 0.5089\nEpoch 23/400\n6/6 [==============================] - 0s 32ms/step - loss: 0.9096 - binary_accuracy: 0.4940 - val_loss: 0.8221 - val_binary_accuracy: 0.5089\nEpoch 24/400\n6/6 [==============================] - 0s 35ms/step - loss: 0.9027 - binary_accuracy: 0.4940 - val_loss: 0.8163 - val_binary_accuracy: 0.5089\nEpoch 25/400\n6/6 [==============================] - 0s 34ms/step - loss: 0.8965 - binary_accuracy: 0.4940 - val_loss: 0.8102 - val_binary_accuracy: 0.5089\nEpoch 26/400\n6/6 [==============================] - 0s 31ms/step - loss: 0.8900 - binary_accuracy: 0.4940 - val_loss: 0.8045 - val_binary_accuracy: 0.5089\nEpoch 27/400\n6/6 [==============================] - 0s 28ms/step - loss: 0.8839 - binary_accuracy: 0.4940 - val_loss: 0.7989 - val_binary_accuracy: 0.5089\nEpoch 28/400\n6/6 [==============================] - 0s 31ms/step - loss: 0.8779 - binary_accuracy: 0.4940 - val_loss: 0.7931 - val_binary_accuracy: 0.5089\nEpoch 29/400\n6/6 [==============================] - 0s 31ms/step - loss: 0.8716 - binary_accuracy: 0.4940 - val_loss: 0.7872 - val_binary_accuracy: 0.5179\nEpoch 30/400\n6/6 [==============================] - 0s 27ms/step - loss: 0.8652 - binary_accuracy: 0.4940 - val_loss: 0.7810 - val_binary_accuracy: 0.5179\nEpoch 31/400\n6/6 [==============================] - 0s 29ms/step - loss: 0.8586 - binary_accuracy: 0.5000 - val_loss: 0.7751 - val_binary_accuracy: 0.5179\nEpoch 32/400\n6/6 [==============================] - 0s 27ms/step - loss: 0.8523 - binary_accuracy: 0.5060 - val_loss: 0.7695 - val_binary_accuracy: 0.5179\nEpoch 33/400\n6/6 [==============================] - 0s 38ms/step - loss: 0.8463 - binary_accuracy: 0.5120 - val_loss: 0.7641 - val_binary_accuracy: 0.5089\nEpoch 34/400\n6/6 [==============================] - 0s 32ms/step - loss: 0.8404 - binary_accuracy: 0.5120 - val_loss: 0.7584 - val_binary_accuracy: 0.5089\nEpoch 35/400\n6/6 [==============================] - 0s 32ms/step - loss: 0.8343 - binary_accuracy: 0.5120 - val_loss: 0.7527 - val_binary_accuracy: 0.5179\nEpoch 36/400\n6/6 [==============================] - 0s 30ms/step - loss: 0.8282 - binary_accuracy: 0.5120 - val_loss: 0.7472 - val_binary_accuracy: 0.5268\nEpoch 37/400\n6/6 [==============================] - 0s 29ms/step - loss: 0.8223 - binary_accuracy: 0.5181 - val_loss: 0.7417 - val_binary_accuracy: 0.5268\nEpoch 38/400\n6/6 [==============================] - 0s 28ms/step - loss: 0.8163 - binary_accuracy: 0.5241 - val_loss: 0.7364 - val_binary_accuracy: 0.5268\nEpoch 39/400\n6/6 [==============================] - 0s 33ms/step - loss: 0.8106 - binary_accuracy: 0.5241 - val_loss: 0.7314 - val_binary_accuracy: 0.5357\nEpoch 40/400\n6/6 [==============================] - 0s 26ms/step - loss: 0.8052 - binary_accuracy: 0.5301 - val_loss: 0.7261 - val_binary_accuracy: 0.5446\nEpoch 41/400\n6/6 [==============================] - 0s 28ms/step - loss: 0.7995 - binary_accuracy: 0.5301 - val_loss: 0.7211 - val_binary_accuracy: 0.5446\nEpoch 42/400\n6/6 [==============================] - 0s 29ms/step - loss: 0.7941 - binary_accuracy: 0.5301 - val_loss: 0.7157 - val_binary_accuracy: 0.5446\nEpoch 43/400\n6/6 [==============================] - 0s 27ms/step - loss: 0.7882 - binary_accuracy: 0.5241 - val_loss: 0.7106 - val_binary_accuracy: 0.5536\nEpoch 44/400\n6/6 [==============================] - 0s 32ms/step - loss: 0.7827 - binary_accuracy: 0.5241 - val_loss: 0.7060 - val_binary_accuracy: 0.5536\nEpoch 45/400\n6/6 [==============================] - 0s 30ms/step - loss: 0.7777 - binary_accuracy: 0.5241 - val_loss: 0.7009 - val_binary_accuracy: 0.5625\nEpoch 46/400\n6/6 [==============================] - 0s 35ms/step - loss: 0.7721 - binary_accuracy: 0.5120 - val_loss: 0.6960 - val_binary_accuracy: 0.5625\nEpoch 47/400\n6/6 [==============================] - 0s 32ms/step - loss: 0.7668 - binary_accuracy: 0.5241 - val_loss: 0.6913 - val_binary_accuracy: 0.5714\nEpoch 48/400\n6/6 [==============================] - 0s 34ms/step - loss: 0.7616 - binary_accuracy: 0.5301 - val_loss: 0.6864 - val_binary_accuracy: 0.5714\nEpoch 49/400\n6/6 [==============================] - 0s 31ms/step - loss: 0.7565 - binary_accuracy: 0.5361 - val_loss: 0.6820 - val_binary_accuracy: 0.5804\nEpoch 50/400\n6/6 [==============================] - 0s 27ms/step - loss: 0.7516 - binary_accuracy: 0.5361 - val_loss: 0.6771 - val_binary_accuracy: 0.5893\nEpoch 51/400\n6/6 [==============================] - 0s 31ms/step - loss: 0.7462 - binary_accuracy: 0.5361 - val_loss: 0.6724 - val_binary_accuracy: 0.5893\nEpoch 52/400\n6/6 [==============================] - 0s 31ms/step - loss: 0.7410 - binary_accuracy: 0.5422 - val_loss: 0.6677 - val_binary_accuracy: 0.5893\nEpoch 53/400\n6/6 [==============================] - 0s 25ms/step - loss: 0.7360 - binary_accuracy: 0.5301 - val_loss: 0.6635 - val_binary_accuracy: 0.5893\nEpoch 54/400\n6/6 [==============================] - 0s 28ms/step - loss: 0.7313 - binary_accuracy: 0.5301 - val_loss: 0.6592 - val_binary_accuracy: 0.5804\nEpoch 55/400\n6/6 [==============================] - 0s 31ms/step - loss: 0.7266 - binary_accuracy: 0.5301 - val_loss: 0.6548 - val_binary_accuracy: 0.5893\nEpoch 56/400\n6/6 [==============================] - 0s 32ms/step - loss: 0.7216 - binary_accuracy: 0.5361 - val_loss: 0.6503 - val_binary_accuracy: 0.5893\nEpoch 57/400\n6/6 [==============================] - 0s 30ms/step - loss: 0.7167 - binary_accuracy: 0.5482 - val_loss: 0.6456 - val_binary_accuracy: 0.6071\nEpoch 58/400\n6/6 [==============================] - 0s 25ms/step - loss: 0.7115 - binary_accuracy: 0.5482 - val_loss: 0.6411 - val_binary_accuracy: 0.6071\nEpoch 59/400\n6/6 [==============================] - 0s 28ms/step - loss: 0.7067 - binary_accuracy: 0.5482 - val_loss: 0.6368 - val_binary_accuracy: 0.6071\nEpoch 60/400\n6/6 [==============================] - 0s 29ms/step - loss: 0.7020 - binary_accuracy: 0.5482 - val_loss: 0.6325 - val_binary_accuracy: 0.6161\nEpoch 61/400\n6/6 [==============================] - 0s 38ms/step - loss: 0.6972 - binary_accuracy: 0.5482 - val_loss: 0.6284 - val_binary_accuracy: 0.6250\nEpoch 62/400\n6/6 [==============================] - 0s 33ms/step - loss: 0.6927 - binary_accuracy: 0.5482 - val_loss: 0.6243 - val_binary_accuracy: 0.6339\nEpoch 63/400\n6/6 [==============================] - 0s 31ms/step - loss: 0.6882 - binary_accuracy: 0.5482 - val_loss: 0.6203 - val_binary_accuracy: 0.6339\nEpoch 64/400\n6/6 [==============================] - 0s 31ms/step - loss: 0.6838 - binary_accuracy: 0.5482 - val_loss: 0.6161 - val_binary_accuracy: 0.6339\nEpoch 65/400\n6/6 [==============================] - 0s 32ms/step - loss: 0.6791 - binary_accuracy: 0.5542 - val_loss: 0.6120 - val_binary_accuracy: 0.6429\nEpoch 66/400\n6/6 [==============================] - 0s 32ms/step - loss: 0.6746 - binary_accuracy: 0.5602 - val_loss: 0.6078 - val_binary_accuracy: 0.6429\nEpoch 67/400\n6/6 [==============================] - 0s 28ms/step - loss: 0.6701 - binary_accuracy: 0.5663 - val_loss: 0.6038 - val_binary_accuracy: 0.6339\nEpoch 68/400\n6/6 [==============================] - 0s 29ms/step - loss: 0.6656 - binary_accuracy: 0.5663 - val_loss: 0.6000 - val_binary_accuracy: 0.6339\nEpoch 69/400\n6/6 [==============================] - 0s 27ms/step - loss: 0.6613 - binary_accuracy: 0.5663 - val_loss: 0.5960 - val_binary_accuracy: 0.6339\nEpoch 70/400\n6/6 [==============================] - 0s 33ms/step - loss: 0.6570 - binary_accuracy: 0.5663 - val_loss: 0.5920 - val_binary_accuracy: 0.6429\nEpoch 71/400\n6/6 [==============================] - 0s 27ms/step - loss: 0.6525 - binary_accuracy: 0.5723 - val_loss: 0.5879 - val_binary_accuracy: 0.6518\nEpoch 72/400\n6/6 [==============================] - 0s 28ms/step - loss: 0.6481 - binary_accuracy: 0.5723 - val_loss: 0.5841 - val_binary_accuracy: 0.6518\nEpoch 73/400\n6/6 [==============================] - 0s 32ms/step - loss: 0.6438 - binary_accuracy: 0.5723 - val_loss: 0.5804 - val_binary_accuracy: 0.6607\nEpoch 74/400\n6/6 [==============================] - 0s 25ms/step - loss: 0.6396 - binary_accuracy: 0.5783 - val_loss: 0.5765 - val_binary_accuracy: 0.6607\nEpoch 75/400\n6/6 [==============================] - 0s 30ms/step - loss: 0.6353 - binary_accuracy: 0.5843 - val_loss: 0.5727 - val_binary_accuracy: 0.6607\nEpoch 76/400\n6/6 [==============================] - 0s 31ms/step - loss: 0.6312 - binary_accuracy: 0.5723 - val_loss: 0.5689 - val_binary_accuracy: 0.6607\nEpoch 77/400\n6/6 [==============================] - 0s 37ms/step - loss: 0.6268 - binary_accuracy: 0.5783 - val_loss: 0.5651 - val_binary_accuracy: 0.6696\nEpoch 78/400\n6/6 [==============================] - 0s 29ms/step - loss: 0.6227 - binary_accuracy: 0.5783 - val_loss: 0.5615 - val_binary_accuracy: 0.6696\nEpoch 79/400\n6/6 [==============================] - 0s 34ms/step - loss: 0.6187 - binary_accuracy: 0.5783 - val_loss: 0.5581 - val_binary_accuracy: 0.6696\nEpoch 80/400\n6/6 [==============================] - 0s 32ms/step - loss: 0.6149 - binary_accuracy: 0.5964 - val_loss: 0.5546 - val_binary_accuracy: 0.6786\nEpoch 81/400\n6/6 [==============================] - 0s 29ms/step - loss: 0.6110 - binary_accuracy: 0.6024 - val_loss: 0.5512 - val_binary_accuracy: 0.6786\nEpoch 82/400\n6/6 [==============================] - 0s 27ms/step - loss: 0.6072 - binary_accuracy: 0.6084 - val_loss: 0.5480 - val_binary_accuracy: 0.6786\nEpoch 83/400\n6/6 [==============================] - 0s 28ms/step - loss: 0.6035 - binary_accuracy: 0.6145 - val_loss: 0.5445 - val_binary_accuracy: 0.6696\nEpoch 84/400\n6/6 [==============================] - 0s 25ms/step - loss: 0.5997 - binary_accuracy: 0.6145 - val_loss: 0.5414 - val_binary_accuracy: 0.6786\nEpoch 85/400\n6/6 [==============================] - 0s 27ms/step - loss: 0.5961 - binary_accuracy: 0.6145 - val_loss: 0.5380 - val_binary_accuracy: 0.6964\nEpoch 86/400\n6/6 [==============================] - 0s 31ms/step - loss: 0.5923 - binary_accuracy: 0.6084 - val_loss: 0.5346 - val_binary_accuracy: 0.6964\nEpoch 87/400\n6/6 [==============================] - 0s 30ms/step - loss: 0.5887 - binary_accuracy: 0.6024 - val_loss: 0.5318 - val_binary_accuracy: 0.6964\nEpoch 88/400\n6/6 [==============================] - 0s 29ms/step - loss: 0.5853 - binary_accuracy: 0.6024 - val_loss: 0.5291 - val_binary_accuracy: 0.7054\nEpoch 89/400\n6/6 [==============================] - 0s 31ms/step - loss: 0.5823 - binary_accuracy: 0.6024 - val_loss: 0.5263 - val_binary_accuracy: 0.7054\nEpoch 90/400\n6/6 [==============================] - 0s 25ms/step - loss: 0.5791 - binary_accuracy: 0.6084 - val_loss: 0.5236 - val_binary_accuracy: 0.7054\nEpoch 91/400\n6/6 [==============================] - 0s 25ms/step - loss: 0.5759 - binary_accuracy: 0.6145 - val_loss: 0.5206 - val_binary_accuracy: 0.7054\nEpoch 92/400\n6/6 [==============================] - 0s 27ms/step - loss: 0.5724 - binary_accuracy: 0.6205 - val_loss: 0.5175 - val_binary_accuracy: 0.6964\nEpoch 93/400\n6/6 [==============================] - 0s 25ms/step - loss: 0.5689 - binary_accuracy: 0.6205 - val_loss: 0.5144 - val_binary_accuracy: 0.6964\nEpoch 94/400\n6/6 [==============================] - 0s 26ms/step - loss: 0.5655 - binary_accuracy: 0.6205 - val_loss: 0.5115 - val_binary_accuracy: 0.6964\nEpoch 95/400\n6/6 [==============================] - 0s 28ms/step - loss: 0.5622 - binary_accuracy: 0.6386 - val_loss: 0.5086 - val_binary_accuracy: 0.6964\nEpoch 96/400\n6/6 [==============================] - 0s 29ms/step - loss: 0.5589 - binary_accuracy: 0.6506 - val_loss: 0.5058 - val_binary_accuracy: 0.6964\nEpoch 97/400\n6/6 [==============================] - 0s 33ms/step - loss: 0.5557 - binary_accuracy: 0.6566 - val_loss: 0.5032 - val_binary_accuracy: 0.6964\nEpoch 98/400\n6/6 [==============================] - 0s 26ms/step - loss: 0.5526 - binary_accuracy: 0.6566 - val_loss: 0.5005 - val_binary_accuracy: 0.7054\nEpoch 99/400\n6/6 [==============================] - 0s 30ms/step - loss: 0.5496 - binary_accuracy: 0.6627 - val_loss: 0.4980 - val_binary_accuracy: 0.7232\nEpoch 100/400\n6/6 [==============================] - 0s 29ms/step - loss: 0.5466 - binary_accuracy: 0.6687 - val_loss: 0.4954 - val_binary_accuracy: 0.7321\nEpoch 101/400\n6/6 [==============================] - 0s 23ms/step - loss: 0.5437 - binary_accuracy: 0.6687 - val_loss: 0.4927 - val_binary_accuracy: 0.7321\nEpoch 102/400\n6/6 [==============================] - 0s 25ms/step - loss: 0.5406 - binary_accuracy: 0.6687 - val_loss: 0.4899 - val_binary_accuracy: 0.7411\nEpoch 103/400\n6/6 [==============================] - 0s 25ms/step - loss: 0.5375 - binary_accuracy: 0.6747 - val_loss: 0.4872 - val_binary_accuracy: 0.7411\nEpoch 104/400\n6/6 [==============================] - 0s 27ms/step - loss: 0.5343 - binary_accuracy: 0.6747 - val_loss: 0.4845 - val_binary_accuracy: 0.7411\nEpoch 105/400\n6/6 [==============================] - 0s 27ms/step - loss: 0.5312 - binary_accuracy: 0.6747 - val_loss: 0.4817 - val_binary_accuracy: 0.7411\nEpoch 106/400\n6/6 [==============================] - 0s 26ms/step - loss: 0.5280 - binary_accuracy: 0.6747 - val_loss: 0.4791 - val_binary_accuracy: 0.7411\nEpoch 107/400\n6/6 [==============================] - 0s 25ms/step - loss: 0.5250 - binary_accuracy: 0.6867 - val_loss: 0.4765 - val_binary_accuracy: 0.7411\nEpoch 108/400\n6/6 [==============================] - 0s 29ms/step - loss: 0.5221 - binary_accuracy: 0.6867 - val_loss: 0.4739 - val_binary_accuracy: 0.7500\nEpoch 109/400\n6/6 [==============================] - 0s 29ms/step - loss: 0.5191 - binary_accuracy: 0.6928 - val_loss: 0.4713 - val_binary_accuracy: 0.7500\nEpoch 110/400\n6/6 [==============================] - 0s 26ms/step - loss: 0.5161 - binary_accuracy: 0.6928 - val_loss: 0.4687 - val_binary_accuracy: 0.7500\nEpoch 111/400\n6/6 [==============================] - 0s 32ms/step - loss: 0.5132 - binary_accuracy: 0.6988 - val_loss: 0.4663 - val_binary_accuracy: 0.7589\nEpoch 112/400\n6/6 [==============================] - 0s 29ms/step - loss: 0.5104 - binary_accuracy: 0.6988 - val_loss: 0.4640 - val_binary_accuracy: 0.7589\nEpoch 113/400\n6/6 [==============================] - 0s 32ms/step - loss: 0.5078 - binary_accuracy: 0.6988 - val_loss: 0.4616 - val_binary_accuracy: 0.7679\nEpoch 114/400\n6/6 [==============================] - 0s 29ms/step - loss: 0.5051 - binary_accuracy: 0.6988 - val_loss: 0.4593 - val_binary_accuracy: 0.7679\nEpoch 115/400\n6/6 [==============================] - 0s 32ms/step - loss: 0.5023 - binary_accuracy: 0.6988 - val_loss: 0.4571 - val_binary_accuracy: 0.7679\nEpoch 116/400\n6/6 [==============================] - 0s 28ms/step - loss: 0.4997 - binary_accuracy: 0.6988 - val_loss: 0.4548 - val_binary_accuracy: 0.7679\nEpoch 117/400\n6/6 [==============================] - 0s 31ms/step - loss: 0.4971 - binary_accuracy: 0.7048 - val_loss: 0.4526 - val_binary_accuracy: 0.7679\nEpoch 118/400\n6/6 [==============================] - 0s 30ms/step - loss: 0.4945 - binary_accuracy: 0.7108 - val_loss: 0.4504 - val_binary_accuracy: 0.7679\nEpoch 119/400\n6/6 [==============================] - 0s 24ms/step - loss: 0.4918 - binary_accuracy: 0.7108 - val_loss: 0.4482 - val_binary_accuracy: 0.7679\nEpoch 120/400\n6/6 [==============================] - 0s 24ms/step - loss: 0.4894 - binary_accuracy: 0.7108 - val_loss: 0.4462 - val_binary_accuracy: 0.7679\nEpoch 121/400\n6/6 [==============================] - 0s 25ms/step - loss: 0.4870 - binary_accuracy: 0.7108 - val_loss: 0.4442 - val_binary_accuracy: 0.7679\nEpoch 122/400\n6/6 [==============================] - 0s 25ms/step - loss: 0.4846 - binary_accuracy: 0.7108 - val_loss: 0.4421 - val_binary_accuracy: 0.7679\nEpoch 123/400\n6/6 [==============================] - 0s 24ms/step - loss: 0.4822 - binary_accuracy: 0.7108 - val_loss: 0.4400 - val_binary_accuracy: 0.7679\nEpoch 124/400\n6/6 [==============================] - 0s 23ms/step - loss: 0.4798 - binary_accuracy: 0.7108 - val_loss: 0.4378 - val_binary_accuracy: 0.7768\nEpoch 125/400\n6/6 [==============================] - 0s 27ms/step - loss: 0.4772 - binary_accuracy: 0.7108 - val_loss: 0.4358 - val_binary_accuracy: 0.7768\nEpoch 126/400\n6/6 [==============================] - 0s 29ms/step - loss: 0.4749 - binary_accuracy: 0.7289 - val_loss: 0.4339 - val_binary_accuracy: 0.7768\nEpoch 127/400\n6/6 [==============================] - 0s 27ms/step - loss: 0.4727 - binary_accuracy: 0.7349 - val_loss: 0.4318 - val_binary_accuracy: 0.7768\nEpoch 128/400\n6/6 [==============================] - 0s 25ms/step - loss: 0.4703 - binary_accuracy: 0.7410 - val_loss: 0.4299 - val_binary_accuracy: 0.7768\nEpoch 129/400\n6/6 [==============================] - 0s 25ms/step - loss: 0.4681 - binary_accuracy: 0.7470 - val_loss: 0.4281 - val_binary_accuracy: 0.7768\nEpoch 130/400\n6/6 [==============================] - 0s 28ms/step - loss: 0.4658 - binary_accuracy: 0.7470 - val_loss: 0.4262 - val_binary_accuracy: 0.7768\nEpoch 131/400\n6/6 [==============================] - 0s 24ms/step - loss: 0.4637 - binary_accuracy: 0.7530 - val_loss: 0.4244 - val_binary_accuracy: 0.7768\nEpoch 132/400\n6/6 [==============================] - 0s 26ms/step - loss: 0.4615 - binary_accuracy: 0.7530 - val_loss: 0.4226 - val_binary_accuracy: 0.7768\nEpoch 133/400\n6/6 [==============================] - 0s 23ms/step - loss: 0.4593 - binary_accuracy: 0.7530 - val_loss: 0.4208 - val_binary_accuracy: 0.7768\nEpoch 134/400\n6/6 [==============================] - 0s 27ms/step - loss: 0.4572 - binary_accuracy: 0.7590 - val_loss: 0.4190 - val_binary_accuracy: 0.7768\nEpoch 135/400\n6/6 [==============================] - 0s 25ms/step - loss: 0.4551 - binary_accuracy: 0.7590 - val_loss: 0.4171 - val_binary_accuracy: 0.7768\nEpoch 136/400\n6/6 [==============================] - 0s 25ms/step - loss: 0.4528 - binary_accuracy: 0.7590 - val_loss: 0.4153 - val_binary_accuracy: 0.7768\nEpoch 137/400\n6/6 [==============================] - 0s 29ms/step - loss: 0.4507 - binary_accuracy: 0.7711 - val_loss: 0.4135 - val_binary_accuracy: 0.7946\nEpoch 138/400\n6/6 [==============================] - 0s 28ms/step - loss: 0.4485 - binary_accuracy: 0.7711 - val_loss: 0.4116 - val_binary_accuracy: 0.7946\nEpoch 139/400\n6/6 [==============================] - 0s 26ms/step - loss: 0.4464 - binary_accuracy: 0.7711 - val_loss: 0.4098 - val_binary_accuracy: 0.7946\nEpoch 140/400\n6/6 [==============================] - 0s 24ms/step - loss: 0.4442 - binary_accuracy: 0.7831 - val_loss: 0.4081 - val_binary_accuracy: 0.7946\nEpoch 141/400\n6/6 [==============================] - 0s 26ms/step - loss: 0.4422 - binary_accuracy: 0.7831 - val_loss: 0.4065 - val_binary_accuracy: 0.7946\nEpoch 142/400\n6/6 [==============================] - 0s 26ms/step - loss: 0.4402 - binary_accuracy: 0.7892 - val_loss: 0.4047 - val_binary_accuracy: 0.7946\nEpoch 143/400\n6/6 [==============================] - 0s 27ms/step - loss: 0.4380 - binary_accuracy: 0.7892 - val_loss: 0.4029 - val_binary_accuracy: 0.8036\nEpoch 144/400\n6/6 [==============================] - 0s 24ms/step - loss: 0.4359 - binary_accuracy: 0.8012 - val_loss: 0.4011 - val_binary_accuracy: 0.8125\nEpoch 145/400\n6/6 [==============================] - 0s 24ms/step - loss: 0.4339 - binary_accuracy: 0.8012 - val_loss: 0.3994 - val_binary_accuracy: 0.8125\nEpoch 146/400\n6/6 [==============================] - 0s 26ms/step - loss: 0.4319 - binary_accuracy: 0.8012 - val_loss: 0.3977 - val_binary_accuracy: 0.8125\nEpoch 147/400\n6/6 [==============================] - 0s 23ms/step - loss: 0.4299 - binary_accuracy: 0.8012 - val_loss: 0.3961 - val_binary_accuracy: 0.8125\nEpoch 148/400\n6/6 [==============================] - 0s 29ms/step - loss: 0.4280 - binary_accuracy: 0.8012 - val_loss: 0.3945 - val_binary_accuracy: 0.8125\nEpoch 149/400\n6/6 [==============================] - 0s 26ms/step - loss: 0.4261 - binary_accuracy: 0.8012 - val_loss: 0.3929 - val_binary_accuracy: 0.8125\nEpoch 150/400\n6/6 [==============================] - 0s 27ms/step - loss: 0.4241 - binary_accuracy: 0.7952 - val_loss: 0.3913 - val_binary_accuracy: 0.8125\nEpoch 151/400\n6/6 [==============================] - 0s 26ms/step - loss: 0.4223 - binary_accuracy: 0.7952 - val_loss: 0.3898 - val_binary_accuracy: 0.8125\nEpoch 152/400\n6/6 [==============================] - 0s 25ms/step - loss: 0.4204 - binary_accuracy: 0.7952 - val_loss: 0.3884 - val_binary_accuracy: 0.8125\nEpoch 153/400\n6/6 [==============================] - 0s 24ms/step - loss: 0.4187 - binary_accuracy: 0.7952 - val_loss: 0.3869 - val_binary_accuracy: 0.8125\nEpoch 154/400\n6/6 [==============================] - 0s 26ms/step - loss: 0.4168 - binary_accuracy: 0.7952 - val_loss: 0.3854 - val_binary_accuracy: 0.8125\nEpoch 155/400\n6/6 [==============================] - 0s 25ms/step - loss: 0.4151 - binary_accuracy: 0.7952 - val_loss: 0.3840 - val_binary_accuracy: 0.8125\nEpoch 156/400\n6/6 [==============================] - 0s 37ms/step - loss: 0.4133 - binary_accuracy: 0.7952 - val_loss: 0.3825 - val_binary_accuracy: 0.8125\nEpoch 157/400\n6/6 [==============================] - 0s 29ms/step - loss: 0.4115 - binary_accuracy: 0.7952 - val_loss: 0.3810 - val_binary_accuracy: 0.8125\nEpoch 158/400\n6/6 [==============================] - 0s 28ms/step - loss: 0.4097 - binary_accuracy: 0.7952 - val_loss: 0.3795 - val_binary_accuracy: 0.8125\nEpoch 159/400\n6/6 [==============================] - 0s 27ms/step - loss: 0.4079 - binary_accuracy: 0.7952 - val_loss: 0.3780 - val_binary_accuracy: 0.8125\nEpoch 160/400\n6/6 [==============================] - 0s 26ms/step - loss: 0.4061 - binary_accuracy: 0.8012 - val_loss: 0.3767 - val_binary_accuracy: 0.8125\nEpoch 161/400\n6/6 [==============================] - 0s 24ms/step - loss: 0.4044 - binary_accuracy: 0.8012 - val_loss: 0.3754 - val_binary_accuracy: 0.8125\nEpoch 162/400\n6/6 [==============================] - 0s 27ms/step - loss: 0.4028 - binary_accuracy: 0.8072 - val_loss: 0.3741 - val_binary_accuracy: 0.8125\nEpoch 163/400\n6/6 [==============================] - 0s 29ms/step - loss: 0.4011 - binary_accuracy: 0.8072 - val_loss: 0.3727 - val_binary_accuracy: 0.8125\nEpoch 164/400\n6/6 [==============================] - 0s 26ms/step - loss: 0.3995 - binary_accuracy: 0.8133 - val_loss: 0.3714 - val_binary_accuracy: 0.8214\nEpoch 165/400\n6/6 [==============================] - 0s 30ms/step - loss: 0.3979 - binary_accuracy: 0.8133 - val_loss: 0.3702 - val_binary_accuracy: 0.8214\nEpoch 166/400\n6/6 [==============================] - 0s 27ms/step - loss: 0.3963 - binary_accuracy: 0.8193 - val_loss: 0.3689 - val_binary_accuracy: 0.8214\nEpoch 167/400\n6/6 [==============================] - 0s 30ms/step - loss: 0.3947 - binary_accuracy: 0.8193 - val_loss: 0.3676 - val_binary_accuracy: 0.8214\nEpoch 168/400\n6/6 [==============================] - 0s 29ms/step - loss: 0.3931 - binary_accuracy: 0.8253 - val_loss: 0.3664 - val_binary_accuracy: 0.8214\nEpoch 169/400\n6/6 [==============================] - 0s 30ms/step - loss: 0.3915 - binary_accuracy: 0.8313 - val_loss: 0.3651 - val_binary_accuracy: 0.8304\nEpoch 170/400\n6/6 [==============================] - 0s 32ms/step - loss: 0.3900 - binary_accuracy: 0.8313 - val_loss: 0.3639 - val_binary_accuracy: 0.8304\nEpoch 171/400\n6/6 [==============================] - 0s 32ms/step - loss: 0.3885 - binary_accuracy: 0.8373 - val_loss: 0.3627 - val_binary_accuracy: 0.8304\nEpoch 172/400\n6/6 [==============================] - 0s 33ms/step - loss: 0.3870 - binary_accuracy: 0.8434 - val_loss: 0.3616 - val_binary_accuracy: 0.8304\nEpoch 173/400\n6/6 [==============================] - 0s 31ms/step - loss: 0.3855 - binary_accuracy: 0.8434 - val_loss: 0.3603 - val_binary_accuracy: 0.8304\nEpoch 174/400\n6/6 [==============================] - 0s 29ms/step - loss: 0.3841 - binary_accuracy: 0.8494 - val_loss: 0.3592 - val_binary_accuracy: 0.8304\nEpoch 175/400\n6/6 [==============================] - 0s 33ms/step - loss: 0.3826 - binary_accuracy: 0.8494 - val_loss: 0.3581 - val_binary_accuracy: 0.8304\nEpoch 176/400\n6/6 [==============================] - 0s 40ms/step - loss: 0.3812 - binary_accuracy: 0.8554 - val_loss: 0.3569 - val_binary_accuracy: 0.8304\nEpoch 177/400\n6/6 [==============================] - 0s 27ms/step - loss: 0.3797 - binary_accuracy: 0.8554 - val_loss: 0.3557 - val_binary_accuracy: 0.8304\nEpoch 178/400\n6/6 [==============================] - 0s 29ms/step - loss: 0.3782 - binary_accuracy: 0.8614 - val_loss: 0.3545 - val_binary_accuracy: 0.8304\nEpoch 179/400\n6/6 [==============================] - 0s 31ms/step - loss: 0.3767 - binary_accuracy: 0.8614 - val_loss: 0.3533 - val_binary_accuracy: 0.8304\nEpoch 180/400\n6/6 [==============================] - 0s 35ms/step - loss: 0.3752 - binary_accuracy: 0.8675 - val_loss: 0.3522 - val_binary_accuracy: 0.8304\nEpoch 181/400\n6/6 [==============================] - 0s 31ms/step - loss: 0.3738 - binary_accuracy: 0.8675 - val_loss: 0.3511 - val_binary_accuracy: 0.8304\nEpoch 182/400\n6/6 [==============================] - 0s 28ms/step - loss: 0.3724 - binary_accuracy: 0.8675 - val_loss: 0.3499 - val_binary_accuracy: 0.8304\nEpoch 183/400\n6/6 [==============================] - 0s 29ms/step - loss: 0.3709 - binary_accuracy: 0.8675 - val_loss: 0.3487 - val_binary_accuracy: 0.8304\nEpoch 184/400\n6/6 [==============================] - 0s 27ms/step - loss: 0.3694 - binary_accuracy: 0.8675 - val_loss: 0.3476 - val_binary_accuracy: 0.8304\nEpoch 185/400\n6/6 [==============================] - 0s 26ms/step - loss: 0.3680 - binary_accuracy: 0.8675 - val_loss: 0.3464 - val_binary_accuracy: 0.8304\nEpoch 186/400\n6/6 [==============================] - 0s 29ms/step - loss: 0.3666 - binary_accuracy: 0.8675 - val_loss: 0.3454 - val_binary_accuracy: 0.8304\nEpoch 187/400\n6/6 [==============================] - 0s 31ms/step - loss: 0.3653 - binary_accuracy: 0.8675 - val_loss: 0.3444 - val_binary_accuracy: 0.8304\nEpoch 188/400\n6/6 [==============================] - 0s 29ms/step - loss: 0.3640 - binary_accuracy: 0.8675 - val_loss: 0.3433 - val_binary_accuracy: 0.8304\nEpoch 189/400\n6/6 [==============================] - 0s 31ms/step - loss: 0.3627 - binary_accuracy: 0.8675 - val_loss: 0.3423 - val_binary_accuracy: 0.8304\nEpoch 190/400\n6/6 [==============================] - 0s 27ms/step - loss: 0.3615 - binary_accuracy: 0.8675 - val_loss: 0.3412 - val_binary_accuracy: 0.8393\nEpoch 191/400\n6/6 [==============================] - 0s 32ms/step - loss: 0.3600 - binary_accuracy: 0.8675 - val_loss: 0.3402 - val_binary_accuracy: 0.8393\nEpoch 192/400\n6/6 [==============================] - 0s 31ms/step - loss: 0.3588 - binary_accuracy: 0.8675 - val_loss: 0.3392 - val_binary_accuracy: 0.8393\nEpoch 193/400\n6/6 [==============================] - 0s 28ms/step - loss: 0.3575 - binary_accuracy: 0.8675 - val_loss: 0.3383 - val_binary_accuracy: 0.8393\nEpoch 194/400\n6/6 [==============================] - 0s 35ms/step - loss: 0.3563 - binary_accuracy: 0.8675 - val_loss: 0.3373 - val_binary_accuracy: 0.8393\nEpoch 195/400\n6/6 [==============================] - 0s 34ms/step - loss: 0.3550 - binary_accuracy: 0.8675 - val_loss: 0.3364 - val_binary_accuracy: 0.8393\nEpoch 196/400\n6/6 [==============================] - 0s 29ms/step - loss: 0.3538 - binary_accuracy: 0.8675 - val_loss: 0.3355 - val_binary_accuracy: 0.8393\nEpoch 197/400\n6/6 [==============================] - 0s 31ms/step - loss: 0.3526 - binary_accuracy: 0.8735 - val_loss: 0.3346 - val_binary_accuracy: 0.8393\nEpoch 198/400\n6/6 [==============================] - 0s 29ms/step - loss: 0.3514 - binary_accuracy: 0.8735 - val_loss: 0.3336 - val_binary_accuracy: 0.8482\nEpoch 199/400\n6/6 [==============================] - 0s 32ms/step - loss: 0.3502 - binary_accuracy: 0.8735 - val_loss: 0.3327 - val_binary_accuracy: 0.8571\nEpoch 200/400\n6/6 [==============================] - 0s 36ms/step - loss: 0.3490 - binary_accuracy: 0.8735 - val_loss: 0.3319 - val_binary_accuracy: 0.8571\nEpoch 201/400\n6/6 [==============================] - 0s 31ms/step - loss: 0.3478 - binary_accuracy: 0.8735 - val_loss: 0.3309 - val_binary_accuracy: 0.8571\nEpoch 202/400\n6/6 [==============================] - 0s 29ms/step - loss: 0.3466 - binary_accuracy: 0.8795 - val_loss: 0.3300 - val_binary_accuracy: 0.8571\nEpoch 203/400\n6/6 [==============================] - 0s 36ms/step - loss: 0.3454 - binary_accuracy: 0.8795 - val_loss: 0.3291 - val_binary_accuracy: 0.8571\nEpoch 204/400\n6/6 [==============================] - 0s 32ms/step - loss: 0.3442 - binary_accuracy: 0.8795 - val_loss: 0.3282 - val_binary_accuracy: 0.8571\nEpoch 205/400\n6/6 [==============================] - 0s 34ms/step - loss: 0.3431 - binary_accuracy: 0.8795 - val_loss: 0.3274 - val_binary_accuracy: 0.8571\nEpoch 206/400\n6/6 [==============================] - 0s 30ms/step - loss: 0.3419 - binary_accuracy: 0.8795 - val_loss: 0.3265 - val_binary_accuracy: 0.8571\nEpoch 207/400\n6/6 [==============================] - 0s 32ms/step - loss: 0.3408 - binary_accuracy: 0.8855 - val_loss: 0.3256 - val_binary_accuracy: 0.8661\nEpoch 208/400\n6/6 [==============================] - 0s 33ms/step - loss: 0.3396 - binary_accuracy: 0.8855 - val_loss: 0.3247 - val_binary_accuracy: 0.8750\nEpoch 209/400\n6/6 [==============================] - 0s 31ms/step - loss: 0.3385 - binary_accuracy: 0.8855 - val_loss: 0.3238 - val_binary_accuracy: 0.8750\nEpoch 210/400\n6/6 [==============================] - 0s 27ms/step - loss: 0.3373 - binary_accuracy: 0.8855 - val_loss: 0.3228 - val_binary_accuracy: 0.8750\nEpoch 211/400\n6/6 [==============================] - 0s 32ms/step - loss: 0.3361 - binary_accuracy: 0.8855 - val_loss: 0.3219 - val_binary_accuracy: 0.8750\nEpoch 212/400\n6/6 [==============================] - 0s 41ms/step - loss: 0.3350 - binary_accuracy: 0.8916 - val_loss: 0.3210 - val_binary_accuracy: 0.8750\nEpoch 213/400\n6/6 [==============================] - 0s 32ms/step - loss: 0.3339 - binary_accuracy: 0.8916 - val_loss: 0.3201 - val_binary_accuracy: 0.8750\nEpoch 214/400\n4/6 [===================>..........] - ETA: 0s - loss: 0.3361 - binary_accuracy: 0.8906/6 [==============================] - 0s 29ms/step - loss: 0.3328 - binary_accuracy: 0.8916 - val_loss: 0.3194 - val_binary_accuracy: 0.8750\nEpoch 215/400\n6/6 [==============================] - 0s 26ms/step - loss: 0.3318 - binary_accuracy: 0.8916 - val_loss: 0.3186 - val_binary_accuracy: 0.8839\nEpoch 216/400\n6/6 [==============================] - 0s 30ms/step - loss: 0.3307 - binary_accuracy: 0.8916 - val_loss: 0.3178 - val_binary_accuracy: 0.8839\nEpoch 217/400\n6/6 [==============================] - 0s 30ms/step - loss: 0.3297 - binary_accuracy: 0.8916 - val_loss: 0.3170 - val_binary_accuracy: 0.8839\nEpoch 218/400\n6/6 [==============================] - 0s 29ms/step - loss: 0.3287 - binary_accuracy: 0.8916 - val_loss: 0.3162 - val_binary_accuracy: 0.8839\nEpoch 219/400\n6/6 [==============================] - 0s 34ms/step - loss: 0.3276 - binary_accuracy: 0.8976 - val_loss: 0.3154 - val_binary_accuracy: 0.8839\nEpoch 220/400\n6/6 [==============================] - 0s 32ms/step - loss: 0.3265 - binary_accuracy: 0.8976 - val_loss: 0.3147 - val_binary_accuracy: 0.8839\nEpoch 221/400\n6/6 [==============================] - 0s 34ms/step - loss: 0.3255 - binary_accuracy: 0.8976 - val_loss: 0.3139 - val_binary_accuracy: 0.8839\nEpoch 222/400\n6/6 [==============================] - 0s 35ms/step - loss: 0.3245 - binary_accuracy: 0.8976 - val_loss: 0.3131 - val_binary_accuracy: 0.8839\nEpoch 223/400\n6/6 [==============================] - 0s 31ms/step - loss: 0.3234 - binary_accuracy: 0.8976 - val_loss: 0.3123 - val_binary_accuracy: 0.8839\nEpoch 224/400\n6/6 [==============================] - 0s 34ms/step - loss: 0.3224 - binary_accuracy: 0.8976 - val_loss: 0.3116 - val_binary_accuracy: 0.8839\nEpoch 225/400\n6/6 [==============================] - 0s 31ms/step - loss: 0.3214 - binary_accuracy: 0.9036 - val_loss: 0.3108 - val_binary_accuracy: 0.8839\nEpoch 226/400\n6/6 [==============================] - 0s 32ms/step - loss: 0.3204 - binary_accuracy: 0.9036 - val_loss: 0.3101 - val_binary_accuracy: 0.8839\nEpoch 227/400\n6/6 [==============================] - 0s 33ms/step - loss: 0.3194 - binary_accuracy: 0.9036 - val_loss: 0.3093 - val_binary_accuracy: 0.8839\nEpoch 228/400\n6/6 [==============================] - 0s 28ms/step - loss: 0.3184 - binary_accuracy: 0.9036 - val_loss: 0.3085 - val_binary_accuracy: 0.8839\nEpoch 229/400\n6/6 [==============================] - 0s 29ms/step - loss: 0.3174 - binary_accuracy: 0.9036 - val_loss: 0.3078 - val_binary_accuracy: 0.8839\nEpoch 230/400\n6/6 [==============================] - 0s 28ms/step - loss: 0.3164 - binary_accuracy: 0.9036 - val_loss: 0.3070 - val_binary_accuracy: 0.8839\nEpoch 231/400\n6/6 [==============================] - 0s 37ms/step - loss: 0.3154 - binary_accuracy: 0.9036 - val_loss: 0.3063 - val_binary_accuracy: 0.8839\nEpoch 232/400\n6/6 [==============================] - 0s 32ms/step - loss: 0.3144 - binary_accuracy: 0.9036 - val_loss: 0.3055 - val_binary_accuracy: 0.8839\nEpoch 233/400\n6/6 [==============================] - 0s 29ms/step - loss: 0.3135 - binary_accuracy: 0.9036 - val_loss: 0.3047 - val_binary_accuracy: 0.8839\nEpoch 234/400\n6/6 [==============================] - 0s 28ms/step - loss: 0.3125 - binary_accuracy: 0.9036 - val_loss: 0.3040 - val_binary_accuracy: 0.8839\nEpoch 235/400\n6/6 [==============================] - 0s 29ms/step - loss: 0.3116 - binary_accuracy: 0.9036 - val_loss: 0.3032 - val_binary_accuracy: 0.8839\nEpoch 236/400\n6/6 [==============================] - 0s 31ms/step - loss: 0.3106 - binary_accuracy: 0.9096 - val_loss: 0.3025 - val_binary_accuracy: 0.8839\nEpoch 237/400\n6/6 [==============================] - 0s 30ms/step - loss: 0.3096 - binary_accuracy: 0.9096 - val_loss: 0.3017 - val_binary_accuracy: 0.8839\nEpoch 238/400\n6/6 [==============================] - 0s 28ms/step - loss: 0.3087 - binary_accuracy: 0.9096 - val_loss: 0.3010 - val_binary_accuracy: 0.8839\nEpoch 239/400\n6/6 [==============================] - 0s 28ms/step - loss: 0.3077 - binary_accuracy: 0.9096 - val_loss: 0.3003 - val_binary_accuracy: 0.8839\nEpoch 240/400\n6/6 [==============================] - 0s 29ms/step - loss: 0.3069 - binary_accuracy: 0.9096 - val_loss: 0.2997 - val_binary_accuracy: 0.8839\nEpoch 241/400\n6/6 [==============================] - 0s 35ms/step - loss: 0.3059 - binary_accuracy: 0.9096 - val_loss: 0.2990 - val_binary_accuracy: 0.8839\nEpoch 242/400\n6/6 [==============================] - 0s 30ms/step - loss: 0.3051 - binary_accuracy: 0.9096 - val_loss: 0.2984 - val_binary_accuracy: 0.8839\nEpoch 243/400\n6/6 [==============================] - 0s 36ms/step - loss: 0.3042 - binary_accuracy: 0.9096 - val_loss: 0.2977 - val_binary_accuracy: 0.8839\nEpoch 244/400\n6/6 [==============================] - 0s 30ms/step - loss: 0.3032 - binary_accuracy: 0.9096 - val_loss: 0.2971 - val_binary_accuracy: 0.8839\nEpoch 245/400\n6/6 [==============================] - 0s 29ms/step - loss: 0.3024 - binary_accuracy: 0.9096 - val_loss: 0.2964 - val_binary_accuracy: 0.8839\nEpoch 246/400\n6/6 [==============================] - 0s 29ms/step - loss: 0.3015 - binary_accuracy: 0.9096 - val_loss: 0.2957 - val_binary_accuracy: 0.8750\nEpoch 247/400\n6/6 [==============================] - 0s 30ms/step - loss: 0.3006 - binary_accuracy: 0.9096 - val_loss: 0.2951 - val_binary_accuracy: 0.8839\nEpoch 248/400\n6/6 [==============================] - 0s 28ms/step - loss: 0.2998 - binary_accuracy: 0.9096 - val_loss: 0.2944 - val_binary_accuracy: 0.8750\nEpoch 249/400\n6/6 [==============================] - 0s 27ms/step - loss: 0.2989 - binary_accuracy: 0.9096 - val_loss: 0.2937 - val_binary_accuracy: 0.8750\nEpoch 250/400\n6/6 [==============================] - 0s 34ms/step - loss: 0.2981 - binary_accuracy: 0.9096 - val_loss: 0.2931 - val_binary_accuracy: 0.8750\nEpoch 251/400\n6/6 [==============================] - 0s 34ms/step - loss: 0.2972 - binary_accuracy: 0.9096 - val_loss: 0.2924 - val_binary_accuracy: 0.8750\nEpoch 252/400\n6/6 [==============================] - 0s 30ms/step - loss: 0.2963 - binary_accuracy: 0.9096 - val_loss: 0.2919 - val_binary_accuracy: 0.8750\nEpoch 253/400\n6/6 [==============================] - 0s 27ms/step - loss: 0.2955 - binary_accuracy: 0.9157 - val_loss: 0.2912 - val_binary_accuracy: 0.8750\nEpoch 254/400\n6/6 [==============================] - 0s 28ms/step - loss: 0.2946 - binary_accuracy: 0.9157 - val_loss: 0.2906 - val_binary_accuracy: 0.8750\nEpoch 255/400\n6/6 [==============================] - 0s 32ms/step - loss: 0.2938 - binary_accuracy: 0.9157 - val_loss: 0.2900 - val_binary_accuracy: 0.8750\nEpoch 256/400\n6/6 [==============================] - 0s 36ms/step - loss: 0.2930 - binary_accuracy: 0.9157 - val_loss: 0.2894 - val_binary_accuracy: 0.8750\nEpoch 257/400\n6/6 [==============================] - 0s 33ms/step - loss: 0.2922 - binary_accuracy: 0.9157 - val_loss: 0.2888 - val_binary_accuracy: 0.8750\nEpoch 258/400\n6/6 [==============================] - 0s 30ms/step - loss: 0.2914 - binary_accuracy: 0.9157 - val_loss: 0.2883 - val_binary_accuracy: 0.8750\nEpoch 259/400\n6/6 [==============================] - 0s 35ms/step - loss: 0.2906 - binary_accuracy: 0.9157 - val_loss: 0.2877 - val_binary_accuracy: 0.8750\nEpoch 260/400\n6/6 [==============================] - 0s 42ms/step - loss: 0.2898 - binary_accuracy: 0.9157 - val_loss: 0.2870 - val_binary_accuracy: 0.8839\nEpoch 261/400\n6/6 [==============================] - 0s 36ms/step - loss: 0.2890 - binary_accuracy: 0.9157 - val_loss: 0.2864 - val_binary_accuracy: 0.8839\nEpoch 262/400\n6/6 [==============================] - 0s 35ms/step - loss: 0.2882 - binary_accuracy: 0.9157 - val_loss: 0.2858 - val_binary_accuracy: 0.8929\nEpoch 263/400\n6/6 [==============================] - 0s 35ms/step - loss: 0.2874 - binary_accuracy: 0.9157 - val_loss: 0.2853 - val_binary_accuracy: 0.8929\nEpoch 264/400\n6/6 [==============================] - 0s 35ms/step - loss: 0.2866 - binary_accuracy: 0.9157 - val_loss: 0.2847 - val_binary_accuracy: 0.8929\nEpoch 265/400\n6/6 [==============================] - 0s 29ms/step - loss: 0.2858 - binary_accuracy: 0.9157 - val_loss: 0.2841 - val_binary_accuracy: 0.8929\nEpoch 266/400\n6/6 [==============================] - 0s 30ms/step - loss: 0.2850 - binary_accuracy: 0.9157 - val_loss: 0.2835 - val_binary_accuracy: 0.8929\nEpoch 267/400\n6/6 [==============================] - 0s 30ms/step - loss: 0.2842 - binary_accuracy: 0.9157 - val_loss: 0.2830 - val_binary_accuracy: 0.8929\nEpoch 268/400\n6/6 [==============================] - 0s 30ms/step - loss: 0.2835 - binary_accuracy: 0.9157 - val_loss: 0.2824 - val_binary_accuracy: 0.8929\nEpoch 269/400\n6/6 [==============================] - 0s 28ms/step - loss: 0.2828 - binary_accuracy: 0.9157 - val_loss: 0.2819 - val_binary_accuracy: 0.8929\nEpoch 270/400\n6/6 [==============================] - 0s 30ms/step - loss: 0.2820 - binary_accuracy: 0.9157 - val_loss: 0.2813 - val_binary_accuracy: 0.8929\nEpoch 271/400\n6/6 [==============================] - 0s 28ms/step - loss: 0.2812 - binary_accuracy: 0.9157 - val_loss: 0.2807 - val_binary_accuracy: 0.8929\nEpoch 272/400\n6/6 [==============================] - 0s 30ms/step - loss: 0.2804 - binary_accuracy: 0.9157 - val_loss: 0.2801 - val_binary_accuracy: 0.8929\nEpoch 273/400\n6/6 [==============================] - 0s 29ms/step - loss: 0.2796 - binary_accuracy: 0.9157 - val_loss: 0.2795 - val_binary_accuracy: 0.8929\nEpoch 274/400\n6/6 [==============================] - 0s 26ms/step - loss: 0.2788 - binary_accuracy: 0.9157 - val_loss: 0.2789 - val_binary_accuracy: 0.8929\nEpoch 275/400\n6/6 [==============================] - 0s 28ms/step - loss: 0.2781 - binary_accuracy: 0.9157 - val_loss: 0.2783 - val_binary_accuracy: 0.8929\nEpoch 276/400\n6/6 [==============================] - 0s 28ms/step - loss: 0.2773 - binary_accuracy: 0.9157 - val_loss: 0.2778 - val_binary_accuracy: 0.8929\nEpoch 277/400\n6/6 [==============================] - 0s 31ms/step - loss: 0.2766 - binary_accuracy: 0.9157 - val_loss: 0.2772 - val_binary_accuracy: 0.8929\nEpoch 278/400\n6/6 [==============================] - 0s 30ms/step - loss: 0.2758 - binary_accuracy: 0.9157 - val_loss: 0.2767 - val_binary_accuracy: 0.8929\nEpoch 279/400\n6/6 [==============================] - 0s 40ms/step - loss: 0.2751 - binary_accuracy: 0.9157 - val_loss: 0.2761 - val_binary_accuracy: 0.8929\nEpoch 280/400\n6/6 [==============================] - 0s 28ms/step - loss: 0.2743 - binary_accuracy: 0.9157 - val_loss: 0.2756 - val_binary_accuracy: 0.8929\nEpoch 281/400\n6/6 [==============================] - 0s 30ms/step - loss: 0.2736 - binary_accuracy: 0.9157 - val_loss: 0.2750 - val_binary_accuracy: 0.8929\nEpoch 282/400\n6/6 [==============================] - 0s 28ms/step - loss: 0.2728 - binary_accuracy: 0.9157 - val_loss: 0.2745 - val_binary_accuracy: 0.8929\nEpoch 283/400\n6/6 [==============================] - 0s 29ms/step - loss: 0.2721 - binary_accuracy: 0.9157 - val_loss: 0.2741 - val_binary_accuracy: 0.8929\nEpoch 284/400\n6/6 [==============================] - 0s 25ms/step - loss: 0.2714 - binary_accuracy: 0.9157 - val_loss: 0.2736 - val_binary_accuracy: 0.8929\nEpoch 285/400\n6/6 [==============================] - 0s 29ms/step - loss: 0.2707 - binary_accuracy: 0.9157 - val_loss: 0.2731 - val_binary_accuracy: 0.8929\nEpoch 286/400\n6/6 [==============================] - 0s 31ms/step - loss: 0.2700 - binary_accuracy: 0.9157 - val_loss: 0.2726 - val_binary_accuracy: 0.8929\nEpoch 287/400\n6/6 [==============================] - 0s 27ms/step - loss: 0.2693 - binary_accuracy: 0.9157 - val_loss: 0.2721 - val_binary_accuracy: 0.8929\nEpoch 288/400\n6/6 [==============================] - 0s 29ms/step - loss: 0.2687 - binary_accuracy: 0.9157 - val_loss: 0.2716 - val_binary_accuracy: 0.8929\nEpoch 289/400\n6/6 [==============================] - 0s 34ms/step - loss: 0.2680 - binary_accuracy: 0.9157 - val_loss: 0.2711 - val_binary_accuracy: 0.8929\nEpoch 290/400\n6/6 [==============================] - 0s 30ms/step - loss: 0.2673 - binary_accuracy: 0.9157 - val_loss: 0.2706 - val_binary_accuracy: 0.8929\nEpoch 291/400\n6/6 [==============================] - 0s 27ms/step - loss: 0.2666 - binary_accuracy: 0.9157 - val_loss: 0.2702 - val_binary_accuracy: 0.8929\nEpoch 292/400\n6/6 [==============================] - 0s 32ms/step - loss: 0.2659 - binary_accuracy: 0.9157 - val_loss: 0.2697 - val_binary_accuracy: 0.8929\nEpoch 293/400\n6/6 [==============================] - 0s 30ms/step - loss: 0.2653 - binary_accuracy: 0.9157 - val_loss: 0.2693 - val_binary_accuracy: 0.8929\nEpoch 294/400\n6/6 [==============================] - 0s 27ms/step - loss: 0.2646 - binary_accuracy: 0.9096 - val_loss: 0.2688 - val_binary_accuracy: 0.8929\nEpoch 295/400\n6/6 [==============================] - 0s 30ms/step - loss: 0.2639 - binary_accuracy: 0.9096 - val_loss: 0.2684 - val_binary_accuracy: 0.8929\nEpoch 296/400\n6/6 [==============================] - 0s 27ms/step - loss: 0.2633 - binary_accuracy: 0.9096 - val_loss: 0.2679 - val_binary_accuracy: 0.8929\nEpoch 297/400\n6/6 [==============================] - 0s 27ms/step - loss: 0.2626 - binary_accuracy: 0.9096 - val_loss: 0.2675 - val_binary_accuracy: 0.8929\nEpoch 298/400\n6/6 [==============================] - 0s 35ms/step - loss: 0.2619 - binary_accuracy: 0.9096 - val_loss: 0.2670 - val_binary_accuracy: 0.8929\nEpoch 299/400\n6/6 [==============================] - 0s 33ms/step - loss: 0.2613 - binary_accuracy: 0.9096 - val_loss: 0.2665 - val_binary_accuracy: 0.8929\nEpoch 300/400\n6/6 [==============================] - 0s 31ms/step - loss: 0.2606 - binary_accuracy: 0.9096 - val_loss: 0.2660 - val_binary_accuracy: 0.8929\nEpoch 301/400\n6/6 [==============================] - 0s 28ms/step - loss: 0.2599 - binary_accuracy: 0.9096 - val_loss: 0.2656 - val_binary_accuracy: 0.8929\nEpoch 302/400\n6/6 [==============================] - 0s 30ms/step - loss: 0.2593 - binary_accuracy: 0.9096 - val_loss: 0.2652 - val_binary_accuracy: 0.8929\nEpoch 303/400\n6/6 [==============================] - 0s 31ms/step - loss: 0.2586 - binary_accuracy: 0.9096 - val_loss: 0.2647 - val_binary_accuracy: 0.8929\nEpoch 304/400\n6/6 [==============================] - 0s 33ms/step - loss: 0.2580 - binary_accuracy: 0.9096 - val_loss: 0.2643 - val_binary_accuracy: 0.8929\nEpoch 305/400\n6/6 [==============================] - 0s 33ms/step - loss: 0.2573 - binary_accuracy: 0.9096 - val_loss: 0.2638 - val_binary_accuracy: 0.8929\nEpoch 306/400\n6/6 [==============================] - 0s 32ms/step - loss: 0.2567 - binary_accuracy: 0.9096 - val_loss: 0.2634 - val_binary_accuracy: 0.8929\nEpoch 307/400\n6/6 [==============================] - 0s 35ms/step - loss: 0.2561 - binary_accuracy: 0.9096 - val_loss: 0.2629 - val_binary_accuracy: 0.8929\nEpoch 308/400\n6/6 [==============================] - 0s 35ms/step - loss: 0.2555 - binary_accuracy: 0.9096 - val_loss: 0.2625 - val_binary_accuracy: 0.8929\nEpoch 309/400\n6/6 [==============================] - 0s 30ms/step - loss: 0.2548 - binary_accuracy: 0.9096 - val_loss: 0.2620 - val_binary_accuracy: 0.8929\nEpoch 310/400\n6/6 [==============================] - 0s 28ms/step - loss: 0.2542 - binary_accuracy: 0.9096 - val_loss: 0.2616 - val_binary_accuracy: 0.8929\nEpoch 311/400\n6/6 [==============================] - 0s 30ms/step - loss: 0.2535 - binary_accuracy: 0.9096 - val_loss: 0.2612 - val_binary_accuracy: 0.8929\nEpoch 312/400\n6/6 [==============================] - 0s 32ms/step - loss: 0.2529 - binary_accuracy: 0.9096 - val_loss: 0.2608 - val_binary_accuracy: 0.8929\nEpoch 313/400\n6/6 [==============================] - 0s 31ms/step - loss: 0.2523 - binary_accuracy: 0.9096 - val_loss: 0.2604 - val_binary_accuracy: 0.8929\nEpoch 314/400\n6/6 [==============================] - 0s 28ms/step - loss: 0.2517 - binary_accuracy: 0.9157 - val_loss: 0.2600 - val_binary_accuracy: 0.8929\nEpoch 315/400\n6/6 [==============================] - 0s 29ms/step - loss: 0.2511 - binary_accuracy: 0.9157 - val_loss: 0.2595 - val_binary_accuracy: 0.8929\nEpoch 316/400\n6/6 [==============================] - 0s 29ms/step - loss: 0.2505 - binary_accuracy: 0.9157 - val_loss: 0.2591 - val_binary_accuracy: 0.8929\nEpoch 317/400\n6/6 [==============================] - 0s 34ms/step - loss: 0.2499 - binary_accuracy: 0.9157 - val_loss: 0.2587 - val_binary_accuracy: 0.8929\nEpoch 318/400\n6/6 [==============================] - 0s 31ms/step - loss: 0.2493 - binary_accuracy: 0.9157 - val_loss: 0.2583 - val_binary_accuracy: 0.8929\nEpoch 319/400\n6/6 [==============================] - 0s 31ms/step - loss: 0.2487 - binary_accuracy: 0.9157 - val_loss: 0.2578 - val_binary_accuracy: 0.8929\nEpoch 320/400\n6/6 [==============================] - 0s 30ms/step - loss: 0.2480 - binary_accuracy: 0.9157 - val_loss: 0.2574 - val_binary_accuracy: 0.8929\nEpoch 321/400\n6/6 [==============================] - 0s 30ms/step - loss: 0.2474 - binary_accuracy: 0.9157 - val_loss: 0.2570 - val_binary_accuracy: 0.8929\nEpoch 322/400\n6/6 [==============================] - 0s 30ms/step - loss: 0.2468 - binary_accuracy: 0.9157 - val_loss: 0.2565 - val_binary_accuracy: 0.8929\nEpoch 323/400\n6/6 [==============================] - 0s 29ms/step - loss: 0.2462 - binary_accuracy: 0.9157 - val_loss: 0.2562 - val_binary_accuracy: 0.8929\nEpoch 324/400\n6/6 [==============================] - 0s 28ms/step - loss: 0.2456 - binary_accuracy: 0.9157 - val_loss: 0.2558 - val_binary_accuracy: 0.8929\nEpoch 325/400\n6/6 [==============================] - 0s 28ms/step - loss: 0.2450 - binary_accuracy: 0.9157 - val_loss: 0.2554 - val_binary_accuracy: 0.8929\nEpoch 326/400\n6/6 [==============================] - 0s 31ms/step - loss: 0.2445 - binary_accuracy: 0.9157 - val_loss: 0.2550 - val_binary_accuracy: 0.8929\nEpoch 327/400\n6/6 [==============================] - 0s 38ms/step - loss: 0.2439 - binary_accuracy: 0.9157 - val_loss: 0.2546 - val_binary_accuracy: 0.8929\nEpoch 328/400\n6/6 [==============================] - 0s 29ms/step - loss: 0.2433 - binary_accuracy: 0.9157 - val_loss: 0.2542 - val_binary_accuracy: 0.8929\nEpoch 329/400\n6/6 [==============================] - 0s 28ms/step - loss: 0.2427 - binary_accuracy: 0.9157 - val_loss: 0.2538 - val_binary_accuracy: 0.8929\nEpoch 330/400\n6/6 [==============================] - 0s 31ms/step - loss: 0.2422 - binary_accuracy: 0.9157 - val_loss: 0.2534 - val_binary_accuracy: 0.8929\nEpoch 331/400\n6/6 [==============================] - 0s 31ms/step - loss: 0.2416 - binary_accuracy: 0.9157 - val_loss: 0.2531 - val_binary_accuracy: 0.8929\nEpoch 332/400\n6/6 [==============================] - 0s 31ms/step - loss: 0.2410 - binary_accuracy: 0.9157 - val_loss: 0.2526 - val_binary_accuracy: 0.8929\nEpoch 333/400\n6/6 [==============================] - 0s 30ms/step - loss: 0.2404 - binary_accuracy: 0.9157 - val_loss: 0.2522 - val_binary_accuracy: 0.8929\nEpoch 334/400\n6/6 [==============================] - 0s 32ms/step - loss: 0.2398 - binary_accuracy: 0.9157 - val_loss: 0.2518 - val_binary_accuracy: 0.8929\nEpoch 335/400\n6/6 [==============================] - 0s 31ms/step - loss: 0.2393 - binary_accuracy: 0.9157 - val_loss: 0.2515 - val_binary_accuracy: 0.8929\nEpoch 336/400\n6/6 [==============================] - 0s 38ms/step - loss: 0.2387 - binary_accuracy: 0.9157 - val_loss: 0.2511 - val_binary_accuracy: 0.8929\nEpoch 337/400\n6/6 [==============================] - 0s 28ms/step - loss: 0.2381 - binary_accuracy: 0.9157 - val_loss: 0.2508 - val_binary_accuracy: 0.8929\nEpoch 338/400\n6/6 [==============================] - 0s 30ms/step - loss: 0.2376 - binary_accuracy: 0.9157 - val_loss: 0.2504 - val_binary_accuracy: 0.8929\nEpoch 339/400\n6/6 [==============================] - 0s 27ms/step - loss: 0.2370 - binary_accuracy: 0.9157 - val_loss: 0.2501 - val_binary_accuracy: 0.8929\nEpoch 340/400\n6/6 [==============================] - 0s 31ms/step - loss: 0.2365 - binary_accuracy: 0.9157 - val_loss: 0.2497 - val_binary_accuracy: 0.8929\nEpoch 341/400\n6/6 [==============================] - 0s 29ms/step - loss: 0.2359 - binary_accuracy: 0.9157 - val_loss: 0.2493 - val_binary_accuracy: 0.8929\nEpoch 342/400\n6/6 [==============================] - 0s 34ms/step - loss: 0.2354 - binary_accuracy: 0.9157 - val_loss: 0.2490 - val_binary_accuracy: 0.8929\nEpoch 343/400\n6/6 [==============================] - 0s 28ms/step - loss: 0.2349 - binary_accuracy: 0.9157 - val_loss: 0.2486 - val_binary_accuracy: 0.8929\nEpoch 344/400\n6/6 [==============================] - 0s 28ms/step - loss: 0.2343 - binary_accuracy: 0.9157 - val_loss: 0.2483 - val_binary_accuracy: 0.8929\nEpoch 345/400\n6/6 [==============================] - 0s 28ms/step - loss: 0.2338 - binary_accuracy: 0.9157 - val_loss: 0.2479 - val_binary_accuracy: 0.8929\nEpoch 346/400\n6/6 [==============================] - 0s 34ms/step - loss: 0.2332 - binary_accuracy: 0.9157 - val_loss: 0.2475 - val_binary_accuracy: 0.8929\nEpoch 347/400\n4/6 [===================>..........] - ETA: 0s - loss: 0.1992 - binary_accuracy: 0.9296/6 [==============================] - 0s 28ms/step - loss: 0.2327 - binary_accuracy: 0.9157 - val_loss: 0.2471 - val_binary_accuracy: 0.8929\nEpoch 348/400\n6/6 [==============================] - 0s 31ms/step - loss: 0.2321 - binary_accuracy: 0.9157 - val_loss: 0.2468 - val_binary_accuracy: 0.8929\nEpoch 349/400\n6/6 [==============================] - 0s 30ms/step - loss: 0.2316 - binary_accuracy: 0.9157 - val_loss: 0.2465 - val_binary_accuracy: 0.8929\nEpoch 350/400\n6/6 [==============================] - 0s 32ms/step - loss: 0.2311 - binary_accuracy: 0.9157 - val_loss: 0.2461 - val_binary_accuracy: 0.8929\nEpoch 351/400\n6/6 [==============================] - 0s 28ms/step - loss: 0.2306 - binary_accuracy: 0.9157 - val_loss: 0.2458 - val_binary_accuracy: 0.8929\nEpoch 352/400\n6/6 [==============================] - 0s 29ms/step - loss: 0.2301 - binary_accuracy: 0.9157 - val_loss: 0.2455 - val_binary_accuracy: 0.8929\nEpoch 353/400\n6/6 [==============================] - 0s 30ms/step - loss: 0.2296 - binary_accuracy: 0.9157 - val_loss: 0.2452 - val_binary_accuracy: 0.8929\nEpoch 354/400\n6/6 [==============================] - 0s 35ms/step - loss: 0.2291 - binary_accuracy: 0.9157 - val_loss: 0.2448 - val_binary_accuracy: 0.8929\nEpoch 355/400\n6/6 [==============================] - 0s 33ms/step - loss: 0.2286 - binary_accuracy: 0.9157 - val_loss: 0.2445 - val_binary_accuracy: 0.8929\nEpoch 356/400\n6/6 [==============================] - 0s 28ms/step - loss: 0.2281 - binary_accuracy: 0.9157 - val_loss: 0.2442 - val_binary_accuracy: 0.8929\nEpoch 357/400\n6/6 [==============================] - 0s 29ms/step - loss: 0.2276 - binary_accuracy: 0.9157 - val_loss: 0.2438 - val_binary_accuracy: 0.8929\nEpoch 358/400\n6/6 [==============================] - 0s 34ms/step - loss: 0.2270 - binary_accuracy: 0.9157 - val_loss: 0.2434 - val_binary_accuracy: 0.8929\nEpoch 359/400\n6/6 [==============================] - 0s 31ms/step - loss: 0.2265 - binary_accuracy: 0.9157 - val_loss: 0.2431 - val_binary_accuracy: 0.8929\nEpoch 360/400\n6/6 [==============================] - 0s 35ms/step - loss: 0.2260 - binary_accuracy: 0.9157 - val_loss: 0.2427 - val_binary_accuracy: 0.8929\nEpoch 361/400\n6/6 [==============================] - 0s 28ms/step - loss: 0.2255 - binary_accuracy: 0.9217 - val_loss: 0.2424 - val_binary_accuracy: 0.8929\nEpoch 362/400\n6/6 [==============================] - 0s 32ms/step - loss: 0.2250 - binary_accuracy: 0.9217 - val_loss: 0.2421 - val_binary_accuracy: 0.8929\nEpoch 363/400\n6/6 [==============================] - 0s 36ms/step - loss: 0.2245 - binary_accuracy: 0.9217 - val_loss: 0.2417 - val_binary_accuracy: 0.8929\nEpoch 364/400\n6/6 [==============================] - 0s 30ms/step - loss: 0.2240 - binary_accuracy: 0.9217 - val_loss: 0.2414 - val_binary_accuracy: 0.8929\nEpoch 365/400\n6/6 [==============================] - 0s 32ms/step - loss: 0.2236 - binary_accuracy: 0.9217 - val_loss: 0.2411 - val_binary_accuracy: 0.8929\nEpoch 366/400\n6/6 [==============================] - 0s 29ms/step - loss: 0.2230 - binary_accuracy: 0.9217 - val_loss: 0.2408 - val_binary_accuracy: 0.8929\nEpoch 367/400\n6/6 [==============================] - 0s 31ms/step - loss: 0.2225 - binary_accuracy: 0.9277 - val_loss: 0.2405 - val_binary_accuracy: 0.8929\nEpoch 368/400\n6/6 [==============================] - 0s 30ms/step - loss: 0.2221 - binary_accuracy: 0.9277 - val_loss: 0.2402 - val_binary_accuracy: 0.8929\nEpoch 369/400\n6/6 [==============================] - 0s 28ms/step - loss: 0.2216 - binary_accuracy: 0.9277 - val_loss: 0.2399 - val_binary_accuracy: 0.8929\nEpoch 370/400\n6/6 [==============================] - 0s 35ms/step - loss: 0.2211 - binary_accuracy: 0.9277 - val_loss: 0.2396 - val_binary_accuracy: 0.8929\nEpoch 371/400\n6/6 [==============================] - 0s 32ms/step - loss: 0.2206 - binary_accuracy: 0.9277 - val_loss: 0.2392 - val_binary_accuracy: 0.8929\nEpoch 372/400\n6/6 [==============================] - 0s 30ms/step - loss: 0.2202 - binary_accuracy: 0.9277 - val_loss: 0.2388 - val_binary_accuracy: 0.8929\nEpoch 373/400\n6/6 [==============================] - 0s 28ms/step - loss: 0.2197 - binary_accuracy: 0.9277 - val_loss: 0.2385 - val_binary_accuracy: 0.8929\nEpoch 374/400\n6/6 [==============================] - 0s 34ms/step - loss: 0.2192 - binary_accuracy: 0.9277 - val_loss: 0.2382 - val_binary_accuracy: 0.8929\nEpoch 375/400\n6/6 [==============================] - 0s 29ms/step - loss: 0.2187 - binary_accuracy: 0.9277 - val_loss: 0.2379 - val_binary_accuracy: 0.8929\nEpoch 376/400\n6/6 [==============================] - 0s 34ms/step - loss: 0.2183 - binary_accuracy: 0.9277 - val_loss: 0.2376 - val_binary_accuracy: 0.9018\nEpoch 377/400\n6/6 [==============================] - 0s 32ms/step - loss: 0.2178 - binary_accuracy: 0.9277 - val_loss: 0.2373 - val_binary_accuracy: 0.9018\nEpoch 378/400\n6/6 [==============================] - 0s 31ms/step - loss: 0.2174 - binary_accuracy: 0.9277 - val_loss: 0.2370 - val_binary_accuracy: 0.9107\nEpoch 379/400\n6/6 [==============================] - 0s 31ms/step - loss: 0.2170 - binary_accuracy: 0.9277 - val_loss: 0.2367 - val_binary_accuracy: 0.9107\nEpoch 380/400\n6/6 [==============================] - 0s 32ms/step - loss: 0.2165 - binary_accuracy: 0.9277 - val_loss: 0.2364 - val_binary_accuracy: 0.9107\nEpoch 381/400\n6/6 [==============================] - 0s 31ms/step - loss: 0.2161 - binary_accuracy: 0.9277 - val_loss: 0.2361 - val_binary_accuracy: 0.9107\nEpoch 382/400\n6/6 [==============================] - 0s 31ms/step - loss: 0.2156 - binary_accuracy: 0.9277 - val_loss: 0.2358 - val_binary_accuracy: 0.9107\nEpoch 383/400\n6/6 [==============================] - 0s 31ms/step - loss: 0.2152 - binary_accuracy: 0.9277 - val_loss: 0.2355 - val_binary_accuracy: 0.9107\nEpoch 384/400\n6/6 [==============================] - 0s 48ms/step - loss: 0.2147 - binary_accuracy: 0.9277 - val_loss: 0.2352 - val_binary_accuracy: 0.9107\nEpoch 385/400\n6/6 [==============================] - 0s 32ms/step - loss: 0.2143 - binary_accuracy: 0.9277 - val_loss: 0.2349 - val_binary_accuracy: 0.9107\nEpoch 386/400\n6/6 [==============================] - 0s 29ms/step - loss: 0.2139 - binary_accuracy: 0.9277 - val_loss: 0.2346 - val_binary_accuracy: 0.9107\nEpoch 387/400\n6/6 [==============================] - 0s 29ms/step - loss: 0.2134 - binary_accuracy: 0.9277 - val_loss: 0.2344 - val_binary_accuracy: 0.9107\nEpoch 388/400\n6/6 [==============================] - 0s 31ms/step - loss: 0.2130 - binary_accuracy: 0.9277 - val_loss: 0.2341 - val_binary_accuracy: 0.9107\nEpoch 389/400\n6/6 [==============================] - 0s 32ms/step - loss: 0.2126 - binary_accuracy: 0.9277 - val_loss: 0.2338 - val_binary_accuracy: 0.9107\nEpoch 390/400\n6/6 [==============================] - 0s 29ms/step - loss: 0.2121 - binary_accuracy: 0.9277 - val_loss: 0.2335 - val_binary_accuracy: 0.9107\nEpoch 391/400\n6/6 [==============================] - 0s 28ms/step - loss: 0.2117 - binary_accuracy: 0.9277 - val_loss: 0.2332 - val_binary_accuracy: 0.9107\nEpoch 392/400\n6/6 [==============================] - 0s 29ms/step - loss: 0.2113 - binary_accuracy: 0.9277 - val_loss: 0.2330 - val_binary_accuracy: 0.9107\nEpoch 393/400\n6/6 [==============================] - 0s 46ms/step - loss: 0.2108 - binary_accuracy: 0.9277 - val_loss: 0.2327 - val_binary_accuracy: 0.9107\nEpoch 394/400\n6/6 [==============================] - 1s 131ms/step - loss: 0.2104 - binary_accuracy: 0.9277 - val_loss: 0.2324 - val_binary_accuracy: 0.9107\nEpoch 395/400\n6/6 [==============================] - 0s 41ms/step - loss: 0.2100 - binary_accuracy: 0.9277 - val_loss: 0.2322 - val_binary_accuracy: 0.9107\nEpoch 396/400\n6/6 [==============================] - 0s 62ms/step - loss: 0.2096 - binary_accuracy: 0.9277 - val_loss: 0.2319 - val_binary_accuracy: 0.9107\nEpoch 397/400\n6/6 [==============================] - 0s 45ms/step - loss: 0.2091 - binary_accuracy: 0.9277 - val_loss: 0.2316 - val_binary_accuracy: 0.9107\nEpoch 398/400\n6/6 [==============================] - 0s 27ms/step - loss: 0.2086 - binary_accuracy: 0.9337 - val_loss: 0.2314 - val_binary_accuracy: 0.9107\nEpoch 399/400\n6/6 [==============================] - 0s 30ms/step - loss: 0.2082 - binary_accuracy: 0.9337 - val_loss: 0.2311 - val_binary_accuracy: 0.9107\nEpoch 400/400\n6/6 [==============================] - 0s 56ms/step - loss: 0.2078 - binary_accuracy: 0.9337 - val_loss: 0.2308 - val_binary_accuracy: 0.9107\n"
    }
   ],
   "source": [
    "epochs = 400\n",
    "run_log_dir = get_run_logdir('cnn')\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_log_dir)\n",
    "#model.run_eagerly = False\n",
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=epochs, verbose=1, batch_size=32,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    callbacks=[tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#early_stopping_cb = keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)\n",
    "def exponential_decay(lr0, s):\n",
    "    def exponential_decay_fn(epoch):\n",
    "        return lr0 * 0.1**(epoch/s)\n",
    "    return exponential_decay_fn\n",
    "\n",
    "exponential_decay_fn = exponential_decay(lr0=1e-5, s=-17)    \n",
    "epochs = 500\n",
    "run_log_dir = get_run_logdir('cnn')\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(run_log_dir)  \n",
    "\n",
    "lr = [exponential_decay_fn(epoch) for epoch in range(100)]\n",
    "lr_scheduler = keras.callbacks.LearningRateScheduler(exponential_decay_fn)\n",
    "epochs = 100\n",
    "class_weight = {0: 1.,\n",
    "                1: 1.}\n",
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=epochs, verbose=1, class_weight=class_weight,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    callbacks= [lr_scheduler, tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(lr, history.history['val_loss'])\n",
    "plt.xlim(1e-5, 1e-1)\n",
    "plt.xscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = y_test\n",
    "y_pred = model.predict_classes(X_test)\n",
    "m = keras.metrics.Recall()\n",
    "m.update_state(y_true, y_pred)\n",
    "m.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [0, 0, 1.2, 0.8]\n",
    "b = [1, 1, 1, 1] \n",
    "keras.metrics.Accuracy()(tf.round(a),tf.round(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "y_pred = grid_search.best_estimator_.predict(X_test)\n",
    "\n",
    "# y_pred = np.round(y_pred)\n",
    "print(accuracy_score(y_test, y_pred))\n",
    "print(recall_score(y_test, y_pred))\n",
    "print(precision_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_clf = keras.wrappers.scikit_learn.KerasClassifier(build_CNN)\n",
    "\n",
    "model = cnn_clf\n",
    "model_dir = 'data/models/cnn'\n",
    "model_version = 'cnn_002.h5'\n",
    "model_csv = 'cnn_002.csv'\n",
    "scoring = ['recall', 'accuracy', 'precision']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [\n",
    "    {'layers': [1],\n",
    "     'filters' : [10, 50, 100], #train batte validation con filter >5. Esecuzione normale con filter =5 layer =1\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "# Tuning hyper-parameters for recall and accuracy\n\nFitting 5 folds for each of 3 candidates, totalling 15 fits\n[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:   58.3s finished\nEpoch 1/30\n9/9 [==============================] - 0s 25ms/step - loss: 0.6059 - binary_accuracy: 0.6835\nEpoch 2/30\n9/9 [==============================] - 0s 18ms/step - loss: 0.5528 - binary_accuracy: 0.7410\nEpoch 3/30\n9/9 [==============================] - 0s 21ms/step - loss: 0.5024 - binary_accuracy: 0.7806\nEpoch 4/30\n9/9 [==============================] - 0s 19ms/step - loss: 0.4574 - binary_accuracy: 0.8273\nEpoch 5/30\n9/9 [==============================] - 0s 19ms/step - loss: 0.4201 - binary_accuracy: 0.8561\nEpoch 6/30\n9/9 [==============================] - 0s 19ms/step - loss: 0.3884 - binary_accuracy: 0.8813\nEpoch 7/30\n9/9 [==============================] - 0s 19ms/step - loss: 0.3623 - binary_accuracy: 0.8813\nEpoch 8/30\n9/9 [==============================] - 0s 20ms/step - loss: 0.3399 - binary_accuracy: 0.8813\nEpoch 9/30\n9/9 [==============================] - 0s 20ms/step - loss: 0.3218 - binary_accuracy: 0.8885\nEpoch 10/30\n9/9 [==============================] - 0s 21ms/step - loss: 0.3053 - binary_accuracy: 0.9065\nEpoch 11/30\n9/9 [==============================] - 0s 18ms/step - loss: 0.2910 - binary_accuracy: 0.9065\nEpoch 12/30\n9/9 [==============================] - 0s 20ms/step - loss: 0.2787 - binary_accuracy: 0.9137\nEpoch 13/30\n9/9 [==============================] - 0s 21ms/step - loss: 0.2679 - binary_accuracy: 0.9173\nEpoch 14/30\n9/9 [==============================] - 0s 19ms/step - loss: 0.2586 - binary_accuracy: 0.9209\nEpoch 15/30\n9/9 [==============================] - 0s 20ms/step - loss: 0.2493 - binary_accuracy: 0.9209\nEpoch 16/30\n9/9 [==============================] - 0s 19ms/step - loss: 0.2416 - binary_accuracy: 0.9281\nEpoch 17/30\n9/9 [==============================] - 0s 21ms/step - loss: 0.2348 - binary_accuracy: 0.9317\nEpoch 18/30\n9/9 [==============================] - 0s 19ms/step - loss: 0.2283 - binary_accuracy: 0.9353\nEpoch 19/30\n9/9 [==============================] - 0s 20ms/step - loss: 0.2222 - binary_accuracy: 0.9353\nEpoch 20/30\n9/9 [==============================] - 0s 21ms/step - loss: 0.2168 - binary_accuracy: 0.9353\nEpoch 21/30\n9/9 [==============================] - 0s 23ms/step - loss: 0.2118 - binary_accuracy: 0.9353\nEpoch 22/30\n9/9 [==============================] - 0s 19ms/step - loss: 0.2072 - binary_accuracy: 0.9353\nEpoch 23/30\n9/9 [==============================] - 0s 19ms/step - loss: 0.2027 - binary_accuracy: 0.9424\nEpoch 24/30\n9/9 [==============================] - 0s 20ms/step - loss: 0.1985 - binary_accuracy: 0.9424\nEpoch 25/30\n9/9 [==============================] - 0s 21ms/step - loss: 0.1945 - binary_accuracy: 0.9424\nEpoch 26/30\n9/9 [==============================] - 0s 19ms/step - loss: 0.1912 - binary_accuracy: 0.9424\nEpoch 27/30\n9/9 [==============================] - 0s 20ms/step - loss: 0.1877 - binary_accuracy: 0.9424\nEpoch 28/30\n9/9 [==============================] - 0s 19ms/step - loss: 0.1843 - binary_accuracy: 0.9424\nEpoch 29/30\n9/9 [==============================] - 0s 20ms/step - loss: 0.1815 - binary_accuracy: 0.9424\nEpoch 30/30\n9/9 [==============================] - 0s 20ms/step - loss: 0.1785 - binary_accuracy: 0.9424\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "GridSearchCV(cv=StratifiedKFold(n_splits=5, random_state=42, shuffle=True),\n             error_score='raise-deprecating',\n             estimator=<tensorflow.python.keras.wrappers.scikit_learn.KerasClassifier object at 0x164f2b208>,\n             iid='warn', n_jobs=-1,\n             param_grid=[{'filters': [10, 50, 100], 'layers': [1]}],\n             pre_dispatch='2*n_jobs', refit='accuracy', return_train_score=True,\n             scoring=['recall', 'accuracy', 'precision'], verbose=2)"
     },
     "metadata": {},
     "execution_count": 195
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "\n",
    "print(\"# Tuning hyper-parameters for {} and {}\".format(scoring[0], scoring[1]))\n",
    "print()\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=model, \n",
    "    param_grid=param_grid, \n",
    "    scoring=scoring,\n",
    "    n_jobs=-1,\n",
    "    verbose=2, \n",
    "    cv=strat_kfold, \n",
    "    return_train_score=True,\n",
    "    refit=scoring[1]  ## Score used for final refit\n",
    ")\n",
    "\n",
    "grid_search.fit(X, y, epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Best parameters set found on development set:\n{'filters': 20, 'layers': 1}\n\nGrid scores on development set:\n\n0.939 (+/-0.048) for {'filters': 20, 'layers': 1}\n"
    }
   ],
   "source": [
    "printGridSearchResults(grid_search, scoring[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search.best_estimator_.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_result = pd.DataFrame(grid_search.cv_results_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_result.to_csv(os.path.join(model_dir, model_csv),  index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.read_csv('data/datasets/df_raw.csv')\n",
    "df_raw = df_raw[df_raw.fillNumber != 2011]\n",
    "\n",
    "df_raw = df_raw.astype({'fillNumber': 'int'})\n",
    "df_raw = df_raw.set_index(['gauge_id','fillNumber'], drop=True)\n",
    "df_raw.index.get_level_values('fillNumber').value_counts()\n",
    "\n",
    "\n",
    "kmeans_centers_path = 'data/datasets/k12_centers.npy'\n",
    "silhouette_scores_path = 'data/datasets/silhouette_scores_range_2_20.npy'\n",
    "inertias_path = 'data/datasets/intertias_range_2_20.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "scaler = RowScaler(scaling_method='Standard')\n",
    "Xu_scaled = scaler.fit_transform(df_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(kmeans_centers_path):\n",
    "    k12_centers = np.load(kmeans_centers_path)\n",
    "    print('KMeans center loaded.')\n",
    "else:\n",
    "    print('Recomputing KMeans...')\n",
    "    kmeans_per_k = [KMeans(n_clusters=k,\n",
    "                                    algorithm='elkan',\n",
    "                                    random_state=42,\n",
    "                                    n_jobs=-1,\n",
    "                                    verbose=2\n",
    "                                    ).fit(X_scaled)\n",
    "                    for k in range(2, 20)]\n",
    "    k12_centers = np.array(kmeans_per_k[12 -2].cluster_centers_)\n",
    "    np.save('data/datasets/k12_centers.npy', k12_centers)\n",
    "\n",
    "\n",
    "\n",
    "if os.path.exists(inertias_path):\n",
    "    inertias = np.load(inertias_path)\n",
    "    print('inertias loaded.')\n",
    "else:\n",
    "    inertias = [model.inertia_ for model in kmeans_per_k]\n",
    "    np.save(inertias_path, inertias)\n",
    "    print('inertias saved.')\n",
    "\n",
    "if os.path.exists(silhouette_scores_path):\n",
    "    silhouette_scores = np.load(silhouette_scores_path)\n",
    "    print('silhouette loaded')\n",
    "else:\n",
    "    silhouette_scores = [silhouette_score(X_scaled, model.labels_)\n",
    "                         for model in kmeans_per_k]\n",
    "    np.save(silhouette_scores_path, silhouette_scores)\n",
    "    print('silhouette saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 3.5))\n",
    "plt.plot(range(2, 20), inertias, \"bo-\")\n",
    "plt.xlabel(\"$k$\", fontsize=14)\n",
    "plt.ylabel(\"Inertia\", fontsize=14)\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 3))\n",
    "plt.plot(range(2, 20), silhouette_scores, \"bo-\")\n",
    "plt.xlabel(\"$k$\", fontsize=14)\n",
    "plt.xlim(10,15)\n",
    "plt.ylim(0.16, 0.19)\n",
    "plt.ylabel(\"Silhouette score\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_samples\n",
    "from matplotlib.ticker import FixedLocator, FixedFormatter\n",
    "\n",
    "plt.figure(figsize=(11, 9))\n",
    "\n",
    "for k in (10, 11, 12, 13):\n",
    "    plt.subplot(2, 2, k - 9)\n",
    "    \n",
    "    y_pred = kmeans_per_k[k - 2].labels_\n",
    "    silhouette_coefficients = silhouette_samples(X_scaled, y_pred)\n",
    "\n",
    "    padding = len(X_scaled) // 30\n",
    "    pos = padding\n",
    "    ticks = []\n",
    "    for i in range(k):\n",
    "        coeffs = silhouette_coefficients[y_pred == i]\n",
    "        coeffs.sort()\n",
    "\n",
    "        color = mpl.cm.Spectral(i / k)\n",
    "        plt.fill_betweenx(np.arange(pos, pos + len(coeffs)), 0, coeffs,\n",
    "                          facecolor=color, edgecolor=color, alpha=0.7)\n",
    "        ticks.append(pos + len(coeffs) // 2)\n",
    "        pos += len(coeffs) + padding\n",
    "\n",
    "    plt.gca().yaxis.set_major_locator(FixedLocator(ticks))\n",
    "    plt.gca().yaxis.set_major_formatter(FixedFormatter(range(k)))\n",
    "    if k in (10, 12):\n",
    "        plt.ylabel(\"Cluster\")\n",
    "    \n",
    "    if k in (12, 13):\n",
    "        plt.gca().set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "        plt.xlabel(\"Silhouette Coefficient\")\n",
    "    else:\n",
    "        plt.tick_params(labelbottom=False)\n",
    "\n",
    "    plt.axvline(x=silhouette_scores[k - 2], color=\"red\", linestyle=\"--\")\n",
    "    plt.title(\"$k={}$\".format(k), fontsize=16)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(kmeans_per_k[12 -2].cluster_centers_)\n",
    "k12_centers.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k12_centers = np.load('data/datasets/k12_centers.npy')\n",
    "for c in k12_centers:\n",
    "    plt.plot(range(3000), c)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "d_max = np.max(euclidean_distances(k12_centers, k12_centers))\n",
    "keras.backend.clear_session()\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Lambda(lambda X: rowScale(X), input_shape=[3000]))\n",
    "model.add(RBFLayer(12,\n",
    "                    initializer=InitFromFile('data/datasets/k12_centers.npy'),\n",
    "                    betas=d_max/np.sqrt(len(k12_centers)),\n",
    "                    trainable=False,\n",
    "                    input_shape=[3000])\n",
    "                    )\n",
    "model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
    "model.add(keras.layers.Lambda(lambda X: tf.round(X)))\n",
    "\n",
    "optimizer = keras.optimizers.Adam()\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=[keras.metrics.Recall()])\n",
    "\n",
    "model.summary()\n",
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X, y, epochs=5, validation_split=0.33, verbose=1)\n",
    "y_pred = model.predict(X[-50:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "11 // 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "domande:\n",
    "devo abilitare il training sul layer RBF? iniziamo senza farlo\n",
    "definire modelli finali: pca solo su training, kmeans su tutto unlabelled\n",
    "train - val- test split, va bene? No usiamo solo k fold\n",
    "quante fold nel k fold? meglio 10\n",
    "perche RNN cosi lenta?"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}